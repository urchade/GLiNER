<!DOCTYPE html>
<html lang="en" data-accent-color="violet" data-content_root="../">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>gliner.modeling.utils module - Home 0.2.24 documentation</title><link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="gliner.data_processing package" href="gliner.data_processing.html" /><link rel="prev" title="gliner.modeling.span_rep module" href="gliner.modeling.span_rep.html" /><script>
    function setColorMode(t){let e=document.documentElement;e.setAttribute("data-color-mode",t);let a=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,s=t;"auto"===t&&(s=a?"dark":"light"),"light"===s?(e.classList.remove("dark"),e.classList.add("light")):(e.classList.remove("light"),e.classList.add("dark"))}
    setColorMode(localStorage._theme||"auto");
  </script><link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=e1a1ceaf" />
    <link rel="stylesheet" type="text/css" href="../_static/shibuya.css?v=d140fbf8" />
    <link media="print" rel="stylesheet" type="text/css" href="../_static/print.css?v=20ff2c19" />
    <link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
<style>
:root {
  --sy-f-text: "Inter", var(--sy-f-sys), var(--sy-f-cjk), sans-serif;
  --sy-f-heading: "Inter", var(--sy-f-sys), var(--sy-f-cjk), sans-serif;
}
</style>
    <meta property="og:type" content="website"/><meta property="og:title" content="gliner.modeling.utils module"/>
<meta name="twitter:card" content="summary"/>
  </head>
<body><div class="sy-head">
  <div class="sy-head-blur"></div>
  <div class="sy-head-inner sy-container mx-auto">
    <a class="sy-head-brand" href="../index.html">
      
      
      <strong>Home</strong>
    </a>
    <div class="sy-head-nav" id="head-nav">
      <nav class="sy-head-links"></nav>
      <div class="sy-head-extra flex items-center print:hidden"><form class="searchbox flex items-center" action="../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <kbd>/</kbd>
</form><div class="sy-head-socials"></div></div>
    </div>
    <div class="sy-head-actions flex items-center shrink-0 print:hidden"><button class="js-theme theme-switch flex items-center"
data-aria-auto="Switch to light color mode"
data-aria-light="Switch to dark color mode"
data-aria-dark="Switch to auto color mode">
<i class="i-lucide theme-icon"></i>
</button><button class="md:hidden flex items-center js-menu" aria-label="Menu" type="button" aria-controls="head-nav" aria-expanded="false">
        <div class="hamburger">
          <span class="hamburger_1"></span>
          <span class="hamburger_2"></span>
          <span class="hamburger_3"></span>
        </div>
      </button>
    </div>
  </div>
</div>
<div class="sy-page sy-container flex mx-auto">
  <aside id="lside" class="sy-lside md:w-72 md:shrink-0 print:hidden">
    <div class="sy-lside-inner md:sticky">
      <div class="sy-scrollbar p-6">
        <div class="globaltoc" data-expand-depth="0"><p class="caption" role="heading" aria-level="3"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intro.html">Introduction to üëë GLiNER</a></li>
<li class="toctree-l1"><a class="reference internal" href="../instalation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../usage.html">Advanced Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../configs.html">Components &amp; Configs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training.html">Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../architectures.html">Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../convert_to_onnx.html">ONNX Export &amp; Deployment</a></li>
</ul>
<p class="caption" role="heading" aria-level="3"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="gliner.model.html">gliner.model module</a></li>
<li class="toctree-l1"><a class="reference internal" href="gliner.config.html">gliner.config module</a></li>
<li class="toctree-l1"><a class="reference internal" href="gliner.training.html">gliner.training package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gliner.training.trainer.html">gliner.training.trainer module</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="gliner.modeling.html">gliner.modeling package</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="gliner.modeling.multitask.html">gliner.modeling.multitask package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gliner.modeling.multitask.relations_layers.html">gliner.modeling.multitask.relations_layers module</a></li>
<li class="toctree-l3"><a class="reference internal" href="gliner.modeling.multitask.triples_layers.html">gliner.modeling.multitask.triples_layers module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gliner.modeling.base.html">gliner.modeling.base module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gliner.modeling.decoder.html">gliner.modeling.decoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gliner.modeling.encoder.html">gliner.modeling.encoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gliner.modeling.layers.html">gliner.modeling.layers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gliner.modeling.loss_functions.html">gliner.modeling.loss_functions module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gliner.modeling.outputs.html">gliner.modeling.outputs module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gliner.modeling.scorers.html">gliner.modeling.scorers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gliner.modeling.span_rep.html">gliner.modeling.span_rep module</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">gliner.modeling.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gliner.data_processing.html">gliner.data_processing package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gliner.data_processing.collator.html">gliner.data_processing.collator module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gliner.data_processing.processor.html">gliner.data_processing.processor module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gliner.data_processing.tokenizer.html">gliner.data_processing.tokenizer module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gliner.data_processing.utils.html">gliner.data_processing.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gliner.evaluation.html">gliner.evaluation package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gliner.evaluation.evaluate_ner.html">gliner.evaluation.evaluate_ner module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gliner.evaluation.evaluator.html">gliner.evaluation.evaluator module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gliner.evaluation.utils.html">gliner.evaluation.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gliner.onnx.html">gliner.onnx package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gliner.onnx.model.html">gliner.onnx.model module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gliner.decoding.html">gliner.decoding package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gliner.decoding.trie.html">gliner.decoding.trie package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gliner.decoding.trie.labels_trie.html">gliner.decoding.trie.labels_trie module</a></li>
<li class="toctree-l3"><a class="reference internal" href="gliner.decoding.trie.python_labels_trie.html">gliner.decoding.trie.python_labels_trie module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gliner.decoding.decoder.html">gliner.decoding.decoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gliner.decoding.utils.html">gliner.decoding.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gliner.utils.html">gliner.utils module</a></li>
</ul>

        </div>
      </div>
    </div>
  </aside>
  <div class="lside-overlay js-menu" role="button" aria-label="Close left sidebar" aria-controls="lside" aria-expanded="false"></div>
  <aside id="rside" class="sy-rside pb-3 w-64 shrink-0 order-last">
    <button class="rside-close js-menu xl:hidden" aria-label="Close Table of Contents" type="button" aria-controls="rside" aria-expanded="false">
      <i class="i-lucide close"></i>
    </button>
    <div class="sy-scrollbar sy-rside-inner px-6 xl:top-16 xl:sticky xl:pl-0 pt-6 pb-4"><div class="localtoc"><h3>On this page</h3><ul>
<li><a class="reference internal" href="#gliner.modeling.utils.extract_word_embeddings"><code class="docutils literal notranslate"><span class="pre">extract_word_embeddings()</span></code></a></li>
<li><a class="reference internal" href="#gliner.modeling.utils.extract_prompt_features"><code class="docutils literal notranslate"><span class="pre">extract_prompt_features()</span></code></a></li>
<li><a class="reference internal" href="#gliner.modeling.utils.extract_prompt_features_and_word_embeddings"><code class="docutils literal notranslate"><span class="pre">extract_prompt_features_and_word_embeddings()</span></code></a></li>
<li><a class="reference internal" href="#gliner.modeling.utils.build_entity_pairs"><code class="docutils literal notranslate"><span class="pre">build_entity_pairs()</span></code></a></li>
<li><a class="reference internal" href="#gliner.modeling.utils.extract_spans_from_tokens"><code class="docutils literal notranslate"><span class="pre">extract_spans_from_tokens()</span></code></a></li>
</ul>
</div><div id="ethical-ad-placement" data-ea-publisher="readthedocs"></div></div>
  </aside>
  <div class="rside-overlay js-menu" role="button" aria-label="Close Table of Contents" aria-controls="rside" aria-expanded="false"></div>
  <main class="sy-main w-full max-sm:max-w-full print:pt-6">
<div class="sy-breadcrumbs" role="navigation">
  <div class="sy-breadcrumbs-inner flex items-center">
    <div class="md:hidden mr-3">
      <button class="js-menu" aria-label="Menu" type="button" aria-controls="lside" aria-expanded="false">
        <i class="i-lucide menu"></i>
      </button>
    </div>
    <ol class="flex-1" itemscope itemtype="https://schema.org/BreadcrumbList"><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <a itemprop="item" href="../index.html"><span itemprop="name">Home</span></a>
        <span>/</span>
        <meta itemprop="position" content="1" />
      </li><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <a itemprop="item" href="gliner.modeling.html"><span itemprop="name">gliner.modeling package</span></a>
        <span>/</span>
        <meta itemprop="position" content="2" />
      </li><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <strong itemprop="name">gliner.modeling.utils module</strong>
        <meta itemprop="position" content="3" />
      </li></ol>
    <div class="xl:hidden ml-1">
      <button class="js-menu" aria-label="Show table of contents" type="button" aria-controls="rside"
        aria-expanded="false">
        <i class="i-lucide outdent"></i>
      </button>
    </div>
  </div>
</div><div class="flex flex-col break-words justify-between">
      <div class="min-w-0 max-w-6xl px-6 pb-6 pt-8 xl:px-12">
        <article class="yue" role="main">
          <section id="module-gliner.modeling.utils">
<span id="gliner-modeling-utils-module"></span><h1>gliner.modeling.utils module<a class="headerlink" href="#module-gliner.modeling.utils" title="Link to this heading">¬∂</a></h1>
<dl class="py function">
<dt class="sig sig-object py" id="gliner.modeling.utils.extract_word_embeddings">
<span class="sig-prename descclassname"><span class="pre">gliner.modeling.utils.</span></span><span class="sig-name descname"><span class="pre">extract_word_embeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">token_embeds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">words_mask</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_mask</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_text_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embed_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">text_lengths</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gliner/modeling/utils.html#extract_word_embeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gliner.modeling.utils.extract_word_embeddings" title="Link to this definition">¬∂</a></dt>
<dd><p>Extract word-level embeddings from subword token embeddings.</p>
<p>Maps subword token embeddings back to word-level embeddings using a word mask
that indicates which subword token corresponds to which word. Only the first
subword token of each word is typically used for the word representation.</p>
<p>This is essential for span-based NER where predictions are made at the word
level but the transformer operates on subword tokens.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>token_embeds</strong> (<em>Tensor</em>) ‚Äì Subword token embeddings from transformer.
Shape: (batch_size, seq_len, embed_dim)</p></li>
<li><p><strong>words_mask</strong> (<em>Tensor</em>) ‚Äì Mask mapping subword positions to word indices. Non-zero values
indicate the word index (1-indexed). Zero values are special tokens or
continuation subwords to ignore.
Shape: (batch_size, seq_len)</p></li>
<li><p><strong>attention_mask</strong> (<em>Tensor</em>) ‚Äì Standard attention mask from tokenizer.
Shape: (batch_size, seq_len)</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) ‚Äì Size of the batch.</p></li>
<li><p><strong>max_text_length</strong> (<em>int</em>) ‚Äì Maximum number of words across all examples in batch.</p></li>
<li><p><strong>embed_dim</strong> (<em>int</em>) ‚Äì Embedding dimension size.</p></li>
<li><p><strong>text_lengths</strong> (<em>Tensor</em>) ‚Äì Number of words in each example.
Shape: (batch_size, 1) or (batch_size,)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>words_embedding: Word-level embeddings extracted from token embeddings.
Shape: (batch_size, max_text_length, embed_dim)</p></li>
<li><p>mask: Boolean mask indicating valid word positions (True) vs padding (False).
Shape: (batch_size, max_text_length)</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple containing</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="gliner.modeling.utils.extract_prompt_features">
<span class="sig-prename descclassname"><span class="pre">gliner.modeling.utils.</span></span><span class="sig-name descname"><span class="pre">extract_prompt_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">class_token_index</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_embeds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_ids</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_mask</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embed_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embed_ent_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gliner/modeling/utils.html#extract_prompt_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gliner.modeling.utils.extract_prompt_features" title="Link to this definition">¬∂</a></dt>
<dd><p>Extract prompt/entity type embeddings from special class tokens.</p>
<p>Extracts embeddings for entity types or other prompt elements that are marked
with special class tokens (e.g., [ENT] tokens). These embeddings represent
the entity types that the model should extract.</p>
<dl class="simple">
<dt>In prompt-based NER, the input is typically:</dt><dd><p>[ENT] Person [ENT] Organization [SEP] John works at Google</p>
</dd>
</dl>
<p>This function extracts the embeddings corresponding to the [ENT] tokens
(or the tokens immediately after them if embed_ent_token=False).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>class_token_index</strong> (<em>int</em>) ‚Äì Token ID of the special class token to extract
(e.g., token ID for [ENT]).</p></li>
<li><p><strong>token_embeds</strong> (<em>Tensor</em>) ‚Äì Token embeddings from transformer.
Shape: (batch_size, seq_len, embed_dim)</p></li>
<li><p><strong>input_ids</strong> (<em>Tensor</em>) ‚Äì Token IDs from tokenizer.
Shape: (batch_size, seq_len)</p></li>
<li><p><strong>attention_mask</strong> (<em>Tensor</em>) ‚Äì Standard attention mask from tokenizer.
Shape: (batch_size, seq_len)</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) ‚Äì Size of the batch.</p></li>
<li><p><strong>embed_dim</strong> (<em>int</em>) ‚Äì Embedding dimension size.</p></li>
<li><p><strong>embed_ent_token</strong> (<em>bool</em>) ‚Äì If True, use the [ENT] token embedding itself.
If False, use the embedding of the token immediately after [ENT]
(i.e., the entity type name token). Default: True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>prompts_embedding: Embeddings for each prompt/entity type.
Shape: (batch_size, max_num_types, embed_dim)
where max_num_types is the maximum number of entity types
across examples in the batch.</p></li>
<li><p>prompts_embedding_mask: Mask indicating valid prompt positions
(True) vs padding (False).
Shape: (batch_size, max_num_types)</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple containing</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="gliner.modeling.utils.extract_prompt_features_and_word_embeddings">
<span class="sig-prename descclassname"><span class="pre">gliner.modeling.utils.</span></span><span class="sig-name descname"><span class="pre">extract_prompt_features_and_word_embeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">class_token_index</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">token_embeds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_ids</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_mask</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">text_lengths</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">words_mask</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embed_ent_token</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gliner/modeling/utils.html#extract_prompt_features_and_word_embeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gliner.modeling.utils.extract_prompt_features_and_word_embeddings" title="Link to this definition">¬∂</a></dt>
<dd><p>Extract both prompt embeddings and word embeddings in one call.</p>
<p>Convenience function that combines extract_prompt_features and
extract_word_embeddings to get both prompt/entity type embeddings
and word-level text embeddings from a single set of token embeddings.</p>
<p>This is the typical use case for prompt-based NER where you need both:
1. Entity type embeddings (from prompt tokens like [ENT])
2. Word-level text embeddings (from the actual text tokens)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>class_token_index</strong> (<em>int</em>) ‚Äì Token ID of the special class token (e.g., [ENT]).</p></li>
<li><p><strong>token_embeds</strong> (<em>Tensor</em>) ‚Äì Token embeddings from transformer.
Shape: (batch_size, seq_len, embed_dim)</p></li>
<li><p><strong>input_ids</strong> (<em>Tensor</em>) ‚Äì Token IDs from tokenizer.
Shape: (batch_size, seq_len)</p></li>
<li><p><strong>attention_mask</strong> (<em>Tensor</em>) ‚Äì Standard attention mask from tokenizer.
Shape: (batch_size, seq_len)</p></li>
<li><p><strong>text_lengths</strong> (<em>Tensor</em>) ‚Äì Number of words in each example.
Shape: (batch_size, 1) or (batch_size,)</p></li>
<li><p><strong>words_mask</strong> (<em>Tensor</em>) ‚Äì Mask mapping subword positions to word indices.
Shape: (batch_size, seq_len)</p></li>
<li><p><strong>embed_ent_token</strong> (<em>bool</em>) ‚Äì If True, use [ENT] token embedding. If False,
use the token after [ENT] (the entity type name). Default: True.</p></li>
<li><p><strong>**kwargs</strong> ‚Äì Additional keyword arguments passed to extract_prompt_features.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>prompts_embedding: Entity type embeddings.
Shape: (batch_size, max_num_types, embed_dim)</p></li>
<li><p>prompts_embedding_mask: Mask for valid entity type positions.
Shape: (batch_size, max_num_types)</p></li>
<li><p>words_embedding: Word-level text embeddings.
Shape: (batch_size, max_text_length, embed_dim)</p></li>
<li><p>mask: Mask for valid word positions.
Shape: (batch_size, max_text_length)</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple containing</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="gliner.modeling.utils.build_entity_pairs">
<span class="sig-prename descclassname"><span class="pre">gliner.modeling.utils.</span></span><span class="sig-name descname"><span class="pre">build_entity_pairs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">adj</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">span_rep</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gliner/modeling/utils.html#build_entity_pairs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gliner.modeling.utils.build_entity_pairs" title="Link to this definition">¬∂</a></dt>
<dd><p>Build entity pairs for relation extraction based on adjacency scores.</p>
<p>Extracts entity pairs (head, tail) where the adjacency score exceeds a
threshold, and retrieves their corresponding embeddings. This is used in
relation extraction to select which entity pairs should be classified for
relation types.</p>
<p>The function considers ALL directed pairs (i,j) where i‚â†j, not just the
upper triangle, since relation direction matters (e.g., ‚Äúfounded‚Äù vs
‚Äúfounded_by‚Äù have opposite directions).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>adj</strong> (<em>Tensor</em>) ‚Äì Adjacency matrix with scores or probabilities for entity pairs.
Shape: (batch_size, num_entities, num_entities)
The diagonal (self-pairs) is ignored. Values &gt; threshold indicate
potential relations.</p></li>
<li><p><strong>span_rep</strong> (<em>Tensor</em>) ‚Äì Entity/span embeddings for each entity in the batch.
Shape: (batch_size, num_entities, embed_dim)</p></li>
<li><p><strong>threshold</strong> (<em>float</em>) ‚Äì Minimum adjacency score to consider a pair as a potential
relation. Pairs with adj[i,j] &gt; threshold are kept. Default: 0.5.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>pair_idx: Indices of (head, tail) entity pairs.
Shape: (batch_size, max_pairs, 2)
Values are entity indices, or -1 for padding positions.</p></li>
<li><p>pair_mask: Boolean mask indicating valid pairs (True) vs padding (False).
Shape: (batch_size, max_pairs)</p></li>
<li><p>head_rep: Embeddings of head entities for each pair.
Shape: (batch_size, max_pairs, embed_dim)</p></li>
<li><p>tail_rep: Embeddings of tail entities for each pair.
Shape: (batch_size, max_pairs, embed_dim)</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple containing</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="gliner.modeling.utils.extract_spans_from_tokens">
<span class="sig-prename descclassname"><span class="pre">gliner.modeling.utils.</span></span><span class="sig-name descname"><span class="pre">extract_spans_from_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scores</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gliner/modeling/utils.html#extract_spans_from_tokens"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gliner.modeling.utils.extract_spans_from_tokens" title="Link to this definition">¬∂</a></dt>
<dd><p>Extract entity spans from BIO-style token predictions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scores</strong> (<em>Tensor</em>) ‚Äì (B, W, C, 3) - logits for [start, end, inside]</p></li>
<li><p><strong>labels</strong> (<em>Tensor</em><em> | </em><em>None</em>) ‚Äì Optional (B, W, C, 3) - ground truth labels</p></li>
<li><p><strong>threshold</strong> (<em>float</em>) ‚Äì Confidence threshold (used when labels is None)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(B, N, 2) - [start, end] indices, padded
span_mask: (B, N) - validity mask</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>span_idx</p>
</dd>
</dl>
</dd></dl>

</section>

        </article><button class="back-to-top" type="button">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
  </svg>
  <span>Back to top</span>
</button><div class="navigation flex print:hidden"><div class="navigation-prev">
    <a href="gliner.modeling.span_rep.html">
      <i class="i-lucide chevron-left"></i>
      <div class="page-info">
        <span>Previous</span><div class="title">gliner.modeling.span_rep module</div></div>
    </a>
  </div><div class="navigation-next">
    <a href="gliner.data_processing.html">
      <div class="page-info">
        <span>Next</span>
        <div class="title">gliner.data_processing package</div>
      </div>
      <i class="i-lucide chevron-right"></i>
    </a>
  </div></div></div>
    </div>
  </main>
</div>
<footer class="sy-foot">
  <div class="sy-foot-inner sy-container mx-auto">
    <div class="sy-foot-reserved md:flex justify-between items-center">
      <div class="sy-foot-copyright"><p>2025, GLiNER community</p>
  
  <p>
    Made with
    
    <a href="https://www.sphinx-doc.org/">Sphinx</a> and
    
    <a href="https://shibuya.lepture.com">Shibuya theme</a>.
  </p>
</div>
      <div class="sy-foot-socials"></div>
    </div>
  </div>
</footer>
      <script src="../_static/documentation_options.js?v=dc91f075"></script>
      <script src="../_static/doctools.js?v=9a2dae69"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../_static/shibuya.js?v=9b0e4dde"></script></body>
</html>