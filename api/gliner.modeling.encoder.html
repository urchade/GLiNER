<!DOCTYPE html>
<html lang="en" data-accent-color="violet" data-content_root="../">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>gliner.modeling.encoder module - Home 0.2.24 documentation</title><link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="gliner.modeling.layers module" href="gliner.modeling.layers.html" /><link rel="prev" title="gliner.modeling.decoder module" href="gliner.modeling.decoder.html" /><script>
    function setColorMode(t){let e=document.documentElement;e.setAttribute("data-color-mode",t);let a=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,s=t;"auto"===t&&(s=a?"dark":"light"),"light"===s?(e.classList.remove("dark"),e.classList.add("light")):(e.classList.remove("light"),e.classList.add("dark"))}
    setColorMode(localStorage._theme||"auto");
  </script><link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=e1a1ceaf" />
    <link rel="stylesheet" type="text/css" href="../_static/shibuya.css?v=d140fbf8" />
    <link media="print" rel="stylesheet" type="text/css" href="../_static/print.css?v=20ff2c19" />
    <link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
<style>
:root {
  --sy-f-text: "Inter", var(--sy-f-sys), var(--sy-f-cjk), sans-serif;
  --sy-f-heading: "Inter", var(--sy-f-sys), var(--sy-f-cjk), sans-serif;
}
</style>
    <meta property="og:type" content="website"/><meta property="og:title" content="gliner.modeling.encoder module"/>
<meta name="twitter:card" content="summary"/>
  </head>
<body><div class="sy-head">
  <div class="sy-head-blur"></div>
  <div class="sy-head-inner sy-container mx-auto">
    <a class="sy-head-brand" href="../index.html">
      
      
      <strong>Home</strong>
    </a>
    <div class="sy-head-nav" id="head-nav">
      <nav class="sy-head-links"></nav>
      <div class="sy-head-extra flex items-center print:hidden"><form class="searchbox flex items-center" action="../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <kbd>/</kbd>
</form><div class="sy-head-socials"></div></div>
    </div>
    <div class="sy-head-actions flex items-center shrink-0 print:hidden"><button class="js-theme theme-switch flex items-center"
data-aria-auto="Switch to light color mode"
data-aria-light="Switch to dark color mode"
data-aria-dark="Switch to auto color mode">
<i class="i-lucide theme-icon"></i>
</button><button class="md:hidden flex items-center js-menu" aria-label="Menu" type="button" aria-controls="head-nav" aria-expanded="false">
        <div class="hamburger">
          <span class="hamburger_1"></span>
          <span class="hamburger_2"></span>
          <span class="hamburger_3"></span>
        </div>
      </button>
    </div>
  </div>
</div>
<div class="sy-page sy-container flex mx-auto">
  <aside id="lside" class="sy-lside md:w-72 md:shrink-0 print:hidden">
    <div class="sy-lside-inner md:sticky">
      <div class="sy-scrollbar p-6">
        <div class="globaltoc" data-expand-depth="0"><p class="caption" role="heading" aria-level="3"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intro.html">Introduction to ðŸ‘‘ GLiNER</a></li>
<li class="toctree-l1"><a class="reference internal" href="../instalation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../usage.html">Advanced Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../configs.html">Components &amp; Configs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training.html">Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../architectures.html">Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../convert_to_onnx.html">ONNX Export &amp; Deployment</a></li>
</ul>
<p class="caption" role="heading" aria-level="3"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="gliner.model.html">gliner.model module</a></li>
<li class="toctree-l1"><a class="reference internal" href="gliner.config.html">gliner.config module</a></li>
<li class="toctree-l1"><a class="reference internal" href="gliner.training.html">gliner.training package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gliner.training.trainer.html">gliner.training.trainer module</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="gliner.modeling.html">gliner.modeling package</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="gliner.modeling.multitask.html">gliner.modeling.multitask package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gliner.modeling.multitask.relations_layers.html">gliner.modeling.multitask.relations_layers module</a></li>
<li class="toctree-l3"><a class="reference internal" href="gliner.modeling.multitask.triples_layers.html">gliner.modeling.multitask.triples_layers module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gliner.modeling.base.html">gliner.modeling.base module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gliner.modeling.decoder.html">gliner.modeling.decoder module</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">gliner.modeling.encoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gliner.modeling.layers.html">gliner.modeling.layers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gliner.modeling.loss_functions.html">gliner.modeling.loss_functions module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gliner.modeling.outputs.html">gliner.modeling.outputs module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gliner.modeling.scorers.html">gliner.modeling.scorers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gliner.modeling.span_rep.html">gliner.modeling.span_rep module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gliner.modeling.utils.html">gliner.modeling.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gliner.data_processing.html">gliner.data_processing package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gliner.data_processing.collator.html">gliner.data_processing.collator module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gliner.data_processing.processor.html">gliner.data_processing.processor module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gliner.data_processing.tokenizer.html">gliner.data_processing.tokenizer module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gliner.data_processing.utils.html">gliner.data_processing.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gliner.evaluation.html">gliner.evaluation package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gliner.evaluation.evaluate_ner.html">gliner.evaluation.evaluate_ner module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gliner.evaluation.evaluator.html">gliner.evaluation.evaluator module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gliner.evaluation.utils.html">gliner.evaluation.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gliner.onnx.html">gliner.onnx package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gliner.onnx.model.html">gliner.onnx.model module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gliner.decoding.html">gliner.decoding package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="gliner.decoding.trie.html">gliner.decoding.trie package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="gliner.decoding.trie.labels_trie.html">gliner.decoding.trie.labels_trie module</a></li>
<li class="toctree-l3"><a class="reference internal" href="gliner.decoding.trie.python_labels_trie.html">gliner.decoding.trie.python_labels_trie module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="gliner.decoding.decoder.html">gliner.decoding.decoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="gliner.decoding.utils.html">gliner.decoding.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="gliner.utils.html">gliner.utils module</a></li>
</ul>

        </div>
      </div>
    </div>
  </aside>
  <div class="lside-overlay js-menu" role="button" aria-label="Close left sidebar" aria-controls="lside" aria-expanded="false"></div>
  <aside id="rside" class="sy-rside pb-3 w-64 shrink-0 order-last">
    <button class="rside-close js-menu xl:hidden" aria-label="Close Table of Contents" type="button" aria-controls="rside" aria-expanded="false">
      <i class="i-lucide close"></i>
    </button>
    <div class="sy-scrollbar sy-rside-inner px-6 xl:top-16 xl:sticky xl:pl-0 pt-6 pb-4"><div class="localtoc"><h3>On this page</h3><ul>
<li><a class="reference internal" href="#gliner.modeling.encoder.Transformer"><code class="docutils literal notranslate"><span class="pre">Transformer</span></code></a><ul>
<li><a class="reference internal" href="#gliner.modeling.encoder.Transformer.model"><code class="docutils literal notranslate">model</span></code></a></li>
<li><a class="reference internal" href="#gliner.modeling.encoder.Transformer.layers_fuser"><code class="docutils literal notranslate">layers_fuser</span></code></a></li>
<li><a class="reference internal" href="#gliner.modeling.encoder.Transformer.config"><code class="docutils literal notranslate">config</span></code></a></li>
<li><a class="reference internal" href="#gliner.modeling.encoder.Transformer.__init__"><code class="docutils literal notranslate">__init__()</span></code></a></li>
<li><a class="reference internal" href="#gliner.modeling.encoder.Transformer.forward"><code class="docutils literal notranslate">forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#gliner.modeling.encoder.Encoder"><code class="docutils literal notranslate"><span class="pre">Encoder</span></code></a><ul>
<li><a class="reference internal" href="#gliner.modeling.encoder.Encoder.bert_layer"><code class="docutils literal notranslate">bert_layer</span></code></a></li>
<li><a class="reference internal" href="#gliner.modeling.encoder.Encoder.projection"><code class="docutils literal notranslate">projection</span></code></a></li>
<li><a class="reference internal" href="#gliner.modeling.encoder.Encoder.__init__"><code class="docutils literal notranslate">__init__()</span></code></a></li>
<li><a class="reference internal" href="#gliner.modeling.encoder.Encoder.resize_token_embeddings"><code class="docutils literal notranslate">resize_token_embeddings()</span></code></a></li>
<li><a class="reference internal" href="#gliner.modeling.encoder.Encoder.get_input_embeddings"><code class="docutils literal notranslate">get_input_embeddings()</span></code></a></li>
<li><a class="reference internal" href="#gliner.modeling.encoder.Encoder.encode_text"><code class="docutils literal notranslate">encode_text()</span></code></a></li>
<li><a class="reference internal" href="#gliner.modeling.encoder.Encoder.forward"><code class="docutils literal notranslate">forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#gliner.modeling.encoder.BiEncoder"><code class="docutils literal notranslate"><span class="pre">BiEncoder</span></code></a><ul>
<li><a class="reference internal" href="#gliner.modeling.encoder.BiEncoder.bert_layer"><code class="docutils literal notranslate">bert_layer</span></code></a></li>
<li><a class="reference internal" href="#gliner.modeling.encoder.BiEncoder.projection"><code class="docutils literal notranslate">projection</span></code></a></li>
<li><a class="reference internal" href="#gliner.modeling.encoder.BiEncoder.labels_encoder"><code class="docutils literal notranslate">labels_encoder</span></code></a></li>
<li><a class="reference internal" href="#gliner.modeling.encoder.BiEncoder.labels_projection"><code class="docutils literal notranslate">labels_projection</span></code></a></li>
<li><a class="reference internal" href="#gliner.modeling.encoder.BiEncoder.__init__"><code class="docutils literal notranslate">__init__()</span></code></a></li>
<li><a class="reference internal" href="#gliner.modeling.encoder.BiEncoder.mean_pooling"><code class="docutils literal notranslate">mean_pooling()</span></code></a></li>
<li><a class="reference internal" href="#gliner.modeling.encoder.BiEncoder.encode_labels"><code class="docutils literal notranslate">encode_labels()</span></code></a></li>
<li><a class="reference internal" href="#gliner.modeling.encoder.BiEncoder.forward"><code class="docutils literal notranslate">forward()</span></code></a></li>
</ul>
</li>
</ul>
</div><div id="ethical-ad-placement" data-ea-publisher="readthedocs"></div></div>
  </aside>
  <div class="rside-overlay js-menu" role="button" aria-label="Close Table of Contents" aria-controls="rside" aria-expanded="false"></div>
  <main class="sy-main w-full max-sm:max-w-full print:pt-6">
<div class="sy-breadcrumbs" role="navigation">
  <div class="sy-breadcrumbs-inner flex items-center">
    <div class="md:hidden mr-3">
      <button class="js-menu" aria-label="Menu" type="button" aria-controls="lside" aria-expanded="false">
        <i class="i-lucide menu"></i>
      </button>
    </div>
    <ol class="flex-1" itemscope itemtype="https://schema.org/BreadcrumbList"><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <a itemprop="item" href="../index.html"><span itemprop="name">Home</span></a>
        <span>/</span>
        <meta itemprop="position" content="1" />
      </li><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <a itemprop="item" href="gliner.modeling.html"><span itemprop="name">gliner.modeling package</span></a>
        <span>/</span>
        <meta itemprop="position" content="2" />
      </li><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <strong itemprop="name">gliner.modeling.encoder module</strong>
        <meta itemprop="position" content="3" />
      </li></ol>
    <div class="xl:hidden ml-1">
      <button class="js-menu" aria-label="Show table of contents" type="button" aria-controls="rside"
        aria-expanded="false">
        <i class="i-lucide outdent"></i>
      </button>
    </div>
  </div>
</div><div class="flex flex-col break-words justify-between">
      <div class="min-w-0 max-w-6xl px-6 pb-6 pt-8 xl:px-12">
        <article class="yue" role="main">
          <section id="module-gliner.modeling.encoder">
<span id="gliner-modeling-encoder-module"></span><h1>gliner.modeling.encoder module<a class="headerlink" href="#module-gliner.modeling.encoder" title="Link to this heading">Â¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="gliner.modeling.encoder.Transformer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">gliner.modeling.encoder.</span></span><span class="sig-name descname"><span class="pre">Transformer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">from_pretrained</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels_encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gliner/modeling/encoder.html#Transformer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gliner.modeling.encoder.Transformer" title="Link to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Flexible transformer wrapper supporting multiple architectures and configurations.</p>
<p>This class provides a unified interface for various transformer models including
encoder-only (BERT, DeBERTa), encoder-decoder (T5), and decoder-only models
(LLaMA, Mistral) with bidirectional adaptations. It handles model initialization,
adapter loading, and specialized forward passes for different architectures.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="gliner.modeling.encoder.Transformer.model">
<span class="sig-name descname"><span class="pre">model</span></span><a class="headerlink" href="#gliner.modeling.encoder.Transformer.model" title="Link to this definition">Â¶</a></dt>
<dd><p>The underlying transformer model instance.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="gliner.modeling.encoder.Transformer.layers_fuser">
<span class="sig-name descname"><span class="pre">layers_fuser</span></span><a class="headerlink" href="#gliner.modeling.encoder.Transformer.layers_fuser" title="Link to this definition">Â¶</a></dt>
<dd><p>Optional layer fusion module when config.fuse_layers is True.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="gliner.modeling.encoder.Transformer.config">
<span class="sig-name descname"><span class="pre">config</span></span><a class="headerlink" href="#gliner.modeling.encoder.Transformer.config" title="Link to this definition">Â¶</a></dt>
<dd><p>Configuration object containing model hyperparameters.</p>
</dd></dl>

<p>Initializes the transformer wrapper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_name</strong> (<em>str</em>) â€“ Name or path of the pretrained model to load.</p></li>
<li><p><strong>config</strong> (<em>Any</em>) â€“ Configuration object containing model hyperparameters. Must have
attributes like <cite>encoder_config</cite>, <cite>labels_encoder_config</cite>, <cite>vocab_size</cite>,
<cite>_attn_implementation</cite>, and <cite>fuse_layers</cite>.</p></li>
<li><p><strong>from_pretrained</strong> (<em>bool</em>) â€“ If True, loads pretrained weights. If False, initializes
from config only. Defaults to False.</p></li>
<li><p><strong>labels_encoder</strong> (<em>bool</em>) â€“ If True, initializes as a labels encoder using
<cite>config.labels_encoder_config</cite>. Defaults to False.</p></li>
<li><p><strong>cache_dir</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>None</em>) â€“ Optional directory for caching downloaded models. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="gliner.utils.html#gliner.utils.MissedPackageException" title="gliner.utils.MissedPackageException"><strong>MissedPackageException</strong></a> â€“ If required packages (llm2vec, peft) are not installed
    when needed for specific model types.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="gliner.modeling.encoder.Transformer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">from_pretrained</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels_encoder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gliner/modeling/encoder.html#Transformer.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gliner.modeling.encoder.Transformer.__init__" title="Link to this definition">Â¶</a></dt>
<dd><p>Initializes the transformer wrapper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_name</strong> (<em>str</em>) â€“ Name or path of the pretrained model to load.</p></li>
<li><p><strong>config</strong> (<em>Any</em>) â€“ Configuration object containing model hyperparameters. Must have
attributes like <cite>encoder_config</cite>, <cite>labels_encoder_config</cite>, <cite>vocab_size</cite>,
<cite>_attn_implementation</cite>, and <cite>fuse_layers</cite>.</p></li>
<li><p><strong>from_pretrained</strong> (<em>bool</em>) â€“ If True, loads pretrained weights. If False, initializes
from config only. Defaults to False.</p></li>
<li><p><strong>labels_encoder</strong> (<em>bool</em>) â€“ If True, initializes as a labels encoder using
<cite>config.labels_encoder_config</cite>. Defaults to False.</p></li>
<li><p><strong>cache_dir</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>None</em>) â€“ Optional directory for caching downloaded models. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="gliner.utils.html#gliner.utils.MissedPackageException" title="gliner.utils.MissedPackageException"><strong>MissedPackageException</strong></a> â€“ If required packages (llm2vec, peft) are not installed
    when needed for specific model types.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gliner.modeling.encoder.Transformer.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gliner/modeling/encoder.html#Transformer.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gliner.modeling.encoder.Transformer.forward" title="Link to this definition">Â¶</a></dt>
<dd><p>Forward pass through the transformer model.</p>
<p>Handles different attention mask configurations and model architectures,
including support for pair attention masks for packed sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> (<em>Any</em>) â€“ Variable positional arguments passed to the model.</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em>) â€“ <p>Variable keyword arguments. Special arguments include:
- pair_attention_mask: Optional pairwise attention mask of shape</p>
<blockquote>
<div><p>(batch_size, seq_len, seq_len) for packed sequences.</p>
</div></blockquote>
<ul>
<li><p>attention_mask: Standard attention mask of shape (batch_size, seq_len).</p></li>
<li><p>input_ids: Input token IDs of shape (batch_size, seq_len).</p></li>
<li><p>Other model-specific arguments.</p></li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Encoded representations of shape (batch_size, seq_len, hidden_size).
If config.fuse_layers is True, returns fused layer outputs, otherwise
returns the last hidden state.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="gliner.modeling.encoder.Encoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">gliner.modeling.encoder.</span></span><span class="sig-name descname"><span class="pre">Encoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">from_pretrained</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gliner/modeling/encoder.html#Encoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gliner.modeling.encoder.Encoder" title="Link to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Standard encoder module wrapping a transformer model with optional projection.</p>
<p>This class provides a high-level interface for encoding text sequences, including
support for inference-time packing to improve throughput. It handles embedding
extraction and optional projection to a different hidden size.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="gliner.modeling.encoder.Encoder.bert_layer">
<span class="sig-name descname"><span class="pre">bert_layer</span></span><a class="headerlink" href="#gliner.modeling.encoder.Encoder.bert_layer" title="Link to this definition">Â¶</a></dt>
<dd><p>The underlying Transformer instance.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="gliner.modeling.encoder.Encoder.projection">
<span class="sig-name descname"><span class="pre">projection</span></span><a class="headerlink" href="#gliner.modeling.encoder.Encoder.projection" title="Link to this definition">Â¶</a></dt>
<dd><p>Optional linear projection layer when config.hidden_size differs
from the modelâ€™s native hidden size.</p>
</dd></dl>

<p>Initializes the encoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config</strong> (<em>Any</em>) â€“ Configuration object containing model hyperparameters including
<cite>model_name</cite>, <cite>hidden_size</cite>, and transformer-specific settings.</p></li>
<li><p><strong>from_pretrained</strong> (<em>bool</em>) â€“ If True, loads pretrained weights for the transformer.
Defaults to False.</p></li>
<li><p><strong>cache_dir</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>None</em>) â€“ Optional directory for caching downloaded models. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="gliner.modeling.encoder.Encoder.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">from_pretrained</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gliner/modeling/encoder.html#Encoder.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gliner.modeling.encoder.Encoder.__init__" title="Link to this definition">Â¶</a></dt>
<dd><p>Initializes the encoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config</strong> (<em>Any</em>) â€“ Configuration object containing model hyperparameters including
<cite>model_name</cite>, <cite>hidden_size</cite>, and transformer-specific settings.</p></li>
<li><p><strong>from_pretrained</strong> (<em>bool</em>) â€“ If True, loads pretrained weights for the transformer.
Defaults to False.</p></li>
<li><p><strong>cache_dir</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>None</em>) â€“ Optional directory for caching downloaded models. Defaults to None.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gliner.modeling.encoder.Encoder.resize_token_embeddings">
<span class="sig-name descname"><span class="pre">resize_token_embeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">new_num_tokens</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_to_multiple_of</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gliner/modeling/encoder.html#Encoder.resize_token_embeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gliner.modeling.encoder.Encoder.resize_token_embeddings" title="Link to this definition">Â¶</a></dt>
<dd><p>Resizes token embeddings to accommodate new vocabulary size.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>new_num_tokens</strong> (<em>int</em>) â€“ New vocabulary size.</p></li>
<li><p><strong>pad_to_multiple_of</strong> (<em>int</em><em> | </em><em>None</em>) â€“ Optional value to pad vocabulary size to a multiple.
Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The resized embedding layer.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Embedding</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gliner.modeling.encoder.Encoder.get_input_embeddings">
<span class="sig-name descname"><span class="pre">get_input_embeddings</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gliner/modeling/encoder.html#Encoder.get_input_embeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gliner.modeling.encoder.Encoder.get_input_embeddings" title="Link to this definition">Â¶</a></dt>
<dd><p>Gets the input embedding layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The modelâ€™s input embedding layer.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Embedding</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gliner.modeling.encoder.Encoder.encode_text">
<span class="sig-name descname"><span class="pre">encode_text</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_ids</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_mask</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gliner/modeling/encoder.html#Encoder.encode_text"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gliner.modeling.encoder.Encoder.encode_text" title="Link to this definition">Â¶</a></dt>
<dd><p>Encodes input text sequences into contextualized embeddings.</p>
<p>Supports inference-time packing to batch multiple variable-length sequences
efficiently when packing_config is provided and not in training mode.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<em>Tensor</em>) â€“ Input token IDs of shape (batch_size, seq_len).</p></li>
<li><p><strong>attention_mask</strong> (<em>Tensor</em>) â€“ Attention mask of shape (batch_size, seq_len) where 1
indicates valid tokens and 0 indicates padding.</p></li>
<li><p><strong>*args</strong> (<em>Any</em>) â€“ Additional positional arguments passed to the transformer.</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em>) â€“ Additional keyword arguments including:
- packing_config: Optional InferencePackingConfig for efficient batching.
- pair_attention_mask: Optional pairwise attention mask for packed sequences.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Token embeddings of shape (batch_size, seq_len, hidden_size).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gliner.modeling.encoder.Encoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gliner/modeling/encoder.html#Encoder.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gliner.modeling.encoder.Encoder.forward" title="Link to this definition">Â¶</a></dt>
<dd><p>Forward pass through the encoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> (<em>Any</em>) â€“ Positional arguments passed to encode_text.</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em>) â€“ Keyword arguments passed to encode_text.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Token embeddings of shape (batch_size, seq_len, hidden_size).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="gliner.modeling.encoder.BiEncoder">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">gliner.modeling.encoder.</span></span><span class="sig-name descname"><span class="pre">BiEncoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">from_pretrained</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gliner/modeling/encoder.html#BiEncoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gliner.modeling.encoder.BiEncoder" title="Link to this definition">Â¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#gliner.modeling.encoder.Encoder" title="gliner.modeling.encoder.Encoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">Encoder</span></code></a></p>
<p>Bi-encoder architecture with separate encoders for text and labels.</p>
<p>This encoder processes text sequences and label sequences through potentially
different transformer models, producing aligned representations for both. The
label representations are mean-pooled to create fixed-size embeddings.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="gliner.modeling.encoder.BiEncoder.bert_layer">
<span class="sig-name descname"><span class="pre">bert_layer</span></span><a class="headerlink" href="#gliner.modeling.encoder.BiEncoder.bert_layer" title="Link to this definition">Â¶</a></dt>
<dd><p>Inherited text encoder from Encoder.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="gliner.modeling.encoder.BiEncoder.projection">
<span class="sig-name descname"><span class="pre">projection</span></span><a class="headerlink" href="#gliner.modeling.encoder.BiEncoder.projection" title="Link to this definition">Â¶</a></dt>
<dd><p>Inherited optional projection from Encoder.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="gliner.modeling.encoder.BiEncoder.labels_encoder">
<span class="sig-name descname"><span class="pre">labels_encoder</span></span><a class="headerlink" href="#gliner.modeling.encoder.BiEncoder.labels_encoder" title="Link to this definition">Â¶</a></dt>
<dd><p>Separate Transformer instance for encoding labels.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="gliner.modeling.encoder.BiEncoder.labels_projection">
<span class="sig-name descname"><span class="pre">labels_projection</span></span><a class="headerlink" href="#gliner.modeling.encoder.BiEncoder.labels_projection" title="Link to this definition">Â¶</a></dt>
<dd><p>Optional projection for label embeddings when label
encoder hidden size differs from config.hidden_size.</p>
</dd></dl>

<p>Initializes the bi-encoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config</strong> (<em>Any</em>) â€“ Configuration object containing model hyperparameters including
<cite>labels_encoder</cite> (model name for label encoder) and <cite>hidden_size</cite>.</p></li>
<li><p><strong>from_pretrained</strong> (<em>bool</em>) â€“ If True, loads pretrained weights for both encoders.
Defaults to False.</p></li>
<li><p><strong>cache_dir</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>None</em>) â€“ Optional directory for caching downloaded models. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="gliner.modeling.encoder.BiEncoder.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">from_pretrained</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gliner/modeling/encoder.html#BiEncoder.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gliner.modeling.encoder.BiEncoder.__init__" title="Link to this definition">Â¶</a></dt>
<dd><p>Initializes the bi-encoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config</strong> (<em>Any</em>) â€“ Configuration object containing model hyperparameters including
<cite>labels_encoder</cite> (model name for label encoder) and <cite>hidden_size</cite>.</p></li>
<li><p><strong>from_pretrained</strong> (<em>bool</em>) â€“ If True, loads pretrained weights for both encoders.
Defaults to False.</p></li>
<li><p><strong>cache_dir</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>None</em>) â€“ Optional directory for caching downloaded models. Defaults to None.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gliner.modeling.encoder.BiEncoder.mean_pooling">
<span class="sig-name descname"><span class="pre">mean_pooling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">token_embeddings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_mask</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gliner/modeling/encoder.html#BiEncoder.mean_pooling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gliner.modeling.encoder.BiEncoder.mean_pooling" title="Link to this definition">Â¶</a></dt>
<dd><p>Applies mean pooling over token embeddings using attention mask.</p>
<p>Computes the average of token embeddings weighted by the attention mask,
ignoring padded positions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>token_embeddings</strong> (<em>Tensor</em>) â€“ Token-level embeddings of shape (batch_size, seq_len, hidden_size).</p></li>
<li><p><strong>attention_mask</strong> (<em>Tensor</em>) â€“ Binary mask of shape (batch_size, seq_len) where 1 indicates
valid tokens and 0 indicates padding.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Pooled embeddings of shape (batch_size, hidden_size).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gliner.modeling.encoder.BiEncoder.encode_labels">
<span class="sig-name descname"><span class="pre">encode_labels</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_ids</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_mask</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gliner/modeling/encoder.html#BiEncoder.encode_labels"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gliner.modeling.encoder.BiEncoder.encode_labels" title="Link to this definition">Â¶</a></dt>
<dd><p>Encodes label sequences into fixed-size embeddings.</p>
<p>Processes labels through the dedicated labels encoder and applies mean pooling
to produce sentence-level representations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<em>Tensor</em>) â€“ Label token IDs of shape (batch_size, seq_len).</p></li>
<li><p><strong>attention_mask</strong> (<em>Tensor</em>) â€“ Attention mask of shape (batch_size, seq_len).</p></li>
<li><p><strong>*args</strong> (<em>Any</em>) â€“ Additional positional arguments.</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em>) â€“ Additional keyword arguments (packing_config and pair_attention_mask
are removed as theyâ€™re not supported for labels).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Pooled label embeddings of shape (batch_size, hidden_size).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gliner.modeling.encoder.BiEncoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_ids</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_mask</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels_input_ids</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels_attention_mask</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/gliner/modeling/encoder.html#BiEncoder.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gliner.modeling.encoder.BiEncoder.forward" title="Link to this definition">Â¶</a></dt>
<dd><p>Forward pass through the bi-encoder.</p>
<p>Encodes both text sequences (token-level) and label sequences (pooled) to
produce aligned representations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<em>Tensor</em>) â€“ Text token IDs of shape (batch_size, seq_len).</p></li>
<li><p><strong>attention_mask</strong> (<em>Tensor</em>) â€“ Text attention mask of shape (batch_size, seq_len).</p></li>
<li><p><strong>labels_input_ids</strong> (<em>Tensor</em><em> | </em><em>None</em>) â€“ Label token IDs of shape (batch_size, label_seq_len).</p></li>
<li><p><strong>labels_attention_mask</strong> (<em>Tensor</em><em> | </em><em>None</em>) â€“ Label attention mask of shape (batch_size, label_seq_len).</p></li>
<li><p><strong>*args</strong> (<em>Any</em>) â€“ Additional positional arguments.</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em>) â€“ Additional keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>token_embeddings: Text embeddings of shape (batch_size, seq_len, hidden_size).</p></li>
<li><p>labels_embeddings: Pooled label embeddings of shape (batch_size, hidden_size).</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>A tuple containing</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>

        </article><button class="back-to-top" type="button">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
  </svg>
  <span>Back to top</span>
</button><div class="navigation flex print:hidden"><div class="navigation-prev">
    <a href="gliner.modeling.decoder.html">
      <i class="i-lucide chevron-left"></i>
      <div class="page-info">
        <span>Previous</span><div class="title">gliner.modeling.decoder module</div></div>
    </a>
  </div><div class="navigation-next">
    <a href="gliner.modeling.layers.html">
      <div class="page-info">
        <span>Next</span>
        <div class="title">gliner.modeling.layers module</div>
      </div>
      <i class="i-lucide chevron-right"></i>
    </a>
  </div></div></div>
    </div>
  </main>
</div>
<footer class="sy-foot">
  <div class="sy-foot-inner sy-container mx-auto">
    <div class="sy-foot-reserved md:flex justify-between items-center">
      <div class="sy-foot-copyright"><p>2025, GLiNER community</p>
  
  <p>
    Made with
    
    <a href="https://www.sphinx-doc.org/">Sphinx</a> and
    
    <a href="https://shibuya.lepture.com">Shibuya theme</a>.
  </p>
</div>
      <div class="sy-foot-socials"></div>
    </div>
  </div>
</footer>
      <script src="../_static/documentation_options.js?v=dc91f075"></script>
      <script src="../_static/doctools.js?v=9a2dae69"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../_static/shibuya.js?v=9b0e4dde"></script></body>
</html>