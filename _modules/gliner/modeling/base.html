<!DOCTYPE html>
<html lang="en" data-accent-color="violet" data-content_root="../../../">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>gliner.modeling.base - Home 0.2.24 documentation</title><link rel="index" title="Index" href="../../../genindex.html" /><link rel="search" title="Search" href="../../../search.html" /><script>
    function setColorMode(t){let e=document.documentElement;e.setAttribute("data-color-mode",t);let a=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,s=t;"auto"===t&&(s=a?"dark":"light"),"light"===s?(e.classList.remove("dark"),e.classList.add("light")):(e.classList.remove("light"),e.classList.add("dark"))}
    setColorMode(localStorage._theme||"auto");
  </script><link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=e1a1ceaf" />
    <link rel="stylesheet" type="text/css" href="../../../_static/shibuya.css?v=d140fbf8" />
    <link media="print" rel="stylesheet" type="text/css" href="../../../_static/print.css?v=20ff2c19" />
    <link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
<style>
:root {
  --sy-f-text: "Inter", var(--sy-f-sys), var(--sy-f-cjk), sans-serif;
  --sy-f-heading: "Inter", var(--sy-f-sys), var(--sy-f-cjk), sans-serif;
}
</style>
    <meta property="og:type" content="website"/><meta property="og:title" content="gliner.modeling.base"/>
<meta name="twitter:card" content="summary"/>
  </head>
<body><div class="sy-head">
  <div class="sy-head-blur"></div>
  <div class="sy-head-inner sy-container mx-auto">
    <a class="sy-head-brand" href="../../../index.html">
      
      
      <strong>Home</strong>
    </a>
    <div class="sy-head-nav" id="head-nav">
      <nav class="sy-head-links"></nav>
      <div class="sy-head-extra flex items-center print:hidden"><form class="searchbox flex items-center" action="../../../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <kbd>/</kbd>
</form><div class="sy-head-socials"></div></div>
    </div>
    <div class="sy-head-actions flex items-center shrink-0 print:hidden"><button class="js-theme theme-switch flex items-center"
data-aria-auto="Switch to light color mode"
data-aria-light="Switch to dark color mode"
data-aria-dark="Switch to auto color mode">
<i class="i-lucide theme-icon"></i>
</button><button class="md:hidden flex items-center js-menu" aria-label="Menu" type="button" aria-controls="head-nav" aria-expanded="false">
        <div class="hamburger">
          <span class="hamburger_1"></span>
          <span class="hamburger_2"></span>
          <span class="hamburger_3"></span>
        </div>
      </button>
    </div>
  </div>
</div>
<div class="sy-page sy-container flex mx-auto">
  <aside id="lside" class="sy-lside md:w-72 md:shrink-0 print:hidden">
    <div class="sy-lside-inner md:sticky">
      <div class="sy-scrollbar p-6">
        <div class="globaltoc" data-expand-depth="0"><p class="caption" role="heading" aria-level="3"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../intro.html">Introduction to ðŸ‘‘ GLiNER</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../instalation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage.html">Advanced Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../configs.html">Components &amp; Configs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../training.html">Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../architectures.html">Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../convert_to_onnx.html">ONNX Export &amp; Deployment</a></li>
</ul>
<p class="caption" role="heading" aria-level="3"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.model.html">gliner.model module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.config.html">gliner.config module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.training.html">gliner.training package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.training.trainer.html">gliner.training.trainer module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.modeling.html">gliner.modeling package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.multitask.html">gliner.modeling.multitask package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gliner.modeling.multitask.relations_layers.html">gliner.modeling.multitask.relations_layers module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gliner.modeling.multitask.triples_layers.html">gliner.modeling.multitask.triples_layers module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.base.html">gliner.modeling.base module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.decoder.html">gliner.modeling.decoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.encoder.html">gliner.modeling.encoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.layers.html">gliner.modeling.layers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.loss_functions.html">gliner.modeling.loss_functions module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.outputs.html">gliner.modeling.outputs module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.scorers.html">gliner.modeling.scorers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.span_rep.html">gliner.modeling.span_rep module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.utils.html">gliner.modeling.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.data_processing.html">gliner.data_processing package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.data_processing.collator.html">gliner.data_processing.collator module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.data_processing.processor.html">gliner.data_processing.processor module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.data_processing.tokenizer.html">gliner.data_processing.tokenizer module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.data_processing.utils.html">gliner.data_processing.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.evaluation.html">gliner.evaluation package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.evaluation.evaluate_ner.html">gliner.evaluation.evaluate_ner module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.evaluation.evaluator.html">gliner.evaluation.evaluator module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.evaluation.utils.html">gliner.evaluation.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.onnx.html">gliner.onnx package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.onnx.model.html">gliner.onnx.model module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.decoding.html">gliner.decoding package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.decoding.trie.html">gliner.decoding.trie package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gliner.decoding.trie.labels_trie.html">gliner.decoding.trie.labels_trie module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gliner.decoding.trie.python_labels_trie.html">gliner.decoding.trie.python_labels_trie module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.decoding.decoder.html">gliner.decoding.decoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.decoding.utils.html">gliner.decoding.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.utils.html">gliner.utils module</a></li>
</ul>

        </div>
      </div>
    </div>
  </aside>
  <div class="lside-overlay js-menu" role="button" aria-label="Close left sidebar" aria-controls="lside" aria-expanded="false"></div>
  <aside id="rside" class="sy-rside pb-3 w-64 shrink-0 order-last">
    <button class="rside-close js-menu xl:hidden" aria-label="Close Table of Contents" type="button" aria-controls="rside" aria-expanded="false">
      <i class="i-lucide close"></i>
    </button>
    <div class="sy-scrollbar sy-rside-inner px-6 xl:top-16 xl:sticky xl:pl-0 pt-6 pb-4"><div id="ethical-ad-placement" data-ea-publisher="readthedocs"></div></div>
  </aside>
  <div class="rside-overlay js-menu" role="button" aria-label="Close Table of Contents" aria-controls="rside" aria-expanded="false"></div>
  <main class="sy-main w-full max-sm:max-w-full print:pt-6">
<div class="sy-breadcrumbs" role="navigation">
  <div class="sy-breadcrumbs-inner flex items-center">
    <div class="md:hidden mr-3">
      <button class="js-menu" aria-label="Menu" type="button" aria-controls="lside" aria-expanded="false">
        <i class="i-lucide menu"></i>
      </button>
    </div>
    <ol class="flex-1" itemscope itemtype="https://schema.org/BreadcrumbList"><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <a itemprop="item" href="../../../index.html"><span itemprop="name">Home</span></a>
        <span>/</span>
        <meta itemprop="position" content="1" />
      </li><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <a itemprop="item" href="../../index.html"><span itemprop="name">Module code</span></a>
        <span>/</span>
        <meta itemprop="position" content="2" />
      </li><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <strong itemprop="name">gliner.modeling.base</strong>
        <meta itemprop="position" content="3" />
      </li></ol>
    <div class="xl:hidden ml-1">
      <button class="js-menu" aria-label="Show table of contents" type="button" aria-controls="rside"
        aria-expanded="false">
        <i class="i-lucide outdent"></i>
      </button>
    </div>
  </div>
</div><div class="flex flex-col break-words justify-between">
      <div class="min-w-0 max-w-6xl px-6 pb-6 pt-8 xl:px-12">
        <article class="yue" role="main">
          <h1>Source code for gliner.modeling.base</h1><div class="highlight"><pre>
<span></span><span data-line="1"><span class="sd">&quot;&quot;&quot;Base model classes for GLiNER neural network architectures.</span>
</span><span data-line="2">
</span><span data-line="3"><span class="sd">This module provides abstract base classes and concrete implementations for various</span>
</span><span data-line="4"><span class="sd">encoder-decoder architectures used in named entity recognition (NER) and relation</span>
</span><span data-line="5"><span class="sd">extraction tasks.</span>
</span><span data-line="6">
</span><span data-line="7"><span class="sd">Classes:</span>
</span><span data-line="8"><span class="sd">    BaseModel: Abstract base class for all models.</span>
</span><span data-line="9"><span class="sd">    BaseUniEncoderModel: Base class for uni-encoder architectures.</span>
</span><span data-line="10"><span class="sd">    UniEncoderSpanModel: Span-based NER model with uni-encoder.</span>
</span><span data-line="11"><span class="sd">    UniEncoderTokenModel: Token-based NER model with uni-encoder.</span>
</span><span data-line="12"><span class="sd">    BaseBiEncoderModel: Base class for bi-encoder architectures.</span>
</span><span data-line="13"><span class="sd">    BiEncoderSpanModel: Span-based NER model with bi-encoder.</span>
</span><span data-line="14"><span class="sd">    BiEncoderTokenModel: Token-based NER model with bi-encoder.</span>
</span><span data-line="15"><span class="sd">    UniEncoderSpanDecoderModel: Span model with decoder for label generation.</span>
</span><span data-line="16"><span class="sd">    UniEncoderSpanRelexModel: Span model with relation extraction capabilities.</span>
</span><span data-line="17"><span class="sd">&quot;&quot;&quot;</span>
</span><span data-line="18">
</span><span data-line="19"><span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
</span><span data-line="20"><span class="kn">from</span><span class="w"> </span><span class="nn">abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
</span><span data-line="21"><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Optional</span>
</span><span data-line="22"><span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
</span><span data-line="23">
</span><span data-line="24"><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span data-line="25"><span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
</span><span data-line="26"><span class="kn">from</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
</span><span data-line="27">
</span><span data-line="28"><span class="kn">from</span><span class="w"> </span><span class="nn">.utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span data-line="29">    <span class="n">build_entity_pairs</span><span class="p">,</span>
</span><span data-line="30">    <span class="n">extract_prompt_features</span><span class="p">,</span>
</span><span data-line="31">    <span class="n">extract_word_embeddings</span><span class="p">,</span>
</span><span data-line="32">    <span class="n">extract_spans_from_tokens</span><span class="p">,</span>
</span><span data-line="33">    <span class="n">extract_prompt_features_and_word_embeddings</span><span class="p">,</span>
</span><span data-line="34"><span class="p">)</span>
</span><span data-line="35"><span class="kn">from</span><span class="w"> </span><span class="nn">.layers</span><span class="w"> </span><span class="kn">import</span> <span class="n">CrossFuser</span><span class="p">,</span> <span class="n">LstmSeq2SeqEncoder</span><span class="p">,</span> <span class="n">create_projection_layer</span>
</span><span data-line="36"><span class="kn">from</span><span class="w"> </span><span class="nn">.decoder</span><span class="w"> </span><span class="kn">import</span> <span class="n">Decoder</span>
</span><span data-line="37"><span class="kn">from</span><span class="w"> </span><span class="nn">.encoder</span><span class="w"> </span><span class="kn">import</span> <span class="n">Encoder</span><span class="p">,</span> <span class="n">BiEncoder</span>
</span><span data-line="38"><span class="kn">from</span><span class="w"> </span><span class="nn">.outputs</span><span class="w"> </span><span class="kn">import</span> <span class="n">GLiNERBaseOutput</span><span class="p">,</span> <span class="n">GLiNERRelexOutput</span><span class="p">,</span> <span class="n">GLiNERDecoderOutput</span>
</span><span data-line="39"><span class="kn">from</span><span class="w"> </span><span class="nn">.scorers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Scorer</span>
</span><span data-line="40"><span class="kn">from</span><span class="w"> </span><span class="nn">.span_rep</span><span class="w"> </span><span class="kn">import</span> <span class="n">SpanRepLayer</span>
</span><span data-line="41"><span class="kn">from</span><span class="w"> </span><span class="nn">.loss_functions</span><span class="w"> </span><span class="kn">import</span> <span class="n">cross_entropy_loss</span><span class="p">,</span> <span class="n">focal_loss_with_logits</span>
</span><span data-line="42"><span class="kn">from</span><span class="w"> </span><span class="nn">.multitask.triples_layers</span><span class="w"> </span><span class="kn">import</span> <span class="n">TriplesScoreLayer</span>
</span><span data-line="43"><span class="kn">from</span><span class="w"> </span><span class="nn">.multitask.relations_layers</span><span class="w"> </span><span class="kn">import</span> <span class="n">RelationsRepLayer</span>
</span><span data-line="44">
</span><span data-line="45">
<div class="viewcode-block" id="BaseModel">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.BaseModel">[docs]</a>
</span><span data-line="46"><span class="k">class</span><span class="w"> </span><span class="nc">BaseModel</span><span class="p">(</span><span class="n">ABC</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span data-line="47"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Abstract base class for all GLiNER models.</span>
</span><span data-line="48">
</span><span data-line="49"><span class="sd">    This class defines the common interface and shared functionality for all model</span>
</span><span data-line="50"><span class="sd">    architectures. It includes methods for padding/truncating sequences and computing</span>
</span><span data-line="51"><span class="sd">    losses with various masking strategies.</span>
</span><span data-line="52">
</span><span data-line="53"><span class="sd">    Attributes:</span>
</span><span data-line="54"><span class="sd">        data_processor: Data processor for handling input preprocessing.</span>
</span><span data-line="55"><span class="sd">        config: Model configuration object.</span>
</span><span data-line="56"><span class="sd">        from_pretrained (bool): Whether model was loaded from pretrained weights.</span>
</span><span data-line="57"><span class="sd">        cache_dir (Optional[Path]): Directory for caching pretrained models.</span>
</span><span data-line="58"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="59">
</span><span data-line="60">    <span class="n">data_processor</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="61">
<div class="viewcode-block" id="BaseModel.__init__">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.BaseModel.__init__">[docs]</a>
</span><span data-line="62">    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span data-line="63">        <span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="64">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="65"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the base model.</span>
</span><span data-line="66">
</span><span data-line="67"><span class="sd">        Args:</span>
</span><span data-line="68"><span class="sd">            config: Configuration object containing model hyperparameters.</span>
</span><span data-line="69"><span class="sd">            from_pretrained: Whether to load from pretrained weights.</span>
</span><span data-line="70"><span class="sd">            cache_dir: Directory path for caching pretrained models.</span>
</span><span data-line="71"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="72">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span data-line="73">        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
</span><span data-line="74">        <span class="bp">self</span><span class="o">.</span><span class="n">from_pretrained</span> <span class="o">=</span> <span class="n">from_pretrained</span>
</span><span data-line="75">        <span class="bp">self</span><span class="o">.</span><span class="n">cache_dir</span> <span class="o">=</span> <span class="n">cache_dir</span></div>

</span><span data-line="76">
<div class="viewcode-block" id="BaseModel.get_representations">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.BaseModel.get_representations">[docs]</a>
</span><span data-line="77">    <span class="nd">@abstractmethod</span>
</span><span data-line="78">    <span class="k">def</span><span class="w"> </span><span class="nf">get_representations</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">]:</span>
</span><span data-line="79"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Get intermediate representations from the model.</span>
</span><span data-line="80">
</span><span data-line="81"><span class="sd">        Returns:</span>
</span><span data-line="82"><span class="sd">            Tuple of tensors representing intermediate model outputs.</span>
</span><span data-line="83"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="84">        <span class="k">pass</span></div>

</span><span data-line="85">
</span><span data-line="86">    <span class="nd">@staticmethod</span>
</span><span data-line="87">    <span class="k">def</span><span class="w"> </span><span class="nf">_fit_length</span><span class="p">(</span><span class="n">embedding</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">target_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span data-line="88"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Make embedding and mask exactly target_len along dimension 1.</span>
</span><span data-line="89">
</span><span data-line="90"><span class="sd">        Pads with zeros if current length is less than target, truncates if greater.</span>
</span><span data-line="91">
</span><span data-line="92"><span class="sd">        Args:</span>
</span><span data-line="93"><span class="sd">            embedding: Tensor of shape (B, L, D) containing embeddings.</span>
</span><span data-line="94"><span class="sd">            mask: Tensor of shape (B, L) containing attention mask.</span>
</span><span data-line="95"><span class="sd">            target_len: Desired sequence length.</span>
</span><span data-line="96">
</span><span data-line="97"><span class="sd">        Returns:</span>
</span><span data-line="98"><span class="sd">            Tuple containing:</span>
</span><span data-line="99"><span class="sd">                - embedding: Resized embedding tensor of shape (B, target_len, D).</span>
</span><span data-line="100"><span class="sd">                - mask: Resized mask tensor of shape (B, target_len).</span>
</span><span data-line="101"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="102">        <span class="n">L</span> <span class="o">=</span> <span class="n">embedding</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span data-line="103">
</span><span data-line="104">        <span class="k">if</span> <span class="n">target_len</span> <span class="o">==</span> <span class="n">L</span><span class="p">:</span>
</span><span data-line="105">            <span class="k">return</span> <span class="n">embedding</span><span class="p">,</span> <span class="n">mask</span>
</span><span data-line="106">
</span><span data-line="107">        <span class="k">if</span> <span class="n">target_len</span> <span class="o">&gt;</span> <span class="n">L</span><span class="p">:</span>
</span><span data-line="108">            <span class="n">pad_len</span> <span class="o">=</span> <span class="n">target_len</span> <span class="o">-</span> <span class="n">L</span>
</span><span data-line="109">            <span class="n">embedding</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">embedding</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">pad_len</span><span class="p">))</span>
</span><span data-line="110">            <span class="n">mask</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_len</span><span class="p">))</span>
</span><span data-line="111">        <span class="k">else</span><span class="p">:</span>
</span><span data-line="112">            <span class="n">embedding</span> <span class="o">=</span> <span class="n">embedding</span><span class="p">[:,</span> <span class="p">:</span><span class="n">target_len</span><span class="p">]</span>
</span><span data-line="113">            <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="p">[:,</span> <span class="p">:</span><span class="n">target_len</span><span class="p">]</span>
</span><span data-line="114">
</span><span data-line="115">        <span class="k">return</span> <span class="n">embedding</span><span class="p">,</span> <span class="n">mask</span>
</span><span data-line="116">
<div class="viewcode-block" id="BaseModel.forward">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.BaseModel.forward">[docs]</a>
</span><span data-line="117">    <span class="nd">@abstractmethod</span>
</span><span data-line="118">    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
</span><span data-line="119"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward pass through the model.</span>
</span><span data-line="120">
</span><span data-line="121"><span class="sd">        Args:</span>
</span><span data-line="122"><span class="sd">            x: Input data.</span>
</span><span data-line="123">
</span><span data-line="124"><span class="sd">        Returns:</span>
</span><span data-line="125"><span class="sd">            Model outputs.</span>
</span><span data-line="126"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="127">        <span class="k">pass</span></div>

</span><span data-line="128">
</span><span data-line="129">    <span class="k">def</span><span class="w"> </span><span class="nf">_loss</span><span class="p">(</span>
</span><span data-line="130">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="131">        <span class="n">logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="132">        <span class="n">labels</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="133">        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span>
</span><span data-line="134">        <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="135">        <span class="n">prob_margin</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="136">        <span class="n">label_smoothing</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="137">        <span class="n">negatives</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span data-line="138">        <span class="n">masking</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;none&quot;</span><span class="p">,</span>
</span><span data-line="139">        <span class="n">normalize_prob</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span data-line="140">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span data-line="141"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute loss with optional negative sampling and masking.</span>
</span><span data-line="142">
</span><span data-line="143"><span class="sd">        This method computes focal loss and applies negative sampling to balance</span>
</span><span data-line="144"><span class="sd">        positive and negative examples in the training data.</span>
</span><span data-line="145">
</span><span data-line="146"><span class="sd">        Args:</span>
</span><span data-line="147"><span class="sd">            logits: Predicted logits from the model.</span>
</span><span data-line="148"><span class="sd">            labels: Ground truth labels.</span>
</span><span data-line="149"><span class="sd">            alpha: Weight factor for balanced focal loss. If -1, no balancing.</span>
</span><span data-line="150"><span class="sd">            gamma: Focusing parameter for focal loss.</span>
</span><span data-line="151"><span class="sd">            prob_margin: Margin to subtract from probabilities.</span>
</span><span data-line="152"><span class="sd">            label_smoothing: Label smoothing factor.</span>
</span><span data-line="153"><span class="sd">            negatives: Probability of sampling negative examples.</span>
</span><span data-line="154"><span class="sd">            masking: Masking strategy, one of &quot;none&quot;, &quot;global&quot;, &quot;label&quot;, or &quot;span&quot;.</span>
</span><span data-line="155"><span class="sd">            normalize_prob: Whether to normalize probabilities in loss computation.</span>
</span><span data-line="156">
</span><span data-line="157"><span class="sd">        Returns:</span>
</span><span data-line="158"><span class="sd">            Loss tensor of same shape as labels.</span>
</span><span data-line="159"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="160">        <span class="c1"># Compute the loss per element using the focal loss function</span>
</span><span data-line="161">        <span class="n">all_losses</span> <span class="o">=</span> <span class="n">focal_loss_with_logits</span><span class="p">(</span>
</span><span data-line="162">            <span class="n">logits</span><span class="p">,</span>
</span><span data-line="163">            <span class="n">labels</span><span class="p">,</span>
</span><span data-line="164">            <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span>
</span><span data-line="165">            <span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span>
</span><span data-line="166">            <span class="n">prob_margin</span><span class="o">=</span><span class="n">prob_margin</span><span class="p">,</span>
</span><span data-line="167">            <span class="n">label_smoothing</span><span class="o">=</span><span class="n">label_smoothing</span><span class="p">,</span>
</span><span data-line="168">            <span class="n">normalize_prob</span><span class="o">=</span><span class="n">normalize_prob</span><span class="p">,</span>
</span><span data-line="169">        <span class="p">)</span>
</span><span data-line="170">
</span><span data-line="171">        <span class="c1"># Create a mask of the same shape as labels:</span>
</span><span data-line="172">        <span class="c1"># For elements where labels==0, sample a Bernoulli random variable that is 1 with probability `negatives`</span>
</span><span data-line="173">        <span class="c1"># For elements where labels==1, set the mask to 1 (i.e. do not change these losses)</span>
</span><span data-line="174">        <span class="k">if</span> <span class="n">masking</span> <span class="o">==</span> <span class="s2">&quot;global&quot;</span><span class="p">:</span>
</span><span data-line="175">            <span class="n">mask_neg</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">negatives</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
</span><span data-line="176">        <span class="k">elif</span> <span class="n">masking</span> <span class="o">==</span> <span class="s2">&quot;label&quot;</span><span class="p">:</span>
</span><span data-line="177">            <span class="n">neg_proposals</span> <span class="o">=</span> <span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
</span><span data-line="178">            <span class="n">mask_neg</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
</span><span data-line="179">                <span class="n">neg_proposals</span><span class="p">,</span>
</span><span data-line="180">                <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">neg_proposals</span><span class="o">.</span><span class="n">float</span><span class="p">())</span> <span class="o">&lt;</span> <span class="n">negatives</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span>
</span><span data-line="181">                <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">neg_proposals</span><span class="o">.</span><span class="n">float</span><span class="p">()),</span>
</span><span data-line="182">            <span class="p">)</span>
</span><span data-line="183">        <span class="k">elif</span> <span class="n">masking</span> <span class="o">==</span> <span class="s2">&quot;span&quot;</span><span class="p">:</span>
</span><span data-line="184">            <span class="n">neg_proposals</span> <span class="o">=</span> <span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
</span><span data-line="185">            <span class="n">mask_neg</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
</span><span data-line="186">                <span class="n">neg_proposals</span><span class="p">,</span>
</span><span data-line="187">                <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">neg_proposals</span><span class="o">.</span><span class="n">float</span><span class="p">())</span> <span class="o">&lt;</span> <span class="n">negatives</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span>
</span><span data-line="188">                <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">neg_proposals</span><span class="o">.</span><span class="n">float</span><span class="p">()),</span>
</span><span data-line="189">            <span class="p">)</span>
</span><span data-line="190">        <span class="k">else</span><span class="p">:</span>
</span><span data-line="191">            <span class="n">mask_neg</span> <span class="o">=</span> <span class="mf">1.0</span>
</span><span data-line="192">
</span><span data-line="193">        <span class="c1"># Apply the mask: for negative examples, some losses will be zeroed out based on the sampling</span>
</span><span data-line="194">        <span class="n">all_losses</span> <span class="o">=</span> <span class="n">all_losses</span> <span class="o">*</span> <span class="n">mask_neg</span>
</span><span data-line="195">
</span><span data-line="196">        <span class="k">return</span> <span class="n">all_losses</span>
</span><span data-line="197">
<div class="viewcode-block" id="BaseModel.loss">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.BaseModel.loss">[docs]</a>
</span><span data-line="198">    <span class="nd">@abstractmethod</span>
</span><span data-line="199">    <span class="k">def</span><span class="w"> </span><span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span data-line="200"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute the total loss for the model.</span>
</span><span data-line="201">
</span><span data-line="202"><span class="sd">        Args:</span>
</span><span data-line="203"><span class="sd">            x: Input data and labels.</span>
</span><span data-line="204">
</span><span data-line="205"><span class="sd">        Returns:</span>
</span><span data-line="206"><span class="sd">            Scalar loss tensor.</span>
</span><span data-line="207"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="208">        <span class="k">pass</span></div>
</div>

</span><span data-line="209">
</span><span data-line="210">
<div class="viewcode-block" id="BaseUniEncoderModel">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.BaseUniEncoderModel">[docs]</a>
</span><span data-line="211"><span class="k">class</span><span class="w"> </span><span class="nc">BaseUniEncoderModel</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
</span><span data-line="212"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Base class for uni-encoder model architectures.</span>
</span><span data-line="213">
</span><span data-line="214"><span class="sd">    Uni-encoder models use a single encoder for both text and entity labels,</span>
</span><span data-line="215"><span class="sd">    embedding them in the same semantic space.</span>
</span><span data-line="216">
</span><span data-line="217"><span class="sd">    Attributes:</span>
</span><span data-line="218"><span class="sd">        token_rep_layer (Encoder): Token-level representation encoder.</span>
</span><span data-line="219"><span class="sd">        rnn (Optional[LstmSeq2SeqEncoder]): Optional LSTM layer for sequence modeling.</span>
</span><span data-line="220"><span class="sd">        cross_fuser (Optional[CrossFuser]): Optional cross-attention fusion layer.</span>
</span><span data-line="221"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="222">
<div class="viewcode-block" id="BaseUniEncoderModel.__init__">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.BaseUniEncoderModel.__init__">[docs]</a>
</span><span data-line="223">    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span data-line="224">        <span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="225">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="226"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the uni-encoder model.</span>
</span><span data-line="227">
</span><span data-line="228"><span class="sd">        Args:</span>
</span><span data-line="229"><span class="sd">            config: Model configuration object.</span>
</span><span data-line="230"><span class="sd">            from_pretrained: Whether to load from pretrained weights.</span>
</span><span data-line="231"><span class="sd">            cache_dir: Directory for caching pretrained models.</span>
</span><span data-line="232"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="233">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">)</span>
</span><span data-line="234">        <span class="bp">self</span><span class="o">.</span><span class="n">token_rep_layer</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">,</span> <span class="n">cache_dir</span><span class="o">=</span><span class="n">cache_dir</span><span class="p">)</span>
</span><span data-line="235">
</span><span data-line="236">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_rnn_layers</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span data-line="237">            <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">LstmSeq2SeqEncoder</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_rnn_layers</span><span class="p">)</span>
</span><span data-line="238">
</span><span data-line="239">        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">post_fusion_schema</span><span class="p">:</span>
</span><span data-line="240">            <span class="bp">self</span><span class="o">.</span><span class="n">cross_fuser</span> <span class="o">=</span> <span class="n">CrossFuser</span><span class="p">(</span>
</span><span data-line="241">                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span>
</span><span data-line="242">                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span>
</span><span data-line="243">                <span class="n">num_heads</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">token_rep_layer</span><span class="o">.</span><span class="n">bert_layer</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">,</span>
</span><span data-line="244">                <span class="n">num_layers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_post_fusion_layers</span><span class="p">,</span>
</span><span data-line="245">                <span class="n">dropout</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span>
</span><span data-line="246">                <span class="n">schema</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">post_fusion_schema</span><span class="p">,</span>
</span><span data-line="247">            <span class="p">)</span></div>

</span><span data-line="248">
</span><span data-line="249">    <span class="k">def</span><span class="w"> </span><span class="nf">_extract_prompt_features_and_word_embeddings</span><span class="p">(</span>
</span><span data-line="250">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="251">        <span class="n">token_embeds</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="252">        <span class="n">input_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="253">        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="254">        <span class="n">text_lengths</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="255">        <span class="n">words_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="256">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span data-line="257"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Extract entity label prompts and word embeddings from token embeddings.</span>
</span><span data-line="258">
</span><span data-line="259"><span class="sd">        Args:</span>
</span><span data-line="260"><span class="sd">            token_embeds: Token-level embeddings of shape (B, L, D).</span>
</span><span data-line="261"><span class="sd">            input_ids: Input token IDs of shape (B, L).</span>
</span><span data-line="262"><span class="sd">            attention_mask: Attention mask of shape (B, L).</span>
</span><span data-line="263"><span class="sd">            text_lengths: Length of each text sequence in batch.</span>
</span><span data-line="264"><span class="sd">            words_mask: Mask indicating word boundaries.</span>
</span><span data-line="265">
</span><span data-line="266"><span class="sd">        Returns:</span>
</span><span data-line="267"><span class="sd">            Tuple containing:</span>
</span><span data-line="268"><span class="sd">                - prompts_embedding: Entity label embeddings of shape (B, C, D).</span>
</span><span data-line="269"><span class="sd">                - prompts_embedding_mask: Mask for prompts of shape (B, C).</span>
</span><span data-line="270"><span class="sd">                - words_embedding: Word-level embeddings of shape (B, W, D).</span>
</span><span data-line="271"><span class="sd">                - mask: Mask for words of shape (B, W).</span>
</span><span data-line="272"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="273">        <span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">,</span> <span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="n">extract_prompt_features_and_word_embeddings</span><span class="p">(</span>
</span><span data-line="274">            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">class_token_index</span><span class="p">,</span>
</span><span data-line="275">            <span class="n">token_embeds</span><span class="p">,</span>
</span><span data-line="276">            <span class="n">input_ids</span><span class="p">,</span>
</span><span data-line="277">            <span class="n">attention_mask</span><span class="p">,</span>
</span><span data-line="278">            <span class="n">text_lengths</span><span class="p">,</span>
</span><span data-line="279">            <span class="n">words_mask</span><span class="p">,</span>
</span><span data-line="280">            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">embed_ent_token</span><span class="p">,</span>
</span><span data-line="281">        <span class="p">)</span>
</span><span data-line="282">        <span class="k">return</span> <span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">,</span> <span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span>
</span><span data-line="283">
<div class="viewcode-block" id="BaseUniEncoderModel.get_representations">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.BaseUniEncoderModel.get_representations">[docs]</a>
</span><span data-line="284">    <span class="k">def</span><span class="w"> </span><span class="nf">get_representations</span><span class="p">(</span>
</span><span data-line="285">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="286">        <span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="287">        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="288">        <span class="n">text_lengths</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="289">        <span class="n">words_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="290">        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span data-line="291">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span data-line="292"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Get entity label and word representations from input.</span>
</span><span data-line="293">
</span><span data-line="294"><span class="sd">        Args:</span>
</span><span data-line="295"><span class="sd">            input_ids: Input token IDs of shape (B, L).</span>
</span><span data-line="296"><span class="sd">            attention_mask: Attention mask of shape (B, L).</span>
</span><span data-line="297"><span class="sd">            text_lengths: Length of each text in batch.</span>
</span><span data-line="298"><span class="sd">            words_mask: Word boundary mask.</span>
</span><span data-line="299"><span class="sd">            **kwargs: Additional arguments for the encoder.</span>
</span><span data-line="300">
</span><span data-line="301"><span class="sd">        Returns:</span>
</span><span data-line="302"><span class="sd">            Tuple containing:</span>
</span><span data-line="303"><span class="sd">                - prompts_embedding: Entity label embeddings of shape (B, C, D).</span>
</span><span data-line="304"><span class="sd">                - prompts_embedding_mask: Mask for prompts of shape (B, C).</span>
</span><span data-line="305"><span class="sd">                - words_embedding: Word embeddings of shape (B, W, D).</span>
</span><span data-line="306"><span class="sd">                - mask: Mask for words of shape (B, W).</span>
</span><span data-line="307"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="308">        <span class="n">token_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_rep_layer</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span data-line="309">
</span><span data-line="310">        <span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">,</span> <span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span>
</span><span data-line="311">            <span class="bp">self</span><span class="o">.</span><span class="n">_extract_prompt_features_and_word_embeddings</span><span class="p">(</span>
</span><span data-line="312">                <span class="n">token_embeds</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">text_lengths</span><span class="p">,</span> <span class="n">words_mask</span>
</span><span data-line="313">            <span class="p">)</span>
</span><span data-line="314">        <span class="p">)</span>
</span><span data-line="315">
</span><span data-line="316">        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;rnn&quot;</span><span class="p">):</span>
</span><span data-line="317">            <span class="n">words_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
</span><span data-line="318">
</span><span data-line="319">        <span class="k">return</span> <span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">,</span> <span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span></div>
</div>

</span><span data-line="320">
</span><span data-line="321">
<div class="viewcode-block" id="UniEncoderSpanModel">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderSpanModel">[docs]</a>
</span><span data-line="322"><span class="k">class</span><span class="w"> </span><span class="nc">UniEncoderSpanModel</span><span class="p">(</span><span class="n">BaseUniEncoderModel</span><span class="p">):</span>
</span><span data-line="323"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Span-based NER model using uni-encoder architecture.</span>
</span><span data-line="324">
</span><span data-line="325"><span class="sd">    This model identifies entity spans by scoring all possible spans against</span>
</span><span data-line="326"><span class="sd">    entity type embeddings.</span>
</span><span data-line="327">
</span><span data-line="328"><span class="sd">    Attributes:</span>
</span><span data-line="329"><span class="sd">        span_rep_layer (SpanRepLayer): Layer for computing span representations.</span>
</span><span data-line="330"><span class="sd">        prompt_rep_layer (nn.Module): Projection layer for entity label embeddings.</span>
</span><span data-line="331"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="332">
<div class="viewcode-block" id="UniEncoderSpanModel.__init__">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderSpanModel.__init__">[docs]</a>
</span><span data-line="333">    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span data-line="334">        <span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="335">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="336"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the span-based uni-encoder model.</span>
</span><span data-line="337">
</span><span data-line="338"><span class="sd">        Args:</span>
</span><span data-line="339"><span class="sd">            config: Model configuration object.</span>
</span><span data-line="340"><span class="sd">            from_pretrained: Whether to load from pretrained weights.</span>
</span><span data-line="341"><span class="sd">            cache_dir: Directory for caching pretrained models.</span>
</span><span data-line="342"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="343">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">)</span>
</span><span data-line="344">        <span class="bp">self</span><span class="o">.</span><span class="n">span_rep_layer</span> <span class="o">=</span> <span class="n">SpanRepLayer</span><span class="p">(</span>
</span><span data-line="345">            <span class="n">span_mode</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">span_mode</span><span class="p">,</span>
</span><span data-line="346">            <span class="n">hidden_size</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span>
</span><span data-line="347">            <span class="n">max_width</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_width</span><span class="p">,</span>
</span><span data-line="348">            <span class="n">dropout</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span>
</span><span data-line="349">        <span class="p">)</span>
</span><span data-line="350">
</span><span data-line="351">        <span class="bp">self</span><span class="o">.</span><span class="n">prompt_rep_layer</span> <span class="o">=</span> <span class="n">create_projection_layer</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">dropout</span><span class="p">)</span></div>

</span><span data-line="352">
<div class="viewcode-block" id="UniEncoderSpanModel.forward">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderSpanModel.forward">[docs]</a>
</span><span data-line="353">    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span data-line="354">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="355">        <span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="356">        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="357">        <span class="n">words_embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="358">        <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="359">        <span class="n">prompts_embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="360">        <span class="n">prompts_embedding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="361">        <span class="n">words_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="362">        <span class="n">text_lengths</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="363">        <span class="n">span_idx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="364">        <span class="n">span_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="365">        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="366">        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span data-line="367">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GLiNERBaseOutput</span><span class="p">:</span>
</span><span data-line="368"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward pass through the span-based model.</span>
</span><span data-line="369">
</span><span data-line="370"><span class="sd">        Args:</span>
</span><span data-line="371"><span class="sd">            input_ids: Input token IDs of shape (B, L).</span>
</span><span data-line="372"><span class="sd">            attention_mask: Attention mask of shape (B, L).</span>
</span><span data-line="373"><span class="sd">            words_embedding: Pre-computed word embeddings of shape (B, W, D).</span>
</span><span data-line="374"><span class="sd">            mask: Mask for words of shape (B, W).</span>
</span><span data-line="375"><span class="sd">            prompts_embedding: Pre-computed entity label embeddings of shape (B, C, D).</span>
</span><span data-line="376"><span class="sd">            prompts_embedding_mask: Mask for prompts of shape (B, C).</span>
</span><span data-line="377"><span class="sd">            words_mask: Word boundary mask.</span>
</span><span data-line="378"><span class="sd">            text_lengths: Length of each text sequence.</span>
</span><span data-line="379"><span class="sd">            span_idx: Span indices of shape (B, L*K, 2).</span>
</span><span data-line="380"><span class="sd">            span_mask: Mask for valid spans of shape (B, L, K).</span>
</span><span data-line="381"><span class="sd">            labels: Ground truth labels of shape (B, L, K, C).</span>
</span><span data-line="382"><span class="sd">            **kwargs: Additional arguments.</span>
</span><span data-line="383">
</span><span data-line="384"><span class="sd">        Returns:</span>
</span><span data-line="385"><span class="sd">            GLiNERBaseOutput containing logits, loss, and intermediate representations.</span>
</span><span data-line="386"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="387">        <span class="n">encoder_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">kwargs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;packing_config&quot;</span><span class="p">,</span> <span class="s2">&quot;pair_attention_mask&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">}</span>
</span><span data-line="388">
</span><span data-line="389">        <span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">,</span> <span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_representations</span><span class="p">(</span>
</span><span data-line="390">            <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">text_lengths</span><span class="p">,</span> <span class="n">words_mask</span><span class="p">,</span> <span class="o">**</span><span class="n">encoder_kwargs</span>
</span><span data-line="391">        <span class="p">)</span>
</span><span data-line="392">
</span><span data-line="393">        <span class="n">target_W</span> <span class="o">=</span> <span class="n">span_idx</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_width</span>
</span><span data-line="394">        <span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_length</span><span class="p">(</span><span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">target_W</span><span class="p">)</span>
</span><span data-line="395">
</span><span data-line="396">        <span class="n">span_idx</span> <span class="o">=</span> <span class="n">span_idx</span> <span class="o">*</span> <span class="n">span_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="397">
</span><span data-line="398">        <span class="n">span_rep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">span_rep_layer</span><span class="p">(</span><span class="n">words_embedding</span><span class="p">,</span> <span class="n">span_idx</span><span class="p">)</span>
</span><span data-line="399">
</span><span data-line="400">        <span class="n">target_C</span> <span class="o">=</span> <span class="n">prompts_embedding</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="401">        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="402">            <span class="n">target_C</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">target_C</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span data-line="403">
</span><span data-line="404">        <span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_length</span><span class="p">(</span>
</span><span data-line="405">            <span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">,</span> <span class="n">target_C</span>
</span><span data-line="406">        <span class="p">)</span>
</span><span data-line="407">
</span><span data-line="408">        <span class="n">prompts_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_rep_layer</span><span class="p">(</span><span class="n">prompts_embedding</span><span class="p">)</span>
</span><span data-line="409">        <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;BLKD,BCD-&gt;BLKC&quot;</span><span class="p">,</span> <span class="n">span_rep</span><span class="p">,</span> <span class="n">prompts_embedding</span><span class="p">)</span>
</span><span data-line="410">
</span><span data-line="411">        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="412">        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="413">            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">,</span> <span class="n">span_mask</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span data-line="414">
</span><span data-line="415">        <span class="n">output</span> <span class="o">=</span> <span class="n">GLiNERBaseOutput</span><span class="p">(</span>
</span><span data-line="416">            <span class="n">logits</span><span class="o">=</span><span class="n">scores</span><span class="p">,</span>
</span><span data-line="417">            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
</span><span data-line="418">            <span class="n">prompts_embedding</span><span class="o">=</span><span class="n">prompts_embedding</span><span class="p">,</span>
</span><span data-line="419">            <span class="n">prompts_embedding_mask</span><span class="o">=</span><span class="n">prompts_embedding_mask</span><span class="p">,</span>
</span><span data-line="420">            <span class="n">words_embedding</span><span class="o">=</span><span class="n">words_embedding</span><span class="p">,</span>
</span><span data-line="421">            <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span>
</span><span data-line="422">        <span class="p">)</span>
</span><span data-line="423">        <span class="k">return</span> <span class="n">output</span></div>

</span><span data-line="424">
<div class="viewcode-block" id="UniEncoderSpanModel.loss">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderSpanModel.loss">[docs]</a>
</span><span data-line="425">    <span class="k">def</span><span class="w"> </span><span class="nf">loss</span><span class="p">(</span>
</span><span data-line="426">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="427">        <span class="n">scores</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="428">        <span class="n">labels</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="429">        <span class="n">prompts_embedding_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="430">        <span class="n">span_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="431">        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span>
</span><span data-line="432">        <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="433">        <span class="n">prob_margin</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="434">        <span class="n">label_smoothing</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="435">        <span class="n">reduction</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sum&quot;</span><span class="p">,</span>
</span><span data-line="436">        <span class="n">negatives</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span data-line="437">        <span class="n">masking</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;none&quot;</span><span class="p">,</span>
</span><span data-line="438">        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span data-line="439">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span data-line="440"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute span classification loss.</span>
</span><span data-line="441">
</span><span data-line="442"><span class="sd">        Args:</span>
</span><span data-line="443"><span class="sd">            scores: Predicted scores of shape (B, L, K, C).</span>
</span><span data-line="444"><span class="sd">            labels: Ground truth labels of shape (B, L, K, C).</span>
</span><span data-line="445"><span class="sd">            prompts_embedding_mask: Mask for valid entity types of shape (B, C).</span>
</span><span data-line="446"><span class="sd">            span_mask: Mask for valid spans of shape (B, L, K).</span>
</span><span data-line="447"><span class="sd">            alpha: Focal loss alpha parameter.</span>
</span><span data-line="448"><span class="sd">            gamma: Focal loss gamma parameter.</span>
</span><span data-line="449"><span class="sd">            prob_margin: Margin for probability adjustment.</span>
</span><span data-line="450"><span class="sd">            label_smoothing: Label smoothing factor.</span>
</span><span data-line="451"><span class="sd">            reduction: Loss reduction method (&#39;sum&#39; or &#39;mean&#39;).</span>
</span><span data-line="452"><span class="sd">            negatives: Negative sampling probability.</span>
</span><span data-line="453"><span class="sd">            masking: Masking strategy for negative sampling.</span>
</span><span data-line="454"><span class="sd">            **kwargs: Additional arguments.</span>
</span><span data-line="455">
</span><span data-line="456"><span class="sd">        Returns:</span>
</span><span data-line="457"><span class="sd">            Scalar loss tensor.</span>
</span><span data-line="458"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="459">        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span data-line="460">        <span class="n">num_classes</span> <span class="o">=</span> <span class="n">prompts_embedding_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span data-line="461">
</span><span data-line="462">        <span class="c1"># Reshape scores and labels to match the expected shape</span>
</span><span data-line="463">        <span class="n">BS</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">CL</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">shape</span>
</span><span data-line="464">
</span><span data-line="465">        <span class="n">scores</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">BS</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">CL</span><span class="p">)</span>
</span><span data-line="466">        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">BS</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">CL</span><span class="p">)</span>
</span><span data-line="467">
</span><span data-line="468">        <span class="n">all_losses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span>
</span><span data-line="469">            <span class="n">scores</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">prob_margin</span><span class="p">,</span> <span class="n">label_smoothing</span><span class="p">,</span> <span class="n">negatives</span><span class="o">=</span><span class="n">negatives</span><span class="p">,</span> <span class="n">masking</span><span class="o">=</span><span class="n">masking</span>
</span><span data-line="470">        <span class="p">)</span>
</span><span data-line="471">
</span><span data-line="472">        <span class="n">masked_loss</span> <span class="o">=</span> <span class="n">all_losses</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span> <span class="o">*</span> <span class="n">prompts_embedding_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="473">        <span class="n">all_losses</span> <span class="o">=</span> <span class="n">masked_loss</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
</span><span data-line="474">
</span><span data-line="475">        <span class="n">span_mask</span> <span class="o">=</span> <span class="n">span_mask</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span data-line="476">
</span><span data-line="477">        <span class="n">all_losses</span> <span class="o">=</span> <span class="n">all_losses</span> <span class="o">*</span> <span class="n">span_mask</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</span><span data-line="478">
</span><span data-line="479">        <span class="k">if</span> <span class="n">reduction</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
</span><span data-line="480">            <span class="n">loss</span> <span class="o">=</span> <span class="n">all_losses</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span data-line="481">        <span class="k">elif</span> <span class="n">reduction</span> <span class="o">==</span> <span class="s2">&quot;sum&quot;</span><span class="p">:</span>
</span><span data-line="482">            <span class="n">loss</span> <span class="o">=</span> <span class="n">all_losses</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span data-line="483">        <span class="k">else</span><span class="p">:</span>
</span><span data-line="484">            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
</span><span data-line="485">                <span class="sa">f</span><span class="s2">&quot;Invalid Value for config &#39;loss_reduction&#39;: &#39;</span><span class="si">{</span><span class="n">reduction</span><span class="si">}</span><span class="s2">&#39; </span><span class="se">\n</span><span class="s2"> Supported reduction modes:&quot;</span>
</span><span data-line="486">                <span class="sa">f</span><span class="s2">&quot; &#39;none&#39;, &#39;mean&#39;, &#39;sum&#39;. It will be used &#39;sum&#39; instead.&quot;</span><span class="p">,</span>
</span><span data-line="487">                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span data-line="488">            <span class="p">)</span>
</span><span data-line="489">            <span class="n">loss</span> <span class="o">=</span> <span class="n">all_losses</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span data-line="490">
</span><span data-line="491">        <span class="k">return</span> <span class="n">loss</span></div>
</div>

</span><span data-line="492">
</span><span data-line="493">
<div class="viewcode-block" id="UniEncoderTokenModel">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderTokenModel">[docs]</a>
</span><span data-line="494"><span class="k">class</span><span class="w"> </span><span class="nc">UniEncoderTokenModel</span><span class="p">(</span><span class="n">BaseUniEncoderModel</span><span class="p">):</span>
</span><span data-line="495"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Token-based NER model using uni-encoder architecture.</span>
</span><span data-line="496">
</span><span data-line="497"><span class="sd">    This model classifies each word independently as entity type or non-entity.</span>
</span><span data-line="498">
</span><span data-line="499"><span class="sd">    Attributes:</span>
</span><span data-line="500"><span class="sd">        scorer (Scorer): Scoring layer for computing token-label compatibility.</span>
</span><span data-line="501"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="502">
<div class="viewcode-block" id="UniEncoderTokenModel.__init__">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderTokenModel.__init__">[docs]</a>
</span><span data-line="503">    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span data-line="504">        <span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="505">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="506"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the token-based uni-encoder model.</span>
</span><span data-line="507">
</span><span data-line="508"><span class="sd">        Args:</span>
</span><span data-line="509"><span class="sd">            config: Model configuration object.</span>
</span><span data-line="510"><span class="sd">            from_pretrained: Whether to load from pretrained weights.</span>
</span><span data-line="511"><span class="sd">            cache_dir: Directory for caching pretrained models.</span>
</span><span data-line="512"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="513">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">)</span>
</span><span data-line="514">        <span class="bp">self</span><span class="o">.</span><span class="n">scorer</span> <span class="o">=</span> <span class="n">Scorer</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">dropout</span><span class="p">)</span>
</span><span data-line="515">
</span><span data-line="516">        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;represent_spans&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
</span><span data-line="517">            <span class="bp">self</span><span class="o">.</span><span class="n">span_rep_layer</span> <span class="o">=</span> <span class="n">SpanRepLayer</span><span class="p">(</span>
</span><span data-line="518">                <span class="n">span_mode</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">span_mode</span><span class="p">,</span>
</span><span data-line="519">                <span class="n">hidden_size</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span>
</span><span data-line="520">                <span class="n">max_width</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;max_width&quot;</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span>
</span><span data-line="521">                <span class="n">dropout</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span>
</span><span data-line="522">            <span class="p">)</span></div>

</span><span data-line="523">
<div class="viewcode-block" id="UniEncoderTokenModel.get_span_representations">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderTokenModel.get_span_representations">[docs]</a>
</span><span data-line="524">    <span class="k">def</span><span class="w"> </span><span class="nf">get_span_representations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">span_idx</span><span class="p">,</span> <span class="n">span_mask</span><span class="p">,</span> <span class="n">words_embedding</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">threshold</span><span class="p">):</span>
</span><span data-line="525">        <span class="k">if</span> <span class="n">span_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="526">            <span class="n">span_idx</span><span class="p">,</span> <span class="n">span_mask</span> <span class="o">=</span> <span class="n">extract_spans_from_tokens</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span>
</span><span data-line="527">            <span class="n">span_idx</span> <span class="o">=</span> <span class="n">span_idx</span> <span class="o">*</span> <span class="n">span_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
</span><span data-line="528">
</span><span data-line="529">        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;represent_spans&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
</span><span data-line="530">            <span class="n">span_rep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">span_rep_layer</span><span class="p">(</span><span class="n">words_embedding</span><span class="p">,</span> <span class="n">span_idx</span><span class="p">)</span>
</span><span data-line="531">        <span class="k">else</span><span class="p">:</span>
</span><span data-line="532">            <span class="n">span_rep</span> <span class="o">=</span> <span class="n">words_embedding</span><span class="p">[</span><span class="n">span_idx</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]]</span> <span class="o">+</span> <span class="n">words_embedding</span><span class="p">[</span><span class="n">span_idx</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]]</span>
</span><span data-line="533">
</span><span data-line="534">            <span class="c1"># span_rep = torch.zeros(B, S, D, device=words_embedding.device, dtype=words_embedding.dtype)</span>
</span><span data-line="535">            <span class="c1"># for b in range(B):</span>
</span><span data-line="536">            <span class="c1">#     for s in range(S):</span>
</span><span data-line="537">            <span class="c1">#         if span_mask[b, s]:</span>
</span><span data-line="538">            <span class="c1">#             start, end = span_idx[b, s]</span>
</span><span data-line="539">            <span class="c1">#             span_rep[b, s] = words_embedding[b, start:end+1].mean(dim=0)</span>
</span><span data-line="540">
</span><span data-line="541">        <span class="k">return</span> <span class="n">span_rep</span><span class="p">,</span> <span class="n">span_idx</span><span class="p">,</span> <span class="n">span_mask</span></div>

</span><span data-line="542">
<div class="viewcode-block" id="UniEncoderTokenModel.forward">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderTokenModel.forward">[docs]</a>
</span><span data-line="543">    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span data-line="544">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="545">        <span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="546">        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="547">        <span class="n">words_embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="548">        <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="549">        <span class="n">span_idx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="550">        <span class="n">span_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="551">        <span class="n">span_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="552">        <span class="n">prompts_embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="553">        <span class="n">prompts_embedding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="554">        <span class="n">words_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="555">        <span class="n">text_lengths</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="556">        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="557">        <span class="n">threshold</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
</span><span data-line="558">        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span data-line="559">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GLiNERBaseOutput</span><span class="p">:</span>
</span><span data-line="560"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward pass through the token-based model.</span>
</span><span data-line="561">
</span><span data-line="562"><span class="sd">        Args:</span>
</span><span data-line="563"><span class="sd">            input_ids: Input token IDs of shape (B, L).</span>
</span><span data-line="564"><span class="sd">            attention_mask: Attention mask of shape (B, L).</span>
</span><span data-line="565"><span class="sd">            words_embedding: Pre-computed word embeddings of shape (B, W, D).</span>
</span><span data-line="566"><span class="sd">            mask: Mask for valid words of shape (B, W).</span>
</span><span data-line="567"><span class="sd">            span_idx: Tensor containing span start/end indices of shape (B, S, 2),</span>
</span><span data-line="568"><span class="sd">                where S is the number of spans.</span>
</span><span data-line="569"><span class="sd">            span_mask: Boolean or integer mask indicating valid spans of shape (B, S).</span>
</span><span data-line="570"><span class="sd">            span_labels: Ground truth span labels of shape (B, S, C).</span>
</span><span data-line="571"><span class="sd">            prompts_embedding: Pre-computed entity label embeddings of shape (B, C, D).</span>
</span><span data-line="572"><span class="sd">            prompts_embedding_mask: Mask for prompts/entities of shape (B, C).</span>
</span><span data-line="573"><span class="sd">            words_mask: Word boundary mask mapping tokens to words.</span>
</span><span data-line="574"><span class="sd">            text_lengths: Length of each text sequence before padding, shape (B,).</span>
</span><span data-line="575"><span class="sd">            labels: Ground truth token-level labels of shape (B, W, C).</span>
</span><span data-line="576"><span class="sd">            threshold: Confidence threshold used for span selection.</span>
</span><span data-line="577"><span class="sd">            **kwargs: Additional arguments passed to the encoder or loss functions</span>
</span><span data-line="578"><span class="sd">                (e.g., ``packing_config``, ``pair_attention_mask``).</span>
</span><span data-line="579">
</span><span data-line="580"><span class="sd">        Returns:</span>
</span><span data-line="581"><span class="sd">            GLiNERBaseOutput containing logits, loss, embeddings, and span-level outputs.</span>
</span><span data-line="582"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="583">        <span class="n">encoder_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">kwargs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;packing_config&quot;</span><span class="p">,</span> <span class="s2">&quot;pair_attention_mask&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">}</span>
</span><span data-line="584">
</span><span data-line="585">        <span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">,</span> <span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_representations</span><span class="p">(</span>
</span><span data-line="586">            <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">text_lengths</span><span class="p">,</span> <span class="n">words_mask</span><span class="p">,</span> <span class="o">**</span><span class="n">encoder_kwargs</span>
</span><span data-line="587">        <span class="p">)</span>
</span><span data-line="588">
</span><span data-line="589">        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="590">            <span class="n">target_W</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span data-line="591">            <span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_length</span><span class="p">(</span><span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">target_W</span><span class="p">)</span>
</span><span data-line="592">
</span><span data-line="593">            <span class="n">target_C</span> <span class="o">=</span> <span class="n">prompts_embedding</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="594">            <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="595">                <span class="n">target_C</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">target_C</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">))</span>
</span><span data-line="596">
</span><span data-line="597">            <span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_length</span><span class="p">(</span>
</span><span data-line="598">                <span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">,</span> <span class="n">target_C</span>
</span><span data-line="599">            <span class="p">)</span>
</span><span data-line="600">
</span><span data-line="601">        <span class="c1"># Shape: (batch_size, seq_len, num_classes, 3), 3 - start, end, inside</span>
</span><span data-line="602">        <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="p">(</span><span class="n">words_embedding</span><span class="p">,</span> <span class="n">prompts_embedding</span><span class="p">)</span>
</span><span data-line="603">
</span><span data-line="604">        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;represent_spans&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
</span><span data-line="605">            <span class="n">span_rep</span><span class="p">,</span> <span class="n">span_idx</span><span class="p">,</span> <span class="n">span_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_span_representations</span><span class="p">(</span>
</span><span data-line="606">                <span class="n">scores</span><span class="p">,</span> <span class="n">span_idx</span><span class="p">,</span> <span class="n">span_mask</span><span class="p">,</span> <span class="n">words_embedding</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">threshold</span>
</span><span data-line="607">            <span class="p">)</span>
</span><span data-line="608">            <span class="n">span_logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;BND,BCD-&gt;BNC&quot;</span><span class="p">,</span> <span class="n">span_rep</span><span class="p">,</span> <span class="n">prompts_embedding</span><span class="p">)</span>
</span><span data-line="609">        <span class="k">else</span><span class="p">:</span>
</span><span data-line="610">            <span class="n">span_logits</span><span class="p">,</span> <span class="n">span_idx</span><span class="p">,</span> <span class="n">span_mask</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
</span><span data-line="611">        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="612">        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="613">            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span data-line="614">
</span><span data-line="615">            <span class="k">if</span> <span class="n">span_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="616">                <span class="n">span_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">span_logits</span><span class="p">,</span> <span class="n">span_labels</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">,</span> <span class="n">span_mask</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span data-line="617">                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">token_loss_coef</span> <span class="o">*</span> <span class="n">loss</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">span_loss_coef</span> <span class="o">*</span> <span class="n">span_loss</span>
</span><span data-line="618">
</span><span data-line="619">        <span class="n">output</span> <span class="o">=</span> <span class="n">GLiNERBaseOutput</span><span class="p">(</span>
</span><span data-line="620">            <span class="n">logits</span><span class="o">=</span><span class="n">scores</span><span class="p">,</span>
</span><span data-line="621">            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
</span><span data-line="622">            <span class="n">prompts_embedding</span><span class="o">=</span><span class="n">prompts_embedding</span><span class="p">,</span>
</span><span data-line="623">            <span class="n">prompts_embedding_mask</span><span class="o">=</span><span class="n">prompts_embedding_mask</span><span class="p">,</span>
</span><span data-line="624">            <span class="n">words_embedding</span><span class="o">=</span><span class="n">words_embedding</span><span class="p">,</span>
</span><span data-line="625">            <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span>
</span><span data-line="626">            <span class="n">span_idx</span><span class="o">=</span><span class="n">span_idx</span><span class="p">,</span>
</span><span data-line="627">            <span class="n">span_logits</span><span class="o">=</span><span class="n">span_logits</span><span class="p">,</span>
</span><span data-line="628">            <span class="n">span_mask</span><span class="o">=</span><span class="n">span_mask</span><span class="p">,</span>
</span><span data-line="629">        <span class="p">)</span>
</span><span data-line="630">        <span class="k">return</span> <span class="n">output</span></div>

</span><span data-line="631">
<div class="viewcode-block" id="UniEncoderTokenModel.loss">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderTokenModel.loss">[docs]</a>
</span><span data-line="632">    <span class="k">def</span><span class="w"> </span><span class="nf">loss</span><span class="p">(</span>
</span><span data-line="633">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="634">        <span class="n">scores</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="635">        <span class="n">labels</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="636">        <span class="n">prompts_embedding_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="637">        <span class="n">word_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="638">        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span>
</span><span data-line="639">        <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="640">        <span class="n">prob_margin</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="641">        <span class="n">label_smoothing</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="642">        <span class="n">reduction</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sum&quot;</span><span class="p">,</span>
</span><span data-line="643">        <span class="n">negatives</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span data-line="644">        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span data-line="645">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span data-line="646"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute token- or span-level classification loss.</span>
</span><span data-line="647">
</span><span data-line="648"><span class="sd">        Args:</span>
</span><span data-line="649"><span class="sd">            scores: Predicted scores. Shape is (B, W, C, 3) for token-level</span>
</span><span data-line="650"><span class="sd">                classification (start, end, inside) or (B, N, C) for span-level</span>
</span><span data-line="651"><span class="sd">                classification, where B is batch size, W is number of words,</span>
</span><span data-line="652"><span class="sd">                N is number of spans, and C is number of entity types.</span>
</span><span data-line="653"><span class="sd">            labels: Ground truth labels matching ``scores`` shape.</span>
</span><span data-line="654"><span class="sd">            prompts_embedding_mask: Mask for valid entity types of shape (B, C).</span>
</span><span data-line="655"><span class="sd">            word_mask: Mask for valid tokens or spans of shape (B, W) for</span>
</span><span data-line="656"><span class="sd">                token-level loss or (B, N) for span-level loss.</span>
</span><span data-line="657"><span class="sd">            alpha: Alpha parameter for focal loss. If negative, focal weighting</span>
</span><span data-line="658"><span class="sd">                is disabled.</span>
</span><span data-line="659"><span class="sd">            gamma: Gamma parameter for focal loss.</span>
</span><span data-line="660"><span class="sd">            prob_margin: Margin applied to predicted probabilities.</span>
</span><span data-line="661"><span class="sd">            label_smoothing: Amount of label smoothing applied to targets.</span>
</span><span data-line="662"><span class="sd">            reduction: Reduction method applied to the final loss. One of</span>
</span><span data-line="663"><span class="sd">                ``&quot;none&quot;``, ``&quot;mean&quot;``, or ``&quot;sum&quot;``.</span>
</span><span data-line="664"><span class="sd">            negatives: Weighting factor for negative examples.</span>
</span><span data-line="665"><span class="sd">            **kwargs: Additional unused keyword arguments for API compatibility.</span>
</span><span data-line="666">
</span><span data-line="667"><span class="sd">        Returns:</span>
</span><span data-line="668"><span class="sd">            A scalar tensor representing the aggregated loss value.</span>
</span><span data-line="669"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="670">        <span class="n">all_losses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">prob_margin</span><span class="p">,</span> <span class="n">label_smoothing</span><span class="p">,</span> <span class="n">negatives</span><span class="p">)</span>
</span><span data-line="671">
</span><span data-line="672">        <span class="c1"># Base mask: (B, W/N, C)</span>
</span><span data-line="673">        <span class="n">mask</span> <span class="o">=</span> <span class="n">word_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">prompts_embedding_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="674">
</span><span data-line="675">        <span class="c1"># Only add extra dimension for 4D token-level scores (B, W, C, 3)</span>
</span><span data-line="676">        <span class="k">if</span> <span class="n">all_losses</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
</span><span data-line="677">            <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="678">
</span><span data-line="679">        <span class="n">all_losses</span> <span class="o">=</span> <span class="n">all_losses</span> <span class="o">*</span> <span class="n">mask</span>
</span><span data-line="680">
</span><span data-line="681">        <span class="k">if</span> <span class="n">reduction</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
</span><span data-line="682">            <span class="n">loss</span> <span class="o">=</span> <span class="n">all_losses</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span data-line="683">        <span class="k">elif</span> <span class="n">reduction</span> <span class="o">==</span> <span class="s2">&quot;sum&quot;</span><span class="p">:</span>
</span><span data-line="684">            <span class="n">loss</span> <span class="o">=</span> <span class="n">all_losses</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span data-line="685">        <span class="k">else</span><span class="p">:</span>
</span><span data-line="686">            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
</span><span data-line="687">                <span class="sa">f</span><span class="s2">&quot;Invalid Value for config &#39;loss_reduction&#39;: &#39;</span><span class="si">{</span><span class="n">reduction</span><span class="si">}</span><span class="s2">&#39; </span><span class="se">\n</span><span class="s2"> Supported reduction modes:&quot;</span>
</span><span data-line="688">                <span class="sa">f</span><span class="s2">&quot; &#39;none&#39;, &#39;mean&#39;, &#39;sum&#39;. It will be used &#39;sum&#39; instead.&quot;</span><span class="p">,</span>
</span><span data-line="689">                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span data-line="690">            <span class="p">)</span>
</span><span data-line="691">            <span class="n">loss</span> <span class="o">=</span> <span class="n">all_losses</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span data-line="692">        <span class="k">return</span> <span class="n">loss</span></div>
</div>

</span><span data-line="693">
</span><span data-line="694">
<div class="viewcode-block" id="BaseBiEncoderModel">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.BaseBiEncoderModel">[docs]</a>
</span><span data-line="695"><span class="k">class</span><span class="w"> </span><span class="nc">BaseBiEncoderModel</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
</span><span data-line="696"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Base class for bi-encoder model architectures.</span>
</span><span data-line="697">
</span><span data-line="698"><span class="sd">    Bi-encoder models use separate encoders for text and entity labels,</span>
</span><span data-line="699"><span class="sd">    allowing independent encoding before fusion.</span>
</span><span data-line="700">
</span><span data-line="701"><span class="sd">    Attributes:</span>
</span><span data-line="702"><span class="sd">        token_rep_layer (BiEncoder): Bi-encoder for text and labels.</span>
</span><span data-line="703"><span class="sd">        rnn (Optional[LstmSeq2SeqEncoder]): Optional LSTM layer.</span>
</span><span data-line="704"><span class="sd">        cross_fuser (Optional[CrossFuser]): Optional cross-attention fusion layer.</span>
</span><span data-line="705"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="706">
<div class="viewcode-block" id="BaseBiEncoderModel.__init__">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.BaseBiEncoderModel.__init__">[docs]</a>
</span><span data-line="707">    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span data-line="708">        <span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="709">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="710"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the bi-encoder model.</span>
</span><span data-line="711">
</span><span data-line="712"><span class="sd">        Args:</span>
</span><span data-line="713"><span class="sd">            config: Model configuration object.</span>
</span><span data-line="714"><span class="sd">            from_pretrained: Whether to load from pretrained weights.</span>
</span><span data-line="715"><span class="sd">            cache_dir: Directory for caching pretrained models.</span>
</span><span data-line="716"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="717">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">)</span>
</span><span data-line="718">        <span class="bp">self</span><span class="o">.</span><span class="n">token_rep_layer</span> <span class="o">=</span> <span class="n">BiEncoder</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">,</span> <span class="n">cache_dir</span><span class="o">=</span><span class="n">cache_dir</span><span class="p">)</span>
</span><span data-line="719">
</span><span data-line="720">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_rnn_layers</span><span class="p">:</span>
</span><span data-line="721">            <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">LstmSeq2SeqEncoder</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_rnn_layers</span><span class="p">)</span>
</span><span data-line="722">
</span><span data-line="723">        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">post_fusion_schema</span><span class="p">:</span>
</span><span data-line="724">            <span class="bp">self</span><span class="o">.</span><span class="n">cross_fuser</span> <span class="o">=</span> <span class="n">CrossFuser</span><span class="p">(</span>
</span><span data-line="725">                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span>
</span><span data-line="726">                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span>
</span><span data-line="727">                <span class="n">num_heads</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">token_rep_layer</span><span class="o">.</span><span class="n">bert_layer</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">,</span>
</span><span data-line="728">                <span class="n">num_layers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_post_fusion_layers</span><span class="p">,</span>
</span><span data-line="729">                <span class="n">dropout</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span>
</span><span data-line="730">                <span class="n">schema</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">post_fusion_schema</span><span class="p">,</span>
</span><span data-line="731">            <span class="p">)</span></div>

</span><span data-line="732">
<div class="viewcode-block" id="BaseBiEncoderModel.features_enhancement">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.BaseBiEncoderModel.features_enhancement">[docs]</a>
</span><span data-line="733">    <span class="k">def</span><span class="w"> </span><span class="nf">features_enhancement</span><span class="p">(</span>
</span><span data-line="734">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="735">        <span class="n">text_embeds</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="736">        <span class="n">labels_embeds</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="737">        <span class="n">text_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="738">        <span class="n">labels_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="739">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span data-line="740"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Enhance features using cross-attention fusion.</span>
</span><span data-line="741">
</span><span data-line="742"><span class="sd">        Args:</span>
</span><span data-line="743"><span class="sd">            text_embeds: Text embeddings of shape (B, W, D).</span>
</span><span data-line="744"><span class="sd">            labels_embeds: Label embeddings of shape (B, C, D).</span>
</span><span data-line="745"><span class="sd">            text_mask: Mask for text of shape (B, W).</span>
</span><span data-line="746"><span class="sd">            labels_mask: Mask for labels of shape (B, C).</span>
</span><span data-line="747">
</span><span data-line="748"><span class="sd">        Returns:</span>
</span><span data-line="749"><span class="sd">            Tuple containing:</span>
</span><span data-line="750"><span class="sd">                - Enhanced text embeddings of shape (B, W, D).</span>
</span><span data-line="751"><span class="sd">                - Enhanced label embeddings of shape (B, C, D).</span>
</span><span data-line="752"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="753">        <span class="n">labels_embeds</span><span class="p">,</span> <span class="n">text_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_fuser</span><span class="p">(</span><span class="n">labels_embeds</span><span class="p">,</span> <span class="n">text_embeds</span><span class="p">,</span> <span class="n">labels_mask</span><span class="p">,</span> <span class="n">text_mask</span><span class="p">)</span>
</span><span data-line="754">        <span class="k">return</span> <span class="n">text_embeds</span><span class="p">,</span> <span class="n">labels_embeds</span></div>

</span><span data-line="755">
<div class="viewcode-block" id="BaseBiEncoderModel.get_representations">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.BaseBiEncoderModel.get_representations">[docs]</a>
</span><span data-line="756">    <span class="k">def</span><span class="w"> </span><span class="nf">get_representations</span><span class="p">(</span>
</span><span data-line="757">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="758">        <span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="759">        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="760">        <span class="n">labels_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="761">        <span class="n">labels_input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="762">        <span class="n">labels_attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="763">        <span class="n">text_lengths</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="764">        <span class="n">words_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="765">        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span data-line="766">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span data-line="767"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Get entity label and word representations using bi-encoder.</span>
</span><span data-line="768">
</span><span data-line="769"><span class="sd">        Args:</span>
</span><span data-line="770"><span class="sd">            input_ids: Input token IDs of shape (B, L).</span>
</span><span data-line="771"><span class="sd">            attention_mask: Attention mask of shape (B, L).</span>
</span><span data-line="772"><span class="sd">            labels_embeds: Pre-computed label embeddings of shape (C, D).</span>
</span><span data-line="773"><span class="sd">            labels_input_ids: Label token IDs for encoding.</span>
</span><span data-line="774"><span class="sd">            labels_attention_mask: Attention mask for labels.</span>
</span><span data-line="775"><span class="sd">            text_lengths: Length of each text in batch.</span>
</span><span data-line="776"><span class="sd">            words_mask: Word boundary mask.</span>
</span><span data-line="777"><span class="sd">            **kwargs: Additional arguments for the encoder.</span>
</span><span data-line="778">
</span><span data-line="779"><span class="sd">        Returns:</span>
</span><span data-line="780"><span class="sd">            Tuple containing:</span>
</span><span data-line="781"><span class="sd">                - labels_embeds: Label embeddings of shape (B, C, D).</span>
</span><span data-line="782"><span class="sd">                - labels_mask: Mask for labels of shape (B, C).</span>
</span><span data-line="783"><span class="sd">                - words_embedding: Word embeddings of shape (B, W, D).</span>
</span><span data-line="784"><span class="sd">                - mask: Mask for words of shape (B, W).</span>
</span><span data-line="785"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="786">        <span class="k">if</span> <span class="n">labels_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="787">            <span class="n">token_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_rep_layer</span><span class="o">.</span><span class="n">encode_text</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span data-line="788">        <span class="k">else</span><span class="p">:</span>
</span><span data-line="789">            <span class="n">token_embeds</span><span class="p">,</span> <span class="n">labels_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_rep_layer</span><span class="p">(</span>
</span><span data-line="790">                <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">labels_input_ids</span><span class="p">,</span> <span class="n">labels_attention_mask</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
</span><span data-line="791">            <span class="p">)</span>
</span><span data-line="792">
</span><span data-line="793">        <span class="n">batch_size</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">embed_dim</span> <span class="o">=</span> <span class="n">token_embeds</span><span class="o">.</span><span class="n">shape</span>  <span class="c1"># batch size, seq length, embed dim</span>
</span><span data-line="794">        <span class="n">max_text_length</span> <span class="o">=</span> <span class="n">text_lengths</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
</span><span data-line="795">
</span><span data-line="796">        <span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="n">extract_word_embeddings</span><span class="p">(</span>
</span><span data-line="797">            <span class="n">token_embeds</span><span class="p">,</span> <span class="n">words_mask</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">max_text_length</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">text_lengths</span>
</span><span data-line="798">        <span class="p">)</span>
</span><span data-line="799">
</span><span data-line="800">        <span class="n">labels_embeds</span> <span class="o">=</span> <span class="n">labels_embeds</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span data-line="801">        <span class="n">labels_embeds</span> <span class="o">=</span> <span class="n">labels_embeds</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="802">        <span class="n">labels_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">labels_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">attention_mask</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">attention_mask</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span data-line="803">
</span><span data-line="804">        <span class="n">labels_embeds</span> <span class="o">=</span> <span class="n">labels_embeds</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">words_embedding</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span data-line="805">
</span><span data-line="806">        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;cross_fuser&quot;</span><span class="p">):</span>
</span><span data-line="807">            <span class="n">words_embedding</span><span class="p">,</span> <span class="n">labels_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features_enhancement</span><span class="p">(</span>
</span><span data-line="808">                <span class="n">words_embedding</span><span class="p">,</span> <span class="n">labels_embeds</span><span class="p">,</span> <span class="n">text_mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">labels_mask</span><span class="o">=</span><span class="n">labels_mask</span>
</span><span data-line="809">            <span class="p">)</span>
</span><span data-line="810">
</span><span data-line="811">        <span class="k">return</span> <span class="n">labels_embeds</span><span class="p">,</span> <span class="n">labels_mask</span><span class="p">,</span> <span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span></div>
</div>

</span><span data-line="812">
</span><span data-line="813">
<div class="viewcode-block" id="BiEncoderSpanModel">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.BiEncoderSpanModel">[docs]</a>
</span><span data-line="814"><span class="k">class</span><span class="w"> </span><span class="nc">BiEncoderSpanModel</span><span class="p">(</span><span class="n">BaseBiEncoderModel</span><span class="p">):</span>
</span><span data-line="815"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Span-based NER model using bi-encoder architecture.</span>
</span><span data-line="816">
</span><span data-line="817"><span class="sd">    Attributes:</span>
</span><span data-line="818"><span class="sd">        span_rep_layer (SpanRepLayer): Layer for computing span representations.</span>
</span><span data-line="819"><span class="sd">        prompt_rep_layer (nn.Module): Projection layer for entity label embeddings.</span>
</span><span data-line="820"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="821">
<div class="viewcode-block" id="BiEncoderSpanModel.__init__">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.BiEncoderSpanModel.__init__">[docs]</a>
</span><span data-line="822">    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span data-line="823">        <span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="824">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="825"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the span-based bi-encoder model.</span>
</span><span data-line="826">
</span><span data-line="827"><span class="sd">        Args:</span>
</span><span data-line="828"><span class="sd">            config: Model configuration object.</span>
</span><span data-line="829"><span class="sd">            from_pretrained: Whether to load from pretrained weights.</span>
</span><span data-line="830"><span class="sd">            cache_dir: Directory for caching pretrained models.</span>
</span><span data-line="831"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="832">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">)</span>
</span><span data-line="833">        <span class="bp">self</span><span class="o">.</span><span class="n">span_rep_layer</span> <span class="o">=</span> <span class="n">SpanRepLayer</span><span class="p">(</span>
</span><span data-line="834">            <span class="n">span_mode</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">span_mode</span><span class="p">,</span>
</span><span data-line="835">            <span class="n">hidden_size</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span>
</span><span data-line="836">            <span class="n">max_width</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">max_width</span><span class="p">,</span>
</span><span data-line="837">            <span class="n">dropout</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span>
</span><span data-line="838">        <span class="p">)</span>
</span><span data-line="839">
</span><span data-line="840">        <span class="bp">self</span><span class="o">.</span><span class="n">prompt_rep_layer</span> <span class="o">=</span> <span class="n">create_projection_layer</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">dropout</span><span class="p">)</span></div>

</span><span data-line="841">
<div class="viewcode-block" id="BiEncoderSpanModel.forward">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.BiEncoderSpanModel.forward">[docs]</a>
</span><span data-line="842">    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span data-line="843">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="844">        <span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="845">        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="846">        <span class="n">labels_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="847">        <span class="n">labels_input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="848">        <span class="n">labels_attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="849">        <span class="n">words_embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="850">        <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="851">        <span class="n">prompts_embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="852">        <span class="n">prompts_embedding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="853">        <span class="n">words_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="854">        <span class="n">text_lengths</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="855">        <span class="n">span_idx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="856">        <span class="n">span_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="857">        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="858">        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span data-line="859">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GLiNERBaseOutput</span><span class="p">:</span>
</span><span data-line="860"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward pass through the bi-encoder span model.</span>
</span><span data-line="861">
</span><span data-line="862"><span class="sd">        Args:</span>
</span><span data-line="863"><span class="sd">            input_ids: Input token IDs of shape (B, L).</span>
</span><span data-line="864"><span class="sd">            attention_mask: Attention mask of shape (B, L).</span>
</span><span data-line="865"><span class="sd">            labels_embeds: Pre-computed label embeddings of shape (C, D).</span>
</span><span data-line="866"><span class="sd">            labels_input_ids: Label token IDs for encoding.</span>
</span><span data-line="867"><span class="sd">            labels_attention_mask: Attention mask for labels.</span>
</span><span data-line="868"><span class="sd">            words_embedding: Pre-computed word embeddings.</span>
</span><span data-line="869"><span class="sd">            mask: Mask for words.</span>
</span><span data-line="870"><span class="sd">            prompts_embedding: Pre-computed entity label embeddings.</span>
</span><span data-line="871"><span class="sd">            prompts_embedding_mask: Mask for prompts.</span>
</span><span data-line="872"><span class="sd">            words_mask: Word boundary mask.</span>
</span><span data-line="873"><span class="sd">            text_lengths: Length of each text sequence.</span>
</span><span data-line="874"><span class="sd">            span_idx: Span indices of shape (B, L*K, 2).</span>
</span><span data-line="875"><span class="sd">            span_mask: Mask for valid spans of shape (B, L, K).</span>
</span><span data-line="876"><span class="sd">            labels: Ground truth labels of shape (B, L, K, C).</span>
</span><span data-line="877"><span class="sd">            **kwargs: Additional arguments.</span>
</span><span data-line="878">
</span><span data-line="879"><span class="sd">        Returns:</span>
</span><span data-line="880"><span class="sd">            GLiNERBaseOutput containing logits, loss, and intermediate representations.</span>
</span><span data-line="881"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="882">        <span class="n">encoder_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">kwargs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;packing_config&quot;</span><span class="p">,</span> <span class="s2">&quot;pair_attention_mask&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">}</span>
</span><span data-line="883">
</span><span data-line="884">        <span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">,</span> <span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_representations</span><span class="p">(</span>
</span><span data-line="885">            <span class="n">input_ids</span><span class="p">,</span>
</span><span data-line="886">            <span class="n">attention_mask</span><span class="p">,</span>
</span><span data-line="887">            <span class="n">labels_embeds</span><span class="p">,</span>
</span><span data-line="888">            <span class="n">labels_input_ids</span><span class="p">,</span>
</span><span data-line="889">            <span class="n">labels_attention_mask</span><span class="p">,</span>
</span><span data-line="890">            <span class="n">text_lengths</span><span class="p">,</span>
</span><span data-line="891">            <span class="n">words_mask</span><span class="p">,</span>
</span><span data-line="892">            <span class="o">**</span><span class="n">encoder_kwargs</span><span class="p">,</span>
</span><span data-line="893">        <span class="p">)</span>
</span><span data-line="894">
</span><span data-line="895">        <span class="n">target_W</span> <span class="o">=</span> <span class="n">span_idx</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_width</span>
</span><span data-line="896">        <span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_length</span><span class="p">(</span><span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">target_W</span><span class="p">)</span>
</span><span data-line="897">
</span><span data-line="898">        <span class="n">span_idx</span> <span class="o">=</span> <span class="n">span_idx</span> <span class="o">*</span> <span class="n">span_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="899">
</span><span data-line="900">        <span class="n">span_rep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">span_rep_layer</span><span class="p">(</span><span class="n">words_embedding</span><span class="p">,</span> <span class="n">span_idx</span><span class="p">)</span>
</span><span data-line="901">
</span><span data-line="902">        <span class="n">target_C</span> <span class="o">=</span> <span class="n">prompts_embedding</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="903">        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="904">            <span class="n">target_C</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">target_C</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span data-line="905">
</span><span data-line="906">        <span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_length</span><span class="p">(</span>
</span><span data-line="907">            <span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">,</span> <span class="n">target_C</span>
</span><span data-line="908">        <span class="p">)</span>
</span><span data-line="909">
</span><span data-line="910">        <span class="n">prompts_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_rep_layer</span><span class="p">(</span><span class="n">prompts_embedding</span><span class="p">)</span>
</span><span data-line="911">
</span><span data-line="912">        <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;BLKD,BCD-&gt;BLKC&quot;</span><span class="p">,</span> <span class="n">span_rep</span><span class="p">,</span> <span class="n">prompts_embedding</span><span class="p">)</span>
</span><span data-line="913">
</span><span data-line="914">        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="915">        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="916">            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">,</span> <span class="n">span_mask</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span data-line="917">
</span><span data-line="918">        <span class="n">output</span> <span class="o">=</span> <span class="n">GLiNERBaseOutput</span><span class="p">(</span>
</span><span data-line="919">            <span class="n">logits</span><span class="o">=</span><span class="n">scores</span><span class="p">,</span>
</span><span data-line="920">            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
</span><span data-line="921">            <span class="n">prompts_embedding</span><span class="o">=</span><span class="n">prompts_embedding</span><span class="p">,</span>
</span><span data-line="922">            <span class="n">prompts_embedding_mask</span><span class="o">=</span><span class="n">prompts_embedding_mask</span><span class="p">,</span>
</span><span data-line="923">            <span class="n">words_embedding</span><span class="o">=</span><span class="n">words_embedding</span><span class="p">,</span>
</span><span data-line="924">            <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span>
</span><span data-line="925">        <span class="p">)</span>
</span><span data-line="926">        <span class="k">return</span> <span class="n">output</span></div>

</span><span data-line="927">
<div class="viewcode-block" id="BiEncoderSpanModel.loss">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.BiEncoderSpanModel.loss">[docs]</a>
</span><span data-line="928">    <span class="k">def</span><span class="w"> </span><span class="nf">loss</span><span class="p">(</span>
</span><span data-line="929">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="930">        <span class="n">scores</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="931">        <span class="n">labels</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="932">        <span class="n">prompts_embedding_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="933">        <span class="n">mask_label</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="934">        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span>
</span><span data-line="935">        <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="936">        <span class="n">label_smoothing</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="937">        <span class="n">reduction</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sum&quot;</span><span class="p">,</span>
</span><span data-line="938">        <span class="n">negatives</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span data-line="939">        <span class="n">masking</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;none&quot;</span><span class="p">,</span>
</span><span data-line="940">        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span data-line="941">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span data-line="942"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute span classification loss for bi-encoder.</span>
</span><span data-line="943">
</span><span data-line="944"><span class="sd">        Args:</span>
</span><span data-line="945"><span class="sd">            scores: Predicted scores of shape (B, L, K, C).</span>
</span><span data-line="946"><span class="sd">            labels: Ground truth labels of shape (B, L, K, C).</span>
</span><span data-line="947"><span class="sd">            prompts_embedding_mask: Mask for valid entity types of shape (B, C).</span>
</span><span data-line="948"><span class="sd">            mask_label: Mask for valid spans of shape (B, L, K).</span>
</span><span data-line="949"><span class="sd">            alpha: Focal loss alpha parameter.</span>
</span><span data-line="950"><span class="sd">            gamma: Focal loss gamma parameter.</span>
</span><span data-line="951"><span class="sd">            label_smoothing: Label smoothing factor.</span>
</span><span data-line="952"><span class="sd">            reduction: Loss reduction method (&#39;sum&#39; or &#39;mean&#39;).</span>
</span><span data-line="953"><span class="sd">            negatives: Negative sampling probability.</span>
</span><span data-line="954"><span class="sd">            masking: Masking strategy for negative sampling.</span>
</span><span data-line="955"><span class="sd">            **kwargs: Additional arguments.</span>
</span><span data-line="956">
</span><span data-line="957"><span class="sd">        Returns:</span>
</span><span data-line="958"><span class="sd">            Scalar loss tensor.</span>
</span><span data-line="959"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="960">        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span data-line="961">        <span class="n">num_classes</span> <span class="o">=</span> <span class="n">prompts_embedding_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span data-line="962">
</span><span data-line="963">        <span class="c1"># Reshape scores and labels to match the expected shape</span>
</span><span data-line="964">        <span class="n">BS</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">CL</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">shape</span>
</span><span data-line="965">
</span><span data-line="966">        <span class="n">scores</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">BS</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">CL</span><span class="p">)</span>
</span><span data-line="967">        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">BS</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">CL</span><span class="p">)</span>
</span><span data-line="968">
</span><span data-line="969">        <span class="n">all_losses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">label_smoothing</span><span class="p">,</span> <span class="n">negatives</span><span class="o">=</span><span class="n">negatives</span><span class="p">,</span> <span class="n">masking</span><span class="o">=</span><span class="n">masking</span><span class="p">)</span>
</span><span data-line="970">
</span><span data-line="971">        <span class="n">masked_loss</span> <span class="o">=</span> <span class="n">all_losses</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span> <span class="o">*</span> <span class="n">prompts_embedding_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="972">        <span class="n">all_losses</span> <span class="o">=</span> <span class="n">masked_loss</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
</span><span data-line="973">
</span><span data-line="974">        <span class="n">mask_label</span> <span class="o">=</span> <span class="n">mask_label</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span data-line="975">
</span><span data-line="976">        <span class="n">all_losses</span> <span class="o">=</span> <span class="n">all_losses</span> <span class="o">*</span> <span class="n">mask_label</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</span><span data-line="977">
</span><span data-line="978">        <span class="k">if</span> <span class="n">reduction</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
</span><span data-line="979">            <span class="n">loss</span> <span class="o">=</span> <span class="n">all_losses</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span data-line="980">        <span class="k">elif</span> <span class="n">reduction</span> <span class="o">==</span> <span class="s2">&quot;sum&quot;</span><span class="p">:</span>
</span><span data-line="981">            <span class="n">loss</span> <span class="o">=</span> <span class="n">all_losses</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span data-line="982">        <span class="k">else</span><span class="p">:</span>
</span><span data-line="983">            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
</span><span data-line="984">                <span class="sa">f</span><span class="s2">&quot;Invalid Value for config &#39;loss_reduction&#39;: &#39;</span><span class="si">{</span><span class="n">reduction</span><span class="si">}</span><span class="s2">&#39; </span><span class="se">\n</span><span class="s2"> Supported reduction modes:&quot;</span>
</span><span data-line="985">                <span class="sa">f</span><span class="s2">&quot; &#39;none&#39;, &#39;mean&#39;, &#39;sum&#39;. It will be used &#39;sum&#39; instead.&quot;</span><span class="p">,</span>
</span><span data-line="986">                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span data-line="987">            <span class="p">)</span>
</span><span data-line="988">            <span class="n">loss</span> <span class="o">=</span> <span class="n">all_losses</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span data-line="989">
</span><span data-line="990">        <span class="k">return</span> <span class="n">loss</span></div>
</div>

</span><span data-line="991">
</span><span data-line="992">
<div class="viewcode-block" id="BiEncoderTokenModel">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.BiEncoderTokenModel">[docs]</a>
</span><span data-line="993"><span class="k">class</span><span class="w"> </span><span class="nc">BiEncoderTokenModel</span><span class="p">(</span><span class="n">BaseBiEncoderModel</span><span class="p">,</span> <span class="n">UniEncoderTokenModel</span><span class="p">):</span>
</span><span data-line="994"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Token-based NER model using bi-encoder architecture.</span>
</span><span data-line="995">
</span><span data-line="996"><span class="sd">    Attributes:</span>
</span><span data-line="997"><span class="sd">        scorer (Scorer): Scoring layer for computing token-label compatibility.</span>
</span><span data-line="998"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="999">
<div class="viewcode-block" id="BiEncoderTokenModel.__init__">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.BiEncoderTokenModel.__init__">[docs]</a>
</span><span data-line="1000">    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span data-line="1001">        <span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="1002">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="1003"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the token-based bi-encoder model.</span>
</span><span data-line="1004">
</span><span data-line="1005"><span class="sd">        Args:</span>
</span><span data-line="1006"><span class="sd">            config: Model configuration object.</span>
</span><span data-line="1007"><span class="sd">            from_pretrained: Whether to load from pretrained weights.</span>
</span><span data-line="1008"><span class="sd">            cache_dir: Directory for caching pretrained models.</span>
</span><span data-line="1009"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="1010">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">)</span>
</span><span data-line="1011">        <span class="bp">self</span><span class="o">.</span><span class="n">scorer</span> <span class="o">=</span> <span class="n">Scorer</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">dropout</span><span class="p">)</span></div>

</span><span data-line="1012">
<div class="viewcode-block" id="BiEncoderTokenModel.forward">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.BiEncoderTokenModel.forward">[docs]</a>
</span><span data-line="1013">    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span data-line="1014">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="1015">        <span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1016">        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1017">        <span class="n">labels_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1018">        <span class="n">labels_input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1019">        <span class="n">labels_attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1020">        <span class="n">words_embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1021">        <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1022">        <span class="n">span_idx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1023">        <span class="n">span_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1024">        <span class="n">span_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1025">        <span class="n">prompts_embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1026">        <span class="n">prompts_embedding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1027">        <span class="n">words_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1028">        <span class="n">text_lengths</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1029">        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1030">        <span class="n">threshold</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
</span><span data-line="1031">        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span data-line="1032">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GLiNERBaseOutput</span><span class="p">:</span>
</span><span data-line="1033"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward pass through the bi-encoder token model.</span>
</span><span data-line="1034">
</span><span data-line="1035"><span class="sd">        Args:</span>
</span><span data-line="1036"><span class="sd">            input_ids: Input token IDs of shape (B, L).</span>
</span><span data-line="1037"><span class="sd">            attention_mask: Attention mask of shape (B, L).</span>
</span><span data-line="1038"><span class="sd">            labels_embeds: Pre-computed label embeddings of shape (C, D).</span>
</span><span data-line="1039"><span class="sd">            labels_input_ids: Label token IDs for encoding.</span>
</span><span data-line="1040"><span class="sd">            labels_attention_mask: Attention mask for labels.</span>
</span><span data-line="1041"><span class="sd">            words_embedding: Pre-computed word embeddings.</span>
</span><span data-line="1042"><span class="sd">            mask: Mask for words.</span>
</span><span data-line="1043"><span class="sd">            span_idx: Tensor containing span start/end indices of shape (B, S, 2),</span>
</span><span data-line="1044"><span class="sd">                where S is the number of spans.</span>
</span><span data-line="1045"><span class="sd">            span_mask: Boolean or integer mask indicating valid spans of shape (B, S).</span>
</span><span data-line="1046"><span class="sd">            span_labels: Ground truth span labels of shape (B, S, C).</span>
</span><span data-line="1047"><span class="sd">            prompts_embedding: Pre-computed entity label embeddings.</span>
</span><span data-line="1048"><span class="sd">            prompts_embedding_mask: Mask for prompts.</span>
</span><span data-line="1049"><span class="sd">            words_mask: Word boundary mask.</span>
</span><span data-line="1050"><span class="sd">            text_lengths: Length of each text sequence.</span>
</span><span data-line="1051"><span class="sd">            labels: Ground truth labels of shape (B, W, C).</span>
</span><span data-line="1052"><span class="sd">            threshold: float value for filtering spans.</span>
</span><span data-line="1053"><span class="sd">            **kwargs: Additional arguments.</span>
</span><span data-line="1054">
</span><span data-line="1055"><span class="sd">        Returns:</span>
</span><span data-line="1056"><span class="sd">            GLiNERBaseOutput containing logits, loss, and intermediate representations.</span>
</span><span data-line="1057"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="1058">        <span class="n">encoder_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">kwargs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;packing_config&quot;</span><span class="p">,</span> <span class="s2">&quot;pair_attention_mask&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">}</span>
</span><span data-line="1059">
</span><span data-line="1060">        <span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">,</span> <span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_representations</span><span class="p">(</span>
</span><span data-line="1061">            <span class="n">input_ids</span><span class="p">,</span>
</span><span data-line="1062">            <span class="n">attention_mask</span><span class="p">,</span>
</span><span data-line="1063">            <span class="n">labels_embeds</span><span class="p">,</span>
</span><span data-line="1064">            <span class="n">labels_input_ids</span><span class="p">,</span>
</span><span data-line="1065">            <span class="n">labels_attention_mask</span><span class="p">,</span>
</span><span data-line="1066">            <span class="n">text_lengths</span><span class="p">,</span>
</span><span data-line="1067">            <span class="n">words_mask</span><span class="p">,</span>
</span><span data-line="1068">            <span class="o">**</span><span class="n">encoder_kwargs</span><span class="p">,</span>
</span><span data-line="1069">        <span class="p">)</span>
</span><span data-line="1070">
</span><span data-line="1071">        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="1072">            <span class="n">target_W</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span data-line="1073">            <span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_length</span><span class="p">(</span><span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">target_W</span><span class="p">)</span>
</span><span data-line="1074">
</span><span data-line="1075">            <span class="n">target_C</span> <span class="o">=</span> <span class="n">prompts_embedding</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1076">            <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="1077">                <span class="n">target_C</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">target_C</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">))</span>
</span><span data-line="1078">
</span><span data-line="1079">            <span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_length</span><span class="p">(</span>
</span><span data-line="1080">                <span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">,</span> <span class="n">target_C</span>
</span><span data-line="1081">            <span class="p">)</span>
</span><span data-line="1082">
</span><span data-line="1083">        <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="p">(</span><span class="n">words_embedding</span><span class="p">,</span> <span class="n">prompts_embedding</span><span class="p">)</span>
</span><span data-line="1084">
</span><span data-line="1085">        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;represent_spans&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
</span><span data-line="1086">            <span class="n">span_rep</span><span class="p">,</span> <span class="n">span_idx</span><span class="p">,</span> <span class="n">span_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_span_representations</span><span class="p">(</span>
</span><span data-line="1087">                <span class="n">scores</span><span class="p">,</span> <span class="n">span_idx</span><span class="p">,</span> <span class="n">span_mask</span><span class="p">,</span> <span class="n">words_embedding</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">threshold</span>
</span><span data-line="1088">            <span class="p">)</span>
</span><span data-line="1089">            <span class="n">span_logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;BND,BCD-&gt;BNC&quot;</span><span class="p">,</span> <span class="n">span_rep</span><span class="p">,</span> <span class="n">prompts_embedding</span><span class="p">)</span>
</span><span data-line="1090">        <span class="k">else</span><span class="p">:</span>
</span><span data-line="1091">            <span class="n">span_logits</span><span class="p">,</span> <span class="n">span_idx</span><span class="p">,</span> <span class="n">span_mask</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
</span><span data-line="1092">
</span><span data-line="1093">        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="1094">        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="1095">            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span data-line="1096">
</span><span data-line="1097">            <span class="k">if</span> <span class="n">span_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="1098">                <span class="n">span_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">span_logits</span><span class="p">,</span> <span class="n">span_labels</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">,</span> <span class="n">span_mask</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span data-line="1099">                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">token_loss_coef</span> <span class="o">*</span> <span class="n">loss</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">span_loss_coef</span> <span class="o">*</span> <span class="n">span_loss</span>
</span><span data-line="1100">
</span><span data-line="1101">        <span class="n">output</span> <span class="o">=</span> <span class="n">GLiNERBaseOutput</span><span class="p">(</span>
</span><span data-line="1102">            <span class="n">logits</span><span class="o">=</span><span class="n">scores</span><span class="p">,</span>
</span><span data-line="1103">            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
</span><span data-line="1104">            <span class="n">prompts_embedding</span><span class="o">=</span><span class="n">prompts_embedding</span><span class="p">,</span>
</span><span data-line="1105">            <span class="n">prompts_embedding_mask</span><span class="o">=</span><span class="n">prompts_embedding_mask</span><span class="p">,</span>
</span><span data-line="1106">            <span class="n">words_embedding</span><span class="o">=</span><span class="n">words_embedding</span><span class="p">,</span>
</span><span data-line="1107">            <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span>
</span><span data-line="1108">            <span class="n">span_idx</span><span class="o">=</span><span class="n">span_idx</span><span class="p">,</span>
</span><span data-line="1109">            <span class="n">span_logits</span><span class="o">=</span><span class="n">span_logits</span><span class="p">,</span>
</span><span data-line="1110">            <span class="n">span_mask</span><span class="o">=</span><span class="n">span_mask</span><span class="p">,</span>
</span><span data-line="1111">        <span class="p">)</span>
</span><span data-line="1112">        <span class="k">return</span> <span class="n">output</span></div>
</div>

</span><span data-line="1113">
</span><span data-line="1114">
<div class="viewcode-block" id="UniEncoderSpanDecoderModel">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderSpanDecoderModel">[docs]</a>
</span><span data-line="1115"><span class="k">class</span><span class="w"> </span><span class="nc">UniEncoderSpanDecoderModel</span><span class="p">(</span><span class="n">UniEncoderSpanModel</span><span class="p">):</span>
</span><span data-line="1116"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Span-based model with decoder for generating entity type labels.</span>
</span><span data-line="1117">
</span><span data-line="1118"><span class="sd">    This model extends the span-based approach by adding a decoder that can</span>
</span><span data-line="1119"><span class="sd">    generate entity type labels as sequences, enabling more flexible entity typing.</span>
</span><span data-line="1120">
</span><span data-line="1121"><span class="sd">    Attributes:</span>
</span><span data-line="1122"><span class="sd">        decoder (Decoder): Decoder module for label generation.</span>
</span><span data-line="1123"><span class="sd">        _enc2dec_proj (Optional[nn.Module]): Projection layer if encoder and decoder</span>
</span><span data-line="1124"><span class="sd">            dimensions differ.</span>
</span><span data-line="1125"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="1126">
<div class="viewcode-block" id="UniEncoderSpanDecoderModel.__init__">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderSpanDecoderModel.__init__">[docs]</a>
</span><span data-line="1127">    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span data-line="1128">        <span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="1129">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="1130"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the span-decoder model.</span>
</span><span data-line="1131">
</span><span data-line="1132"><span class="sd">        Args:</span>
</span><span data-line="1133"><span class="sd">            config: Model configuration object.</span>
</span><span data-line="1134"><span class="sd">            from_pretrained: Whether to load from pretrained weights.</span>
</span><span data-line="1135"><span class="sd">            cache_dir: Directory for caching pretrained models.</span>
</span><span data-line="1136"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="1137">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">)</span>
</span><span data-line="1138">        <span class="bp">self</span><span class="o">.</span><span class="n">__init_decoder__</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">)</span></div>

</span><span data-line="1139">
</span><span data-line="1140">    <span class="k">def</span><span class="w"> </span><span class="nf">__init_decoder__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">):</span>
</span><span data-line="1141">        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">,</span> <span class="n">cache_dir</span><span class="o">=</span><span class="n">cache_dir</span><span class="p">)</span>
</span><span data-line="1142">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">decoder_hidden_size</span><span class="p">:</span>
</span><span data-line="1143">            <span class="bp">self</span><span class="o">.</span><span class="n">_enc2dec_proj</span> <span class="o">=</span> <span class="n">create_projection_layer</span><span class="p">(</span>
</span><span data-line="1144">                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span>
</span><span data-line="1145">                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span>
</span><span data-line="1146">                <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">decoder_hidden_size</span><span class="p">,</span>
</span><span data-line="1147">            <span class="p">)</span>
</span><span data-line="1148">
<div class="viewcode-block" id="UniEncoderSpanDecoderModel.select_decoder_embedding">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderSpanDecoderModel.select_decoder_embedding">[docs]</a>
</span><span data-line="1149">    <span class="k">def</span><span class="w"> </span><span class="nf">select_decoder_embedding</span><span class="p">(</span>
</span><span data-line="1150">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="1151">        <span class="n">representations</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">,</span>
</span><span data-line="1152">        <span class="n">rep_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">,</span>
</span><span data-line="1153">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span data-line="1154"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Select and pack valid representations for decoder input.</span>
</span><span data-line="1155">
</span><span data-line="1156"><span class="sd">        Keeps only representations where mask == 1 and optionally projects them</span>
</span><span data-line="1157"><span class="sd">        to the decoder hidden size.</span>
</span><span data-line="1158">
</span><span data-line="1159"><span class="sd">        Args:</span>
</span><span data-line="1160"><span class="sd">            representations: Tensor of shape (B, N, D) containing embeddings.</span>
</span><span data-line="1161"><span class="sd">            rep_mask: Tensor of shape (B, N) where 1 indicates valid position.</span>
</span><span data-line="1162">
</span><span data-line="1163"><span class="sd">        Returns:</span>
</span><span data-line="1164"><span class="sd">            Tuple containing:</span>
</span><span data-line="1165"><span class="sd">                - target_rep: FloatTensor of shape (B, M, D) with kept representations.</span>
</span><span data-line="1166"><span class="sd">                - target_mask: LongTensor of shape (B, M) with 1 for valid, 0 for pad.</span>
</span><span data-line="1167"><span class="sd">                - sel_idx: LongTensor of shape (B, M) with original column indices</span>
</span><span data-line="1168"><span class="sd">                  (-1 for padding positions).</span>
</span><span data-line="1169"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="1170">        <span class="n">B</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="n">representations</span><span class="o">.</span><span class="n">shape</span>
</span><span data-line="1171">        <span class="n">lengths</span> <span class="o">=</span> <span class="n">rep_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1172">        <span class="n">max_len</span> <span class="o">=</span> <span class="n">lengths</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span><span data-line="1173">
</span><span data-line="1174">        <span class="n">target_rep</span> <span class="o">=</span> <span class="n">representations</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
</span><span data-line="1175">        <span class="n">target_mask</span> <span class="o">=</span> <span class="n">rep_mask</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">max_len</span><span class="p">)</span>
</span><span data-line="1176">        <span class="n">sel_idx</span> <span class="o">=</span> <span class="n">rep_mask</span><span class="o">.</span><span class="n">new_full</span><span class="p">((</span><span class="n">B</span><span class="p">,</span> <span class="n">max_len</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1177">
</span><span data-line="1178">        <span class="n">keep</span> <span class="o">=</span> <span class="n">rep_mask</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
</span><span data-line="1179">        <span class="k">if</span> <span class="n">keep</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
</span><span data-line="1180">            <span class="n">new_col_idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">rep_mask</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)[</span><span class="n">keep</span><span class="p">]</span>
</span><span data-line="1181">            <span class="n">batch_idx</span><span class="p">,</span> <span class="n">old_col_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">keep</span><span class="p">)</span>
</span><span data-line="1182">
</span><span data-line="1183">            <span class="n">target_rep</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">,</span> <span class="n">new_col_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">representations</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">,</span> <span class="n">old_col_idx</span><span class="p">]</span>
</span><span data-line="1184">            <span class="n">target_mask</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">,</span> <span class="n">new_col_idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span data-line="1185">            <span class="n">sel_idx</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">,</span> <span class="n">new_col_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">old_col_idx</span>
</span><span data-line="1186">
</span><span data-line="1187">        <span class="k">return</span> <span class="n">target_rep</span><span class="p">,</span> <span class="n">target_mask</span><span class="p">,</span> <span class="n">sel_idx</span></div>

</span><span data-line="1188">
<div class="viewcode-block" id="UniEncoderSpanDecoderModel.get_raw_decoder_inputs">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderSpanDecoderModel.get_raw_decoder_inputs">[docs]</a>
</span><span data-line="1189">    <span class="k">def</span><span class="w"> </span><span class="nf">get_raw_decoder_inputs</span><span class="p">(</span>
</span><span data-line="1190">        <span class="bp">self</span><span class="p">,</span> <span class="n">representations</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">rep_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
</span><span data-line="1191">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span data-line="1192"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Extract valid span tokens for decoder input.</span>
</span><span data-line="1193">
</span><span data-line="1194"><span class="sd">        Args:</span>
</span><span data-line="1195"><span class="sd">            representations: Span representations of shape (B, S, T, D).</span>
</span><span data-line="1196"><span class="sd">            rep_mask: Mask of shape (B, S, T).</span>
</span><span data-line="1197">
</span><span data-line="1198"><span class="sd">        Returns:</span>
</span><span data-line="1199"><span class="sd">            Tuple containing:</span>
</span><span data-line="1200"><span class="sd">                - span_tokens: Valid span tokens of shape (M, T, D).</span>
</span><span data-line="1201"><span class="sd">                - span_tokens_mask: Mask for span tokens of shape (M, T).</span>
</span><span data-line="1202"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="1203">        <span class="n">B</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="n">representations</span><span class="o">.</span><span class="n">shape</span>
</span><span data-line="1204">        <span class="n">BN</span> <span class="o">=</span> <span class="n">B</span> <span class="o">*</span> <span class="n">S</span>
</span><span data-line="1205">        <span class="n">valid_spans</span> <span class="o">=</span> <span class="n">rep_mask</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1206">        <span class="n">keep_mask</span> <span class="o">=</span> <span class="n">valid_spans</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1207">
</span><span data-line="1208">        <span class="k">if</span> <span class="ow">not</span> <span class="n">keep_mask</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
</span><span data-line="1209">            <span class="n">empty</span> <span class="o">=</span> <span class="n">representations</span><span class="o">.</span><span class="n">new_empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
</span><span data-line="1210">            <span class="k">return</span> <span class="n">empty</span><span class="p">,</span> <span class="n">representations</span><span class="o">.</span><span class="n">new_empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">rep_mask</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span data-line="1211">
</span><span data-line="1212">        <span class="n">keep_idx</span> <span class="o">=</span> <span class="n">keep_mask</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">as_tuple</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1213">
</span><span data-line="1214">        <span class="n">span_tokens</span> <span class="o">=</span> <span class="n">representations</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">BN</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">D</span><span class="p">)[</span><span class="n">keep_idx</span><span class="p">]</span>
</span><span data-line="1215">        <span class="n">span_tokens_mask</span> <span class="o">=</span> <span class="n">rep_mask</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">BN</span><span class="p">,</span> <span class="n">T</span><span class="p">)[</span><span class="n">keep_idx</span><span class="p">]</span>
</span><span data-line="1216">        <span class="k">return</span> <span class="n">span_tokens</span><span class="p">,</span> <span class="n">span_tokens_mask</span></div>

</span><span data-line="1217">
<div class="viewcode-block" id="UniEncoderSpanDecoderModel.decode_labels">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderSpanDecoderModel.decode_labels">[docs]</a>
</span><span data-line="1218">    <span class="k">def</span><span class="w"> </span><span class="nf">decode_labels</span><span class="p">(</span>
</span><span data-line="1219">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="1220">        <span class="n">decoder_embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1221">        <span class="n">decoder_embedding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1222">        <span class="n">decoder_labels_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1223">        <span class="n">decoder_labels_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1224">        <span class="n">decoder_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1225">        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span data-line="1226">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span data-line="1227"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Decode labels using the decoder in teacher forcing mode.</span>
</span><span data-line="1228">
</span><span data-line="1229"><span class="sd">        Args:</span>
</span><span data-line="1230"><span class="sd">            decoder_embedding: Span token embeddings of shape (B, N, T, D).</span>
</span><span data-line="1231"><span class="sd">            decoder_embedding_mask: Mask for span tokens of shape (B, N, T).</span>
</span><span data-line="1232"><span class="sd">            decoder_labels_ids: Label token IDs of shape (M, L).</span>
</span><span data-line="1233"><span class="sd">            decoder_labels_mask: Mask for labels of shape (M, L).</span>
</span><span data-line="1234"><span class="sd">            decoder_labels: Ground truth labels for loss computation of shape (M, L).</span>
</span><span data-line="1235"><span class="sd">            **kwargs: Additional arguments.</span>
</span><span data-line="1236">
</span><span data-line="1237"><span class="sd">        Returns:</span>
</span><span data-line="1238"><span class="sd">            Tuple containing:</span>
</span><span data-line="1239"><span class="sd">                - loss: Cross-entropy loss scalar.</span>
</span><span data-line="1240"><span class="sd">                - decoder_outputs: Decoder logits of shape (M, S+L-1, V).</span>
</span><span data-line="1241"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="1242">        <span class="n">span_tokens</span><span class="p">,</span> <span class="n">span_tokens_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_raw_decoder_inputs</span><span class="p">(</span><span class="n">decoder_embedding</span><span class="p">,</span> <span class="n">decoder_embedding_mask</span><span class="p">)</span>
</span><span data-line="1243">
</span><span data-line="1244">        <span class="n">label_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">ids_to_embeds</span><span class="p">(</span><span class="n">decoder_labels_ids</span><span class="p">)</span>
</span><span data-line="1245">
</span><span data-line="1246">        <span class="n">decoder_inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">span_tokens</span><span class="p">,</span> <span class="n">label_embeds</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1247">
</span><span data-line="1248">        <span class="n">attn_inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">span_tokens_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">decoder_labels_mask</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">decoder_labels_mask</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1249">
</span><span data-line="1250">        <span class="n">decoder_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">inputs_embeds</span><span class="o">=</span><span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attn_inputs</span><span class="p">)</span>
</span><span data-line="1251">
</span><span data-line="1252">        <span class="n">blank_for_spans</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
</span><span data-line="1253">            <span class="p">(</span><span class="n">decoder_labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">span_tokens</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span>
</span><span data-line="1254">            <span class="o">-</span><span class="mi">100</span><span class="p">,</span>
</span><span data-line="1255">            <span class="n">dtype</span><span class="o">=</span><span class="n">decoder_labels</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span><span data-line="1256">            <span class="n">device</span><span class="o">=</span><span class="n">decoder_labels</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span><span data-line="1257">        <span class="p">)</span>
</span><span data-line="1258">
</span><span data-line="1259">        <span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">blank_for_spans</span><span class="p">,</span> <span class="n">decoder_labels</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1260">
</span><span data-line="1261">        <span class="n">loss</span> <span class="o">=</span> <span class="n">cross_entropy_loss</span><span class="p">(</span><span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:])</span>
</span><span data-line="1262">
</span><span data-line="1263">        <span class="k">return</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">decoder_outputs</span><span class="p">)</span></div>

</span><span data-line="1264">
<div class="viewcode-block" id="UniEncoderSpanDecoderModel.generate_labels">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderSpanDecoderModel.generate_labels">[docs]</a>
</span><span data-line="1265">    <span class="k">def</span><span class="w"> </span><span class="nf">generate_labels</span><span class="p">(</span>
</span><span data-line="1266">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="1267">        <span class="n">decoder_embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1268">        <span class="n">decoder_embedding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1269">        <span class="n">max_new_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
</span><span data-line="1270">        <span class="n">eos_token_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1271">        <span class="n">pad_token_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1272">        <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span data-line="1273">        <span class="n">do_sample</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span data-line="1274">        <span class="n">num_return_sequences</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span data-line="1275">        <span class="n">labels_trie</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1276">        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span data-line="1277">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span data-line="1278"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate entity type labels from decoder embeddings.</span>
</span><span data-line="1279">
</span><span data-line="1280"><span class="sd">        Args:</span>
</span><span data-line="1281"><span class="sd">            decoder_embedding: Span token embeddings of shape (B, N, D).</span>
</span><span data-line="1282"><span class="sd">            decoder_embedding_mask: Mask for span tokens of shape (B, N).</span>
</span><span data-line="1283"><span class="sd">            max_new_tokens: Maximum number of tokens to generate.</span>
</span><span data-line="1284"><span class="sd">            eos_token_id: End-of-sequence token ID.</span>
</span><span data-line="1285"><span class="sd">            pad_token_id: Padding token ID.</span>
</span><span data-line="1286"><span class="sd">            temperature: Sampling temperature.</span>
</span><span data-line="1287"><span class="sd">            do_sample: Whether to use sampling instead of greedy decoding.</span>
</span><span data-line="1288"><span class="sd">            num_return_sequences: Number of sequences to generate per input.</span>
</span><span data-line="1289"><span class="sd">            labels_trie: Optional trie for constrained decoding.</span>
</span><span data-line="1290"><span class="sd">            **kwargs: Additional generation arguments.</span>
</span><span data-line="1291">
</span><span data-line="1292"><span class="sd">        Returns:</span>
</span><span data-line="1293"><span class="sd">            Generated token IDs of shape (M, L).</span>
</span><span data-line="1294"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="1295">        <span class="n">span_tokens</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_raw_decoder_inputs</span><span class="p">(</span><span class="n">decoder_embedding</span><span class="p">,</span> <span class="n">decoder_embedding_mask</span><span class="p">)</span>
</span><span data-line="1296">        <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">generate_from_embeds</span><span class="p">(</span>
</span><span data-line="1297">            <span class="n">span_tokens</span><span class="p">,</span>
</span><span data-line="1298">            <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span data-line="1299">            <span class="n">max_new_tokens</span><span class="o">=</span><span class="n">max_new_tokens</span><span class="p">,</span>
</span><span data-line="1300">            <span class="n">eos_token_id</span><span class="o">=</span><span class="n">eos_token_id</span><span class="p">,</span>
</span><span data-line="1301">            <span class="n">pad_token_id</span><span class="o">=</span><span class="n">pad_token_id</span><span class="p">,</span>
</span><span data-line="1302">            <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span>
</span><span data-line="1303">            <span class="n">do_sample</span><span class="o">=</span><span class="n">do_sample</span><span class="p">,</span>
</span><span data-line="1304">            <span class="n">num_return_sequences</span><span class="o">=</span><span class="n">num_return_sequences</span><span class="p">,</span>
</span><span data-line="1305">            <span class="n">labels_trie</span><span class="o">=</span><span class="n">labels_trie</span><span class="p">,</span>
</span><span data-line="1306">            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span data-line="1307">        <span class="p">)</span>
</span><span data-line="1308">        <span class="k">return</span> <span class="n">results</span></div>

</span><span data-line="1309">
<div class="viewcode-block" id="UniEncoderSpanDecoderModel.select_span_decoder_embedding">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderSpanDecoderModel.select_span_decoder_embedding">[docs]</a>
</span><span data-line="1310">    <span class="k">def</span><span class="w"> </span><span class="nf">select_span_decoder_embedding</span><span class="p">(</span>
</span><span data-line="1311">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="1312">        <span class="n">prompts_embedding</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="1313">        <span class="n">prompts_embedding_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="1314">        <span class="n">span_rep</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="1315">        <span class="n">span_scores</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="1316">        <span class="n">span_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="1317">        <span class="n">decoder_text_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1318">        <span class="n">decoder_words_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1319">        <span class="n">span_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1320">        <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
</span><span data-line="1321">        <span class="n">top_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1322">        <span class="n">decoder_input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1323">        <span class="n">decoder_labels_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1324">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
</span><span data-line="1325"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Select span embeddings for decoder input based on predictions or labels.</span>
</span><span data-line="1326">
</span><span data-line="1327"><span class="sd">        This method selects which spans to provide to the decoder, either based on</span>
</span><span data-line="1328"><span class="sd">        ground truth labels (during training) or model predictions (during inference).</span>
</span><span data-line="1329"><span class="sd">        It can operate in two modes:</span>
</span><span data-line="1330"><span class="sd">        1. &quot;prompt&quot; mode: Uses entity type embeddings as decoder input.</span>
</span><span data-line="1331"><span class="sd">        2. &quot;span&quot; mode: Uses contextualized tokens within each span as decoder input.</span>
</span><span data-line="1332">
</span><span data-line="1333"><span class="sd">        Args:</span>
</span><span data-line="1334"><span class="sd">            prompts_embedding: Entity type embeddings of shape (B, C, D).</span>
</span><span data-line="1335"><span class="sd">            prompts_embedding_mask: Mask for prompts of shape (B, C).</span>
</span><span data-line="1336"><span class="sd">            span_rep: Span representations of shape (B, L, K, D).</span>
</span><span data-line="1337"><span class="sd">            span_scores: Span classification scores of shape (B, L, K, C).</span>
</span><span data-line="1338"><span class="sd">            span_mask: Mask for valid spans of shape (B, L, K).</span>
</span><span data-line="1339"><span class="sd">            decoder_text_embeds: Text embeddings for span mode of shape (B, T, D).</span>
</span><span data-line="1340"><span class="sd">            decoder_words_mask: Word position mask of shape (B, T).</span>
</span><span data-line="1341"><span class="sd">            span_labels: Ground truth labels of shape (B, L, K, C).</span>
</span><span data-line="1342"><span class="sd">            threshold: Confidence threshold for selecting spans.</span>
</span><span data-line="1343"><span class="sd">            top_k: Optional limit on number of spans to select.</span>
</span><span data-line="1344"><span class="sd">            decoder_input_ids: Debugging parameter for input IDs.</span>
</span><span data-line="1345"><span class="sd">            decoder_labels_ids: Debugging parameter for label IDs.</span>
</span><span data-line="1346">
</span><span data-line="1347"><span class="sd">        Returns:</span>
</span><span data-line="1348"><span class="sd">            Tuple containing:</span>
</span><span data-line="1349"><span class="sd">                - span_rep_kept: Selected span embeddings for decoder of shape (B, S, T, D)</span>
</span><span data-line="1350"><span class="sd">                  or None if no valid spans.</span>
</span><span data-line="1351"><span class="sd">                - span_msk: Mask for selected spans of shape (B, S, T) or None.</span>
</span><span data-line="1352"><span class="sd">                - span_sel_idx: Original indices of selected spans of shape (B, S) or None.</span>
</span><span data-line="1353"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="1354">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">decoder_mode</span> <span class="o">==</span> <span class="s2">&quot;prompt&quot;</span><span class="p">:</span>
</span><span data-line="1355">            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_decoder_embedding</span><span class="p">(</span><span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">)[:</span><span class="mi">3</span><span class="p">]</span>
</span><span data-line="1356">
</span><span data-line="1357">        <span class="n">B</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="n">span_rep</span><span class="o">.</span><span class="n">shape</span>
</span><span data-line="1358">        <span class="n">flat_rep</span> <span class="o">=</span> <span class="n">span_rep</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">L</span> <span class="o">*</span> <span class="n">K</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
</span><span data-line="1359">        <span class="n">flat_mask</span> <span class="o">=</span> <span class="n">span_mask</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">L</span> <span class="o">*</span> <span class="n">K</span><span class="p">)</span>
</span><span data-line="1360">
</span><span data-line="1361">        <span class="k">if</span> <span class="n">span_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="1362">            <span class="n">flat_prob</span> <span class="o">=</span> <span class="n">span_labels</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">L</span> <span class="o">*</span> <span class="n">K</span><span class="p">)</span>
</span><span data-line="1363">            <span class="n">keep</span> <span class="o">=</span> <span class="p">(</span><span class="n">flat_prob</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">flat_mask</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
</span><span data-line="1364">        <span class="k">else</span><span class="p">:</span>
</span><span data-line="1365">            <span class="n">flat_prob</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">span_scores</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">L</span> <span class="o">*</span> <span class="n">K</span><span class="p">)</span>
</span><span data-line="1366">            <span class="n">keep</span> <span class="o">=</span> <span class="p">(</span><span class="n">flat_prob</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">flat_mask</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
</span><span data-line="1367">
</span><span data-line="1368">        <span class="k">if</span> <span class="n">top_k</span><span class="p">:</span>
</span><span data-line="1369">            <span class="n">sel_scores</span> <span class="o">=</span> <span class="n">flat_prob</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="o">~</span><span class="n">keep</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">)</span>
</span><span data-line="1370">            <span class="n">top_idx</span> <span class="o">=</span> <span class="n">sel_scores</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">top_k</span><span class="p">,</span> <span class="n">sel_scores</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">indices</span>
</span><span data-line="1371">            <span class="n">keep</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
</span><span data-line="1372">            <span class="n">keep</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">top_idx</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</span><span data-line="1373">
</span><span data-line="1374">        <span class="n">span_rep_kept</span><span class="p">,</span> <span class="n">span_msk</span><span class="p">,</span> <span class="n">span_sel_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_decoder_embedding</span><span class="p">(</span><span class="n">flat_rep</span><span class="p">,</span> <span class="n">keep</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
</span><span data-line="1375">
</span><span data-line="1376">        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_enc2dec_proj&quot;</span><span class="p">):</span>
</span><span data-line="1377">            <span class="n">span_rep_kept</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_enc2dec_proj</span><span class="p">(</span><span class="n">span_rep_kept</span><span class="p">)</span>
</span><span data-line="1378">        <span class="n">span_rep_kept</span> <span class="o">=</span> <span class="n">span_rep_kept</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span data-line="1379">        <span class="n">span_msk</span> <span class="o">=</span> <span class="n">span_msk</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1380">
</span><span data-line="1381">        <span class="k">if</span> <span class="n">decoder_text_embeds</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">decoder_words_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="1382">            <span class="k">return</span> <span class="n">span_rep_kept</span><span class="p">,</span> <span class="n">span_msk</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">span_sel_idx</span>
</span><span data-line="1383">
</span><span data-line="1384">        <span class="k">if</span> <span class="n">span_rep_kept</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span data-line="1385">            <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
</span><span data-line="1386">
</span><span data-line="1387">        <span class="n">decoder_text_embeds</span> <span class="o">=</span> <span class="n">decoder_text_embeds</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">span_rep_kept</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span data-line="1388">
</span><span data-line="1389">        <span class="n">S</span> <span class="o">=</span> <span class="n">span_rep_kept</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span data-line="1390">        <span class="n">dec_D</span> <span class="o">=</span> <span class="n">span_rep_kept</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span data-line="1391">        <span class="n">span_start</span> <span class="o">=</span> <span class="n">span_sel_idx</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_width</span> <span class="o">+</span> <span class="mi">1</span>
</span><span data-line="1392">        <span class="n">span_end</span> <span class="o">=</span> <span class="n">span_sel_idx</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_width</span> <span class="o">+</span> <span class="n">span_start</span>
</span><span data-line="1393">
</span><span data-line="1394">        <span class="n">token_in_span</span> <span class="o">=</span> <span class="p">(</span><span class="n">decoder_words_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">span_start</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">&amp;</span> <span class="p">(</span>
</span><span data-line="1395">            <span class="n">decoder_words_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">span_end</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1396">        <span class="p">)</span>
</span><span data-line="1397">
</span><span data-line="1398">        <span class="n">tokens_per_span</span> <span class="o">=</span> <span class="n">token_in_span</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1399">        <span class="n">max_tokens</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">tokens_per_span</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
</span><span data-line="1400">
</span><span data-line="1401">        <span class="n">span_rep_new</span> <span class="o">=</span> <span class="n">span_rep_kept</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">max_tokens</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dec_D</span><span class="p">)</span>
</span><span data-line="1402">        <span class="n">span_rep_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">max_tokens</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">decoder_text_embeds</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span data-line="1403">
</span><span data-line="1404">        <span class="n">left_offset</span> <span class="o">=</span> <span class="p">(</span><span class="n">max_tokens</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">tokens_per_span</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span data-line="1405">        <span class="n">pos_in_span</span> <span class="o">=</span> <span class="p">(</span><span class="n">token_in_span</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="o">~</span><span class="n">token_in_span</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span><span data-line="1406">        <span class="n">pos_in_span</span> <span class="o">=</span> <span class="n">pos_in_span</span> <span class="o">+</span> <span class="n">left_offset</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1407">
</span><span data-line="1408">        <span class="n">b_idx</span><span class="p">,</span> <span class="n">s_idx</span><span class="p">,</span> <span class="n">tok_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">token_in_span</span><span class="p">)</span>
</span><span data-line="1409">        <span class="n">span_rep_new</span><span class="p">[</span><span class="n">b_idx</span><span class="p">,</span> <span class="n">s_idx</span><span class="p">,</span> <span class="n">pos_in_span</span><span class="p">[</span><span class="n">b_idx</span><span class="p">,</span> <span class="n">s_idx</span><span class="p">,</span> <span class="n">tok_idx</span><span class="p">]]</span> <span class="o">=</span> <span class="n">decoder_text_embeds</span><span class="p">[</span><span class="n">b_idx</span><span class="p">,</span> <span class="n">tok_idx</span><span class="p">]</span>
</span><span data-line="1410">        <span class="n">span_rep_mask</span><span class="p">[</span><span class="n">b_idx</span><span class="p">,</span> <span class="n">s_idx</span><span class="p">,</span> <span class="n">pos_in_span</span><span class="p">[</span><span class="n">b_idx</span><span class="p">,</span> <span class="n">s_idx</span><span class="p">,</span> <span class="n">tok_idx</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">True</span>
</span><span data-line="1411">        <span class="n">kept_pos</span> <span class="o">=</span> <span class="p">(</span><span class="n">left_offset</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span data-line="1412">
</span><span data-line="1413">        <span class="n">b_flat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">decoder_text_embeds</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">S</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1414">        <span class="n">s_flat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">decoder_text_embeds</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">S</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1415">        <span class="n">t_flat</span> <span class="o">=</span> <span class="n">kept_pos</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1416">
</span><span data-line="1417">        <span class="n">span_rep_new</span><span class="p">[</span><span class="n">b_flat</span><span class="p">,</span> <span class="n">s_flat</span><span class="p">,</span> <span class="n">t_flat</span><span class="p">]</span> <span class="o">=</span> <span class="n">span_rep_kept</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dec_D</span><span class="p">)</span>
</span><span data-line="1418">        <span class="n">span_rep_mask</span><span class="p">[</span><span class="n">b_flat</span><span class="p">,</span> <span class="n">s_flat</span><span class="p">,</span> <span class="n">t_flat</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
</span><span data-line="1419">        <span class="n">span_rep_mask</span> <span class="o">=</span> <span class="n">span_rep_mask</span> <span class="o">&amp;</span> <span class="n">span_msk</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
</span><span data-line="1420">        <span class="k">return</span> <span class="n">span_rep_new</span><span class="p">,</span> <span class="n">span_rep_mask</span><span class="p">,</span> <span class="n">span_sel_idx</span></div>

</span><span data-line="1421">
<div class="viewcode-block" id="UniEncoderSpanDecoderModel.forward">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderSpanDecoderModel.forward">[docs]</a>
</span><span data-line="1422">    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span data-line="1423">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="1424">        <span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1425">        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1426">        <span class="n">decoder_input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1427">        <span class="n">decoder_attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1428">        <span class="n">decoder_labels_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1429">        <span class="n">decoder_labels_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1430">        <span class="n">decoder_words_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1431">        <span class="n">words_embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1432">        <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1433">        <span class="n">prompts_embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1434">        <span class="n">prompts_embedding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1435">        <span class="n">words_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1436">        <span class="n">text_lengths</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1437">        <span class="n">span_idx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1438">        <span class="n">span_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1439">        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1440">        <span class="n">decoder_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1441">        <span class="n">threshold</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
</span><span data-line="1442">        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span data-line="1443">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GLiNERDecoderOutput</span><span class="p">:</span>
</span><span data-line="1444"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward pass through the span-decoder model.</span>
</span><span data-line="1445">
</span><span data-line="1446"><span class="sd">        Args:</span>
</span><span data-line="1447"><span class="sd">            input_ids: Input token IDs of shape (B, L).</span>
</span><span data-line="1448"><span class="sd">            attention_mask: Attention mask of shape (B, L).</span>
</span><span data-line="1449"><span class="sd">            decoder_input_ids: Decoder input IDs for span mode.</span>
</span><span data-line="1450"><span class="sd">            decoder_attention_mask: Decoder attention mask.</span>
</span><span data-line="1451"><span class="sd">            decoder_labels_ids: Label token IDs for decoding of shape (M, L).</span>
</span><span data-line="1452"><span class="sd">            decoder_labels_mask: Mask for decoder labels of shape (M, L).</span>
</span><span data-line="1453"><span class="sd">            decoder_words_mask: Word position mask for span mode.</span>
</span><span data-line="1454"><span class="sd">            words_embedding: Pre-computed word embeddings.</span>
</span><span data-line="1455"><span class="sd">            mask: Mask for words.</span>
</span><span data-line="1456"><span class="sd">            prompts_embedding: Pre-computed entity type embeddings.</span>
</span><span data-line="1457"><span class="sd">            prompts_embedding_mask: Mask for prompts.</span>
</span><span data-line="1458"><span class="sd">            words_mask: Word boundary mask.</span>
</span><span data-line="1459"><span class="sd">            text_lengths: Length of each text sequence.</span>
</span><span data-line="1460"><span class="sd">            span_idx: Span indices of shape (B, L*K, 2).</span>
</span><span data-line="1461"><span class="sd">            span_mask: Mask for valid spans of shape (B, L, K).</span>
</span><span data-line="1462"><span class="sd">            labels: Ground truth span labels of shape (B, L, K, C).</span>
</span><span data-line="1463"><span class="sd">            decoder_labels: Ground truth decoder labels of shape (M, L).</span>
</span><span data-line="1464"><span class="sd">            threshold: Confidence threshold for span selection.</span>
</span><span data-line="1465"><span class="sd">            **kwargs: Additional arguments.</span>
</span><span data-line="1466">
</span><span data-line="1467"><span class="sd">        Returns:</span>
</span><span data-line="1468"><span class="sd">            GLiNERDecoderOutput containing logits, losses, and decoder information.</span>
</span><span data-line="1469"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="1470">        <span class="n">encoder_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">kwargs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;packing_config&quot;</span><span class="p">,</span> <span class="s2">&quot;pair_attention_mask&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">}</span>
</span><span data-line="1471">
</span><span data-line="1472">        <span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">,</span> <span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_representations</span><span class="p">(</span>
</span><span data-line="1473">            <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">text_lengths</span><span class="p">,</span> <span class="n">words_mask</span><span class="p">,</span> <span class="o">**</span><span class="n">encoder_kwargs</span>
</span><span data-line="1474">        <span class="p">)</span>
</span><span data-line="1475">
</span><span data-line="1476">        <span class="n">target_W</span> <span class="o">=</span> <span class="n">span_idx</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_width</span>
</span><span data-line="1477">        <span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_length</span><span class="p">(</span><span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">target_W</span><span class="p">)</span>
</span><span data-line="1478">
</span><span data-line="1479">        <span class="n">span_idx</span> <span class="o">=</span> <span class="n">span_idx</span> <span class="o">*</span> <span class="n">span_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1480">
</span><span data-line="1481">        <span class="n">span_rep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">span_rep_layer</span><span class="p">(</span><span class="n">words_embedding</span><span class="p">,</span> <span class="n">span_idx</span><span class="p">)</span>
</span><span data-line="1482">
</span><span data-line="1483">        <span class="n">target_C</span> <span class="o">=</span> <span class="n">prompts_embedding</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1484">        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="1485">            <span class="n">target_C</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">target_C</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span data-line="1486">
</span><span data-line="1487">        <span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_length</span><span class="p">(</span>
</span><span data-line="1488">            <span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">,</span> <span class="n">target_C</span>
</span><span data-line="1489">        <span class="p">)</span>
</span><span data-line="1490">
</span><span data-line="1491">        <span class="n">prompts_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_rep_layer</span><span class="p">(</span><span class="n">prompts_embedding</span><span class="p">)</span>
</span><span data-line="1492">
</span><span data-line="1493">        <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;BLKD,BCD-&gt;BLKC&quot;</span><span class="p">,</span> <span class="n">span_rep</span><span class="p">,</span> <span class="n">prompts_embedding</span><span class="p">)</span>
</span><span data-line="1494">
</span><span data-line="1495">        <span class="n">decoder_embedding</span> <span class="o">=</span> <span class="n">decoder_mask</span> <span class="o">=</span> <span class="n">decoder_loss</span> <span class="o">=</span> <span class="n">decoder_span_idx</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="1496">        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;decoder&quot;</span><span class="p">):</span>
</span><span data-line="1497">            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">decoder_mode</span> <span class="o">==</span> <span class="s2">&quot;span&quot;</span><span class="p">:</span>
</span><span data-line="1498">                <span class="n">decoder_text_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">ids_to_embeds</span><span class="p">(</span><span class="n">decoder_input_ids</span><span class="p">)</span>
</span><span data-line="1499">            <span class="k">else</span><span class="p">:</span>
</span><span data-line="1500">                <span class="n">decoder_text_embeds</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="1501">
</span><span data-line="1502">            <span class="n">decoder_embedding</span><span class="p">,</span> <span class="n">decoder_mask</span><span class="p">,</span> <span class="n">decoder_span_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_span_decoder_embedding</span><span class="p">(</span>
</span><span data-line="1503">                <span class="n">prompts_embedding</span><span class="p">,</span>
</span><span data-line="1504">                <span class="n">prompts_embedding_mask</span><span class="p">,</span>
</span><span data-line="1505">                <span class="n">span_rep</span><span class="p">,</span>
</span><span data-line="1506">                <span class="n">scores</span><span class="p">,</span>
</span><span data-line="1507">                <span class="n">span_mask</span><span class="p">,</span>
</span><span data-line="1508">                <span class="n">decoder_text_embeds</span><span class="o">=</span><span class="n">decoder_text_embeds</span><span class="p">,</span>
</span><span data-line="1509">                <span class="n">decoder_words_mask</span><span class="o">=</span><span class="n">decoder_words_mask</span><span class="p">,</span>
</span><span data-line="1510">                <span class="n">span_labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
</span><span data-line="1511">                <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span>
</span><span data-line="1512">                <span class="n">decoder_input_ids</span><span class="o">=</span><span class="n">decoder_input_ids</span><span class="p">,</span>
</span><span data-line="1513">                <span class="n">decoder_labels_ids</span><span class="o">=</span><span class="n">decoder_labels_ids</span><span class="p">,</span>
</span><span data-line="1514">            <span class="p">)</span>
</span><span data-line="1515">
</span><span data-line="1516">            <span class="k">if</span> <span class="n">decoder_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="1517">                <span class="n">decoder_loss</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode_labels</span><span class="p">(</span>
</span><span data-line="1518">                    <span class="n">decoder_embedding</span><span class="p">,</span> <span class="n">decoder_mask</span><span class="p">,</span> <span class="n">decoder_labels_ids</span><span class="p">,</span> <span class="n">decoder_labels_mask</span><span class="p">,</span> <span class="n">decoder_labels</span>
</span><span data-line="1519">                <span class="p">)</span>
</span><span data-line="1520">
</span><span data-line="1521">        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="1522">        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="1523">            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">,</span> <span class="n">span_mask</span><span class="p">,</span> <span class="n">decoder_loss</span><span class="o">=</span><span class="n">decoder_loss</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span data-line="1524">
</span><span data-line="1525">        <span class="n">output</span> <span class="o">=</span> <span class="n">GLiNERDecoderOutput</span><span class="p">(</span>
</span><span data-line="1526">            <span class="n">logits</span><span class="o">=</span><span class="n">scores</span><span class="p">,</span>
</span><span data-line="1527">            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
</span><span data-line="1528">            <span class="n">decoder_loss</span><span class="o">=</span><span class="n">decoder_loss</span><span class="p">,</span>
</span><span data-line="1529">            <span class="n">prompts_embedding</span><span class="o">=</span><span class="n">prompts_embedding</span><span class="p">,</span>
</span><span data-line="1530">            <span class="n">prompts_embedding_mask</span><span class="o">=</span><span class="n">prompts_embedding_mask</span><span class="p">,</span>
</span><span data-line="1531">            <span class="n">decoder_embedding</span><span class="o">=</span><span class="n">decoder_embedding</span><span class="p">,</span>
</span><span data-line="1532">            <span class="n">decoder_embedding_mask</span><span class="o">=</span><span class="n">decoder_mask</span><span class="p">,</span>
</span><span data-line="1533">            <span class="n">decoder_span_idx</span><span class="o">=</span><span class="n">decoder_span_idx</span><span class="p">,</span>
</span><span data-line="1534">            <span class="n">words_embedding</span><span class="o">=</span><span class="n">words_embedding</span><span class="p">,</span>
</span><span data-line="1535">            <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span>
</span><span data-line="1536">        <span class="p">)</span>
</span><span data-line="1537">        <span class="k">return</span> <span class="n">output</span></div>

</span><span data-line="1538">
<div class="viewcode-block" id="UniEncoderSpanDecoderModel.loss">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderSpanDecoderModel.loss">[docs]</a>
</span><span data-line="1539">    <span class="k">def</span><span class="w"> </span><span class="nf">loss</span><span class="p">(</span>
</span><span data-line="1540">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="1541">        <span class="n">scores</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="1542">        <span class="n">labels</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="1543">        <span class="n">prompts_embedding_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="1544">        <span class="n">mask_label</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="1545">        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span>
</span><span data-line="1546">        <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="1547">        <span class="n">label_smoothing</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="1548">        <span class="n">reduction</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sum&quot;</span><span class="p">,</span>
</span><span data-line="1549">        <span class="n">negatives</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span data-line="1550">        <span class="n">masking</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;none&quot;</span><span class="p">,</span>
</span><span data-line="1551">        <span class="n">decoder_loss</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1552">        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span data-line="1553">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span data-line="1554"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute combined loss for span classification and decoder.</span>
</span><span data-line="1555">
</span><span data-line="1556"><span class="sd">        Args:</span>
</span><span data-line="1557"><span class="sd">            scores: Predicted span scores of shape (B, L, K, C).</span>
</span><span data-line="1558"><span class="sd">            labels: Ground truth span labels of shape (B, L, K, C).</span>
</span><span data-line="1559"><span class="sd">            prompts_embedding_mask: Mask for valid entity types of shape (B, C).</span>
</span><span data-line="1560"><span class="sd">            mask_label: Mask for valid spans of shape (B, L, K).</span>
</span><span data-line="1561"><span class="sd">            alpha: Focal loss alpha parameter.</span>
</span><span data-line="1562"><span class="sd">            gamma: Focal loss gamma parameter.</span>
</span><span data-line="1563"><span class="sd">            label_smoothing: Label smoothing factor.</span>
</span><span data-line="1564"><span class="sd">            reduction: Loss reduction method (&#39;sum&#39; or &#39;mean&#39;).</span>
</span><span data-line="1565"><span class="sd">            negatives: Negative sampling probability.</span>
</span><span data-line="1566"><span class="sd">            masking: Masking strategy for negative sampling.</span>
</span><span data-line="1567"><span class="sd">            decoder_loss: Optional decoder loss to combine with span loss.</span>
</span><span data-line="1568"><span class="sd">            **kwargs: Additional arguments.</span>
</span><span data-line="1569">
</span><span data-line="1570"><span class="sd">        Returns:</span>
</span><span data-line="1571"><span class="sd">            Scalar combined loss tensor.</span>
</span><span data-line="1572"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="1573">        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span data-line="1574">        <span class="n">num_classes</span> <span class="o">=</span> <span class="n">prompts_embedding_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span data-line="1575">
</span><span data-line="1576">        <span class="n">BS</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">CL</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">shape</span>
</span><span data-line="1577">
</span><span data-line="1578">        <span class="n">scores</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">BS</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">CL</span><span class="p">)</span>
</span><span data-line="1579">        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">BS</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">CL</span><span class="p">)</span>
</span><span data-line="1580">
</span><span data-line="1581">        <span class="n">all_losses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">label_smoothing</span><span class="p">,</span> <span class="n">negatives</span><span class="o">=</span><span class="n">negatives</span><span class="p">,</span> <span class="n">masking</span><span class="o">=</span><span class="n">masking</span><span class="p">)</span>
</span><span data-line="1582">
</span><span data-line="1583">        <span class="n">masked_loss</span> <span class="o">=</span> <span class="n">all_losses</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span> <span class="o">*</span> <span class="n">prompts_embedding_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1584">        <span class="n">all_losses</span> <span class="o">=</span> <span class="n">masked_loss</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
</span><span data-line="1585">
</span><span data-line="1586">        <span class="n">mask_label</span> <span class="o">=</span> <span class="n">mask_label</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span data-line="1587">
</span><span data-line="1588">        <span class="n">all_losses</span> <span class="o">=</span> <span class="n">all_losses</span> <span class="o">*</span> <span class="n">mask_label</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
</span><span data-line="1589">
</span><span data-line="1590">        <span class="k">if</span> <span class="n">reduction</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
</span><span data-line="1591">            <span class="n">loss</span> <span class="o">=</span> <span class="n">all_losses</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span data-line="1592">        <span class="k">elif</span> <span class="n">reduction</span> <span class="o">==</span> <span class="s2">&quot;sum&quot;</span><span class="p">:</span>
</span><span data-line="1593">            <span class="n">loss</span> <span class="o">=</span> <span class="n">all_losses</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span data-line="1594">        <span class="k">else</span><span class="p">:</span>
</span><span data-line="1595">            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
</span><span data-line="1596">                <span class="sa">f</span><span class="s2">&quot;Invalid Value for config &#39;loss_reduction&#39;: &#39;</span><span class="si">{</span><span class="n">reduction</span><span class="si">}</span><span class="s2">&#39; </span><span class="se">\n</span><span class="s2"> Supported reduction modes:&quot;</span>
</span><span data-line="1597">                <span class="sa">f</span><span class="s2">&quot; &#39;none&#39;, &#39;mean&#39;, &#39;sum&#39;. It will be used &#39;sum&#39; instead.&quot;</span><span class="p">,</span>
</span><span data-line="1598">                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span data-line="1599">            <span class="p">)</span>
</span><span data-line="1600">            <span class="n">loss</span> <span class="o">=</span> <span class="n">all_losses</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span data-line="1601">
</span><span data-line="1602">        <span class="k">if</span> <span class="n">decoder_loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="1603">            <span class="n">loss</span> <span class="o">=</span> <span class="n">decoder_loss</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">decoder_loss_coef</span> <span class="o">+</span> <span class="n">loss</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">span_loss_coef</span>
</span><span data-line="1604">
</span><span data-line="1605">        <span class="k">return</span> <span class="n">loss</span></div>
</div>

</span><span data-line="1606">
</span><span data-line="1607">
<div class="viewcode-block" id="UniEncoderTokenDecoderModel">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderTokenDecoderModel">[docs]</a>
</span><span data-line="1608"><span class="k">class</span><span class="w"> </span><span class="nc">UniEncoderTokenDecoderModel</span><span class="p">(</span><span class="n">UniEncoderTokenModel</span><span class="p">,</span> <span class="n">UniEncoderSpanDecoderModel</span><span class="p">):</span>
</span><span data-line="1609"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Token-based NER model with encoder-decoder architecture.</span>
</span><span data-line="1610">
</span><span data-line="1611"><span class="sd">    This model combines token-level BIO-style classification with a decoder</span>
</span><span data-line="1612"><span class="sd">    that generates entity type labels autoregressively, enabling more flexible</span>
</span><span data-line="1613"><span class="sd">    prediction strategies for token-level NER tasks.</span>
</span><span data-line="1614">
</span><span data-line="1615"><span class="sd">    Inherits from:</span>
</span><span data-line="1616"><span class="sd">        - UniEncoderTokenModel: Token-level BIO tagging for entities</span>
</span><span data-line="1617"><span class="sd">        - UniEncoderSpanDecoderModel: Encoder-decoder architecture and decoder utilities</span>
</span><span data-line="1618">
</span><span data-line="1619"><span class="sd">    Attributes:</span>
</span><span data-line="1620"><span class="sd">        scorer (Scorer): Scoring layer for computing token-label compatibility.</span>
</span><span data-line="1621"><span class="sd">        decoder (Decoder): Decoder module for label generation.</span>
</span><span data-line="1622"><span class="sd">        span_rep_layer (SpanRepLayer): Layer for computing span representations (if represent_spans=True).</span>
</span><span data-line="1623"><span class="sd">        _enc2dec_proj (Optional[nn.Module]): Projection layer if encoder and decoder</span>
</span><span data-line="1624"><span class="sd">            dimensions differ.</span>
</span><span data-line="1625"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="1626">
<div class="viewcode-block" id="UniEncoderTokenDecoderModel.__init__">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderTokenDecoderModel.__init__">[docs]</a>
</span><span data-line="1627">    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span data-line="1628">        <span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="1629">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="1630"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the token-level encoder-decoder model.</span>
</span><span data-line="1631">
</span><span data-line="1632"><span class="sd">        Args:</span>
</span><span data-line="1633"><span class="sd">            config: Model configuration object.</span>
</span><span data-line="1634"><span class="sd">            from_pretrained: Whether to load from pretrained weights.</span>
</span><span data-line="1635"><span class="sd">            cache_dir: Directory for caching pretrained models.</span>
</span><span data-line="1636"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="1637">        <span class="c1"># Initialize through UniEncoderTokenModel&#39;s chain to get scorer</span>
</span><span data-line="1638">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">)</span>
</span><span data-line="1639">        <span class="bp">self</span><span class="o">.</span><span class="n">__init_decoder__</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">)</span></div>

</span><span data-line="1640">
<div class="viewcode-block" id="UniEncoderTokenDecoderModel.select_token_decoder_embedding">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderTokenDecoderModel.select_token_decoder_embedding">[docs]</a>
</span><span data-line="1641">    <span class="k">def</span><span class="w"> </span><span class="nf">select_token_decoder_embedding</span><span class="p">(</span>
</span><span data-line="1642">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="1643">        <span class="n">prompts_embedding</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="1644">        <span class="n">prompts_embedding_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="1645">        <span class="n">span_logits</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1646">        <span class="n">span_rep</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1647">        <span class="n">span_idx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1648">        <span class="n">span_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1649">        <span class="n">span_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1650">        <span class="n">decoder_text_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1651">        <span class="n">decoder_words_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1652">        <span class="n">top_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1653">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
</span><span data-line="1654"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Select entity embeddings for decoder input based on token predictions or labels.</span>
</span><span data-line="1655">
</span><span data-line="1656"><span class="sd">        This method extracts entity spans from token-level predictions and prepares</span>
</span><span data-line="1657"><span class="sd">        their representations for the decoder. It can operate in two modes:</span>
</span><span data-line="1658"><span class="sd">        1. &quot;prompt&quot; mode: Uses entity type embeddings as decoder input.</span>
</span><span data-line="1659"><span class="sd">        2. &quot;span&quot; mode: Uses contextualized tokens within each detected span as decoder input.</span>
</span><span data-line="1660">
</span><span data-line="1661"><span class="sd">        Args:</span>
</span><span data-line="1662"><span class="sd">            prompts_embedding: Entity type embeddings of shape (B, C, D).</span>
</span><span data-line="1663"><span class="sd">            prompts_embedding_mask: Mask for prompts of shape (B, C).</span>
</span><span data-line="1664"><span class="sd">            words_embedding: Word-level embeddings of shape (B, W, D).</span>
</span><span data-line="1665"><span class="sd">            token_scores: Token classification scores of shape (B, W, C, 3).</span>
</span><span data-line="1666"><span class="sd">            word_mask: Mask for valid words of shape (B, W).</span>
</span><span data-line="1667"><span class="sd">            span_logits: Span-level classification logits of shape (B, S, C),</span>
</span><span data-line="1668"><span class="sd">            span_rep: Span representations (B, S, D).</span>
</span><span data-line="1669"><span class="sd">            span_idx: Pre-computed span indices of shape (B, S, 2).</span>
</span><span data-line="1670"><span class="sd">            span_labels: Ground truth span labels of shape (B, S, C)</span>
</span><span data-line="1671"><span class="sd">            span_mask: Pre-computed span mask of shape (B, S).</span>
</span><span data-line="1672"><span class="sd">            decoder_text_embeds: Text embeddings for span mode of shape (B, T, D).</span>
</span><span data-line="1673"><span class="sd">            decoder_words_mask: Word position mask of shape (B, T).</span>
</span><span data-line="1674"><span class="sd">            labels: Ground truth token-level labels of shape (B, W, C, 3).</span>
</span><span data-line="1675"><span class="sd">            threshold: Confidence threshold for selecting spans.</span>
</span><span data-line="1676"><span class="sd">            top_k: Optional limit on number of spans to select.</span>
</span><span data-line="1677">
</span><span data-line="1678"><span class="sd">        Returns:</span>
</span><span data-line="1679"><span class="sd">            Tuple containing:</span>
</span><span data-line="1680"><span class="sd">                - span_rep_kept: Selected span embeddings for decoder of shape (B, S, T, D)</span>
</span><span data-line="1681"><span class="sd">                  or None if no valid spans.</span>
</span><span data-line="1682"><span class="sd">                - span_msk: Mask for selected spans of shape (B, S, T) or None.</span>
</span><span data-line="1683"><span class="sd">                - span_sel_idx: Original indices of selected spans of shape (B, S) or None.</span>
</span><span data-line="1684"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="1685">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">decoder_mode</span> <span class="o">==</span> <span class="s2">&quot;prompt&quot;</span><span class="p">:</span>
</span><span data-line="1686">            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_decoder_embedding</span><span class="p">(</span><span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">)[:</span><span class="mi">3</span><span class="p">]</span>
</span><span data-line="1687">
</span><span data-line="1688">        <span class="n">span_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">span_logits</span><span class="p">)</span>
</span><span data-line="1689">
</span><span data-line="1690">        <span class="c1"># Flatten span representations for selection</span>
</span><span data-line="1691">        <span class="n">B</span> <span class="o">=</span> <span class="n">span_rep</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span data-line="1692">
</span><span data-line="1693">        <span class="k">if</span> <span class="n">span_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="1694">            <span class="c1"># During training: select spans where any class is positive (label == 1)</span>
</span><span data-line="1695">            <span class="n">span_prob</span> <span class="o">=</span> <span class="n">span_labels</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># (B, S)</span>
</span><span data-line="1696">            <span class="n">keep</span> <span class="o">=</span> <span class="p">(</span><span class="n">span_prob</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">span_mask</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
</span><span data-line="1697">        <span class="k">else</span><span class="p">:</span>
</span><span data-line="1698">            <span class="c1"># During inference: use predicted scores</span>
</span><span data-line="1699">            <span class="n">span_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">span_logits</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># (B, S)</span>
</span><span data-line="1700">            <span class="n">keep</span> <span class="o">=</span> <span class="p">(</span><span class="n">span_scores</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">span_mask</span><span class="o">.</span><span class="n">bool</span>
</span><span data-line="1701">
</span><span data-line="1702">        <span class="k">if</span> <span class="n">top_k</span><span class="p">:</span>
</span><span data-line="1703">            <span class="n">sel_scores</span> <span class="o">=</span> <span class="n">span_scores</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="o">~</span><span class="n">keep</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">)</span>
</span><span data-line="1704">            <span class="n">top_idx</span> <span class="o">=</span> <span class="n">sel_scores</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">top_k</span><span class="p">,</span> <span class="n">sel_scores</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">indices</span>
</span><span data-line="1705">            <span class="n">keep</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
</span><span data-line="1706">            <span class="n">keep</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">top_idx</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</span><span data-line="1707">
</span><span data-line="1708">        <span class="c1"># Pack valid spans</span>
</span><span data-line="1709">        <span class="n">span_rep_kept</span><span class="p">,</span> <span class="n">span_msk</span><span class="p">,</span> <span class="n">span_sel_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_decoder_embedding</span><span class="p">(</span><span class="n">span_rep</span><span class="p">,</span> <span class="n">keep</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
</span><span data-line="1710">
</span><span data-line="1711">        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_enc2dec_proj&quot;</span><span class="p">):</span>
</span><span data-line="1712">            <span class="n">span_rep_kept</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_enc2dec_proj</span><span class="p">(</span><span class="n">span_rep_kept</span><span class="p">)</span>
</span><span data-line="1713">
</span><span data-line="1714">        <span class="n">span_rep_kept</span> <span class="o">=</span> <span class="n">span_rep_kept</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span data-line="1715">        <span class="n">span_msk</span> <span class="o">=</span> <span class="n">span_msk</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1716">
</span><span data-line="1717">        <span class="k">if</span> <span class="n">decoder_text_embeds</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">decoder_words_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="1718">            <span class="k">return</span> <span class="n">span_rep_kept</span><span class="p">,</span> <span class="n">span_msk</span><span class="p">,</span> <span class="n">span_sel_idx</span>
</span><span data-line="1719">
</span><span data-line="1720">        <span class="k">if</span> <span class="n">span_rep_kept</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span data-line="1721">            <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
</span><span data-line="1722">
</span><span data-line="1723">        <span class="n">decoder_text_embeds</span> <span class="o">=</span> <span class="n">decoder_text_embeds</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">span_rep_kept</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span data-line="1724">
</span><span data-line="1725">        <span class="c1"># Build span representations with context tokens</span>
</span><span data-line="1726">        <span class="n">S_kept</span> <span class="o">=</span> <span class="n">span_rep_kept</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span data-line="1727">        <span class="n">dec_D</span> <span class="o">=</span> <span class="n">span_rep_kept</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span data-line="1728">
</span><span data-line="1729">        <span class="c1"># Get actual span boundaries from selected indices</span>
</span><span data-line="1730">        <span class="n">batch_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">span_idx</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">S_kept</span><span class="p">)</span>
</span><span data-line="1731">        <span class="n">selected_spans</span> <span class="o">=</span> <span class="n">span_idx</span><span class="p">[</span><span class="n">batch_indices</span><span class="p">,</span> <span class="n">span_sel_idx</span><span class="p">]</span>  <span class="c1"># (B, S_kept, 2)</span>
</span><span data-line="1732">
</span><span data-line="1733">        <span class="n">span_start</span> <span class="o">=</span> <span class="n">selected_spans</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># (B, S_kept)</span>
</span><span data-line="1734">        <span class="n">span_end</span> <span class="o">=</span> <span class="n">selected_spans</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># (B, S_kept)</span>
</span><span data-line="1735">
</span><span data-line="1736">        <span class="c1"># Determine which decoder tokens belong to each span</span>
</span><span data-line="1737">        <span class="n">token_in_span</span> <span class="o">=</span> <span class="p">(</span><span class="n">decoder_words_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">span_start</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">&amp;</span> <span class="p">(</span>
</span><span data-line="1738">            <span class="n">decoder_words_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">span_end</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1739">        <span class="p">)</span>
</span><span data-line="1740">
</span><span data-line="1741">        <span class="n">tokens_per_span</span> <span class="o">=</span> <span class="n">token_in_span</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1742">        <span class="n">max_tokens</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">tokens_per_span</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
</span><span data-line="1743">
</span><span data-line="1744">        <span class="n">span_rep_new</span> <span class="o">=</span> <span class="n">span_rep_kept</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">S_kept</span><span class="p">,</span> <span class="n">max_tokens</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dec_D</span><span class="p">)</span>
</span><span data-line="1745">        <span class="n">span_rep_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">S_kept</span><span class="p">,</span> <span class="n">max_tokens</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">decoder_text_embeds</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span data-line="1746">
</span><span data-line="1747">        <span class="n">left_offset</span> <span class="o">=</span> <span class="p">(</span><span class="n">max_tokens</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">tokens_per_span</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span data-line="1748">        <span class="n">pos_in_span</span> <span class="o">=</span> <span class="p">(</span><span class="n">token_in_span</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="o">~</span><span class="n">token_in_span</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span><span data-line="1749">        <span class="n">pos_in_span</span> <span class="o">=</span> <span class="n">pos_in_span</span> <span class="o">+</span> <span class="n">left_offset</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1750">
</span><span data-line="1751">        <span class="n">b_idx</span><span class="p">,</span> <span class="n">s_idx</span><span class="p">,</span> <span class="n">tok_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">token_in_span</span><span class="p">)</span>
</span><span data-line="1752">        <span class="n">span_rep_new</span><span class="p">[</span><span class="n">b_idx</span><span class="p">,</span> <span class="n">s_idx</span><span class="p">,</span> <span class="n">pos_in_span</span><span class="p">[</span><span class="n">b_idx</span><span class="p">,</span> <span class="n">s_idx</span><span class="p">,</span> <span class="n">tok_idx</span><span class="p">]]</span> <span class="o">=</span> <span class="n">decoder_text_embeds</span><span class="p">[</span><span class="n">b_idx</span><span class="p">,</span> <span class="n">tok_idx</span><span class="p">]</span>
</span><span data-line="1753">        <span class="n">span_rep_mask</span><span class="p">[</span><span class="n">b_idx</span><span class="p">,</span> <span class="n">s_idx</span><span class="p">,</span> <span class="n">pos_in_span</span><span class="p">[</span><span class="n">b_idx</span><span class="p">,</span> <span class="n">s_idx</span><span class="p">,</span> <span class="n">tok_idx</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">True</span>
</span><span data-line="1754">
</span><span data-line="1755">        <span class="n">kept_pos</span> <span class="o">=</span> <span class="p">(</span><span class="n">left_offset</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span data-line="1756">
</span><span data-line="1757">        <span class="n">b_flat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">decoder_text_embeds</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">S_kept</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1758">        <span class="n">s_flat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">S_kept</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">decoder_text_embeds</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">S_kept</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1759">        <span class="n">t_flat</span> <span class="o">=</span> <span class="n">kept_pos</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1760">
</span><span data-line="1761">        <span class="n">span_rep_new</span><span class="p">[</span><span class="n">b_flat</span><span class="p">,</span> <span class="n">s_flat</span><span class="p">,</span> <span class="n">t_flat</span><span class="p">]</span> <span class="o">=</span> <span class="n">span_rep_kept</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dec_D</span><span class="p">)</span>
</span><span data-line="1762">        <span class="n">span_rep_mask</span><span class="p">[</span><span class="n">b_flat</span><span class="p">,</span> <span class="n">s_flat</span><span class="p">,</span> <span class="n">t_flat</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
</span><span data-line="1763">        <span class="n">span_rep_mask</span> <span class="o">=</span> <span class="n">span_rep_mask</span> <span class="o">&amp;</span> <span class="n">span_msk</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
</span><span data-line="1764">
</span><span data-line="1765">        <span class="k">return</span> <span class="n">span_rep_new</span><span class="p">,</span> <span class="n">span_rep_mask</span><span class="p">,</span> <span class="n">span_sel_idx</span></div>

</span><span data-line="1766">
<div class="viewcode-block" id="UniEncoderTokenDecoderModel.forward">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderTokenDecoderModel.forward">[docs]</a>
</span><span data-line="1767">    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span data-line="1768">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="1769">        <span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1770">        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1771">        <span class="n">decoder_input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1772">        <span class="n">decoder_attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1773">        <span class="n">decoder_labels_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1774">        <span class="n">decoder_labels_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1775">        <span class="n">decoder_words_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1776">        <span class="n">words_embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1777">        <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1778">        <span class="n">span_idx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1779">        <span class="n">span_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1780">        <span class="n">span_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1781">        <span class="n">prompts_embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1782">        <span class="n">prompts_embedding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1783">        <span class="n">words_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1784">        <span class="n">text_lengths</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1785">        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1786">        <span class="n">decoder_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1787">        <span class="n">threshold</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
</span><span data-line="1788">        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span data-line="1789">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GLiNERDecoderOutput</span><span class="p">:</span>
</span><span data-line="1790"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward pass through the token-level encoder-decoder model.</span>
</span><span data-line="1791">
</span><span data-line="1792"><span class="sd">        Args:</span>
</span><span data-line="1793"><span class="sd">            input_ids: Input token IDs of shape (B, L).</span>
</span><span data-line="1794"><span class="sd">            attention_mask: Attention mask of shape (B, L).</span>
</span><span data-line="1795"><span class="sd">            decoder_input_ids: Decoder input IDs for span mode.</span>
</span><span data-line="1796"><span class="sd">            decoder_attention_mask: Decoder attention mask.</span>
</span><span data-line="1797"><span class="sd">            decoder_labels_ids: Label token IDs for decoding of shape (M, L).</span>
</span><span data-line="1798"><span class="sd">            decoder_labels_mask: Mask for decoder labels of shape (M, L).</span>
</span><span data-line="1799"><span class="sd">            decoder_words_mask: Word position mask for span mode.</span>
</span><span data-line="1800"><span class="sd">            words_embedding: Pre-computed word embeddings.</span>
</span><span data-line="1801"><span class="sd">            mask: Mask for words.</span>
</span><span data-line="1802"><span class="sd">            span_idx: Pre-computed span indices of shape (B, S, 2).</span>
</span><span data-line="1803"><span class="sd">            span_mask: Pre-computed span mask of shape (B, S).</span>
</span><span data-line="1804"><span class="sd">            span_labels: Ground truth span labels of shape (B, S, C).</span>
</span><span data-line="1805"><span class="sd">            prompts_embedding: Pre-computed entity type embeddings.</span>
</span><span data-line="1806"><span class="sd">            prompts_embedding_mask: Mask for prompts.</span>
</span><span data-line="1807"><span class="sd">            words_mask: Word boundary mask.</span>
</span><span data-line="1808"><span class="sd">            text_lengths: Length of each text sequence.</span>
</span><span data-line="1809"><span class="sd">            labels: Ground truth token-level labels of shape (B, W, C, 3).</span>
</span><span data-line="1810"><span class="sd">            decoder_labels: Ground truth decoder labels of shape (M, L).</span>
</span><span data-line="1811"><span class="sd">            threshold: Confidence threshold for span selection.</span>
</span><span data-line="1812"><span class="sd">            **kwargs: Additional arguments.</span>
</span><span data-line="1813">
</span><span data-line="1814"><span class="sd">        Returns:</span>
</span><span data-line="1815"><span class="sd">            GLiNERDecoderOutput containing logits, losses, and decoder information.</span>
</span><span data-line="1816"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="1817">        <span class="n">encoder_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">kwargs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;packing_config&quot;</span><span class="p">,</span> <span class="s2">&quot;pair_attention_mask&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">}</span>
</span><span data-line="1818">
</span><span data-line="1819">        <span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">,</span> <span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_representations</span><span class="p">(</span>
</span><span data-line="1820">            <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">text_lengths</span><span class="p">,</span> <span class="n">words_mask</span><span class="p">,</span> <span class="o">**</span><span class="n">encoder_kwargs</span>
</span><span data-line="1821">        <span class="p">)</span>
</span><span data-line="1822">
</span><span data-line="1823">        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="1824">            <span class="n">target_W</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span data-line="1825">            <span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_length</span><span class="p">(</span><span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">target_W</span><span class="p">)</span>
</span><span data-line="1826">
</span><span data-line="1827">            <span class="n">target_C</span> <span class="o">=</span> <span class="n">prompts_embedding</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="1828">            <span class="n">target_C</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">target_C</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">))</span>
</span><span data-line="1829">
</span><span data-line="1830">            <span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_length</span><span class="p">(</span>
</span><span data-line="1831">                <span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">,</span> <span class="n">target_C</span>
</span><span data-line="1832">            <span class="p">)</span>
</span><span data-line="1833">
</span><span data-line="1834">        <span class="c1"># Token-level classification: (B, W, C, 3)</span>
</span><span data-line="1835">        <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="p">(</span><span class="n">words_embedding</span><span class="p">,</span> <span class="n">prompts_embedding</span><span class="p">)</span>
</span><span data-line="1836">
</span><span data-line="1837">        <span class="c1"># Get span representations and logits if represent_spans is enabled</span>
</span><span data-line="1838">        <span class="n">span_rep</span><span class="p">,</span> <span class="n">span_idx</span><span class="p">,</span> <span class="n">span_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_span_representations</span><span class="p">(</span>
</span><span data-line="1839">            <span class="n">scores</span><span class="p">,</span> <span class="n">span_idx</span><span class="p">,</span> <span class="n">span_mask</span><span class="p">,</span> <span class="n">words_embedding</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">threshold</span>
</span><span data-line="1840">        <span class="p">)</span>
</span><span data-line="1841">        <span class="n">span_logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;BND,BCD-&gt;BNC&quot;</span><span class="p">,</span> <span class="n">span_rep</span><span class="p">,</span> <span class="n">prompts_embedding</span><span class="p">)</span>
</span><span data-line="1842">
</span><span data-line="1843">        <span class="c1"># Decoder processing</span>
</span><span data-line="1844">        <span class="n">decoder_embedding</span> <span class="o">=</span> <span class="n">decoder_mask</span> <span class="o">=</span> <span class="n">decoder_loss</span> <span class="o">=</span> <span class="n">decoder_span_idx</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="1845">        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;decoder&quot;</span><span class="p">):</span>
</span><span data-line="1846">            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">decoder_mode</span> <span class="o">==</span> <span class="s2">&quot;span&quot;</span><span class="p">:</span>
</span><span data-line="1847">                <span class="n">decoder_text_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">ids_to_embeds</span><span class="p">(</span><span class="n">decoder_input_ids</span><span class="p">)</span>
</span><span data-line="1848">            <span class="k">else</span><span class="p">:</span>
</span><span data-line="1849">                <span class="n">decoder_text_embeds</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="1850">
</span><span data-line="1851">            <span class="n">decoder_embedding</span><span class="p">,</span> <span class="n">decoder_mask</span><span class="p">,</span> <span class="n">decoder_span_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_token_decoder_embedding</span><span class="p">(</span>
</span><span data-line="1852">                <span class="n">prompts_embedding</span><span class="p">,</span>
</span><span data-line="1853">                <span class="n">prompts_embedding_mask</span><span class="p">,</span>
</span><span data-line="1854">                <span class="n">span_logits</span><span class="o">=</span><span class="n">span_logits</span><span class="p">,</span>
</span><span data-line="1855">                <span class="n">span_rep</span><span class="o">=</span><span class="n">span_rep</span><span class="p">,</span>
</span><span data-line="1856">                <span class="n">span_idx</span><span class="o">=</span><span class="n">span_idx</span><span class="p">,</span>
</span><span data-line="1857">                <span class="n">span_mask</span><span class="o">=</span><span class="n">span_mask</span><span class="p">,</span>
</span><span data-line="1858">                <span class="n">span_labels</span><span class="o">=</span><span class="n">span_labels</span><span class="p">,</span>
</span><span data-line="1859">                <span class="n">decoder_text_embeds</span><span class="o">=</span><span class="n">decoder_text_embeds</span><span class="p">,</span>
</span><span data-line="1860">                <span class="n">decoder_words_mask</span><span class="o">=</span><span class="n">decoder_words_mask</span><span class="p">,</span>
</span><span data-line="1861">            <span class="p">)</span>
</span><span data-line="1862">
</span><span data-line="1863">            <span class="k">if</span> <span class="n">decoder_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="1864">                <span class="n">decoder_loss</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode_labels</span><span class="p">(</span>
</span><span data-line="1865">                    <span class="n">decoder_embedding</span><span class="p">,</span> <span class="n">decoder_mask</span><span class="p">,</span> <span class="n">decoder_labels_ids</span><span class="p">,</span> <span class="n">decoder_labels_mask</span><span class="p">,</span> <span class="n">decoder_labels</span>
</span><span data-line="1866">                <span class="p">)</span>
</span><span data-line="1867">
</span><span data-line="1868">        <span class="c1"># Compute loss</span>
</span><span data-line="1869">        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="1870">        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="1871">            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span>
</span><span data-line="1872">                <span class="n">scores</span><span class="p">,</span>
</span><span data-line="1873">                <span class="n">labels</span><span class="p">,</span>
</span><span data-line="1874">                <span class="n">prompts_embedding_mask</span><span class="p">,</span>
</span><span data-line="1875">                <span class="n">mask</span><span class="p">,</span>
</span><span data-line="1876">                <span class="n">span_logits</span><span class="o">=</span><span class="n">span_logits</span><span class="p">,</span>
</span><span data-line="1877">                <span class="n">span_labels</span><span class="o">=</span><span class="n">span_labels</span><span class="p">,</span>
</span><span data-line="1878">                <span class="n">span_mask</span><span class="o">=</span><span class="n">span_mask</span><span class="p">,</span>
</span><span data-line="1879">                <span class="n">decoder_loss</span><span class="o">=</span><span class="n">decoder_loss</span><span class="p">,</span>
</span><span data-line="1880">                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span data-line="1881">            <span class="p">)</span>
</span><span data-line="1882">
</span><span data-line="1883">        <span class="n">output</span> <span class="o">=</span> <span class="n">GLiNERDecoderOutput</span><span class="p">(</span>
</span><span data-line="1884">            <span class="n">logits</span><span class="o">=</span><span class="n">scores</span><span class="p">,</span>
</span><span data-line="1885">            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
</span><span data-line="1886">            <span class="n">decoder_loss</span><span class="o">=</span><span class="n">decoder_loss</span><span class="p">,</span>
</span><span data-line="1887">            <span class="n">prompts_embedding</span><span class="o">=</span><span class="n">prompts_embedding</span><span class="p">,</span>
</span><span data-line="1888">            <span class="n">prompts_embedding_mask</span><span class="o">=</span><span class="n">prompts_embedding_mask</span><span class="p">,</span>
</span><span data-line="1889">            <span class="n">decoder_embedding</span><span class="o">=</span><span class="n">decoder_embedding</span><span class="p">,</span>
</span><span data-line="1890">            <span class="n">decoder_embedding_mask</span><span class="o">=</span><span class="n">decoder_mask</span><span class="p">,</span>
</span><span data-line="1891">            <span class="n">decoder_span_idx</span><span class="o">=</span><span class="n">decoder_span_idx</span><span class="p">,</span>
</span><span data-line="1892">            <span class="n">words_embedding</span><span class="o">=</span><span class="n">words_embedding</span><span class="p">,</span>
</span><span data-line="1893">            <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span>
</span><span data-line="1894">            <span class="n">span_idx</span><span class="o">=</span><span class="n">span_idx</span><span class="p">,</span>
</span><span data-line="1895">            <span class="n">span_logits</span><span class="o">=</span><span class="n">span_logits</span><span class="p">,</span>
</span><span data-line="1896">            <span class="n">span_mask</span><span class="o">=</span><span class="n">span_mask</span><span class="p">,</span>
</span><span data-line="1897">        <span class="p">)</span>
</span><span data-line="1898">        <span class="k">return</span> <span class="n">output</span></div>

</span><span data-line="1899">
<div class="viewcode-block" id="UniEncoderTokenDecoderModel.loss">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderTokenDecoderModel.loss">[docs]</a>
</span><span data-line="1900">    <span class="k">def</span><span class="w"> </span><span class="nf">loss</span><span class="p">(</span>
</span><span data-line="1901">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="1902">        <span class="n">scores</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="1903">        <span class="n">labels</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="1904">        <span class="n">prompts_embedding_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="1905">        <span class="n">word_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="1906">        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span>
</span><span data-line="1907">        <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="1908">        <span class="n">prob_margin</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="1909">        <span class="n">label_smoothing</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="1910">        <span class="n">reduction</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sum&quot;</span><span class="p">,</span>
</span><span data-line="1911">        <span class="n">negatives</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span data-line="1912">        <span class="n">span_logits</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1913">        <span class="n">span_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1914">        <span class="n">span_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1915">        <span class="n">decoder_loss</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="1916">        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span data-line="1917">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span data-line="1918"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute combined loss for token classification, spans, and decoder.</span>
</span><span data-line="1919">
</span><span data-line="1920"><span class="sd">        Args:</span>
</span><span data-line="1921"><span class="sd">            scores: Predicted token scores of shape (B, W, C, 3).</span>
</span><span data-line="1922"><span class="sd">            labels: Ground truth token labels of shape (B, W, C, 3).</span>
</span><span data-line="1923"><span class="sd">            prompts_embedding_mask: Mask for valid entity types of shape (B, C).</span>
</span><span data-line="1924"><span class="sd">            word_mask: Mask for valid words of shape (B, W).</span>
</span><span data-line="1925"><span class="sd">            alpha: Focal loss alpha parameter.</span>
</span><span data-line="1926"><span class="sd">            gamma: Focal loss gamma parameter.</span>
</span><span data-line="1927"><span class="sd">            prob_margin: Margin for probability adjustment.</span>
</span><span data-line="1928"><span class="sd">            label_smoothing: Label smoothing factor.</span>
</span><span data-line="1929"><span class="sd">            reduction: Loss reduction method (&#39;sum&#39; or &#39;mean&#39;).</span>
</span><span data-line="1930"><span class="sd">            negatives: Negative sampling probability.</span>
</span><span data-line="1931"><span class="sd">            span_logits: Optional span logits of shape (B, S, C).</span>
</span><span data-line="1932"><span class="sd">            span_labels: Optional span labels of shape (B, S, C).</span>
</span><span data-line="1933"><span class="sd">            span_mask: Optional span mask of shape (B, S).</span>
</span><span data-line="1934"><span class="sd">            decoder_loss: Optional decoder loss to combine.</span>
</span><span data-line="1935"><span class="sd">            **kwargs: Additional arguments.</span>
</span><span data-line="1936">
</span><span data-line="1937"><span class="sd">        Returns:</span>
</span><span data-line="1938"><span class="sd">            Scalar combined loss tensor.</span>
</span><span data-line="1939"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="1940">        <span class="c1"># Token-level loss (use parent&#39;s loss function)</span>
</span><span data-line="1941">        <span class="n">token_loss</span> <span class="o">=</span> <span class="n">UniEncoderTokenModel</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span>
</span><span data-line="1942">            <span class="bp">self</span><span class="p">,</span>
</span><span data-line="1943">            <span class="n">scores</span><span class="p">,</span>
</span><span data-line="1944">            <span class="n">labels</span><span class="p">,</span>
</span><span data-line="1945">            <span class="n">prompts_embedding_mask</span><span class="p">,</span>
</span><span data-line="1946">            <span class="n">word_mask</span><span class="p">,</span>
</span><span data-line="1947">            <span class="n">alpha</span><span class="p">,</span>
</span><span data-line="1948">            <span class="n">gamma</span><span class="p">,</span>
</span><span data-line="1949">            <span class="n">prob_margin</span><span class="p">,</span>
</span><span data-line="1950">            <span class="n">label_smoothing</span><span class="p">,</span>
</span><span data-line="1951">            <span class="n">reduction</span><span class="p">,</span>
</span><span data-line="1952">            <span class="n">negatives</span><span class="p">,</span>
</span><span data-line="1953">            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span data-line="1954">        <span class="p">)</span>
</span><span data-line="1955">
</span><span data-line="1956">        <span class="c1"># Combine with span loss if available</span>
</span><span data-line="1957">        <span class="k">if</span> <span class="n">span_logits</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">span_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">span_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="1958">            <span class="n">span_loss</span> <span class="o">=</span> <span class="n">UniEncoderTokenModel</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span>
</span><span data-line="1959">                <span class="bp">self</span><span class="p">,</span>
</span><span data-line="1960">                <span class="n">span_logits</span><span class="p">,</span>
</span><span data-line="1961">                <span class="n">span_labels</span><span class="p">,</span>
</span><span data-line="1962">                <span class="n">prompts_embedding_mask</span><span class="p">,</span>
</span><span data-line="1963">                <span class="n">span_mask</span><span class="p">,</span>
</span><span data-line="1964">                <span class="n">alpha</span><span class="p">,</span>
</span><span data-line="1965">                <span class="n">gamma</span><span class="p">,</span>
</span><span data-line="1966">                <span class="n">prob_margin</span><span class="p">,</span>
</span><span data-line="1967">                <span class="n">label_smoothing</span><span class="p">,</span>
</span><span data-line="1968">                <span class="n">reduction</span><span class="p">,</span>
</span><span data-line="1969">                <span class="n">negatives</span><span class="p">,</span>
</span><span data-line="1970">                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span data-line="1971">            <span class="p">)</span>
</span><span data-line="1972">            <span class="n">token_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">token_loss_coef</span> <span class="o">*</span> <span class="n">token_loss</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">span_loss_coef</span> <span class="o">*</span> <span class="n">span_loss</span>
</span><span data-line="1973">
</span><span data-line="1974">        <span class="c1"># Combine with decoder loss if available</span>
</span><span data-line="1975">        <span class="k">if</span> <span class="n">decoder_loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="1976">            <span class="n">total_loss</span> <span class="o">=</span> <span class="n">decoder_loss</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">decoder_loss_coef</span> <span class="o">+</span> <span class="n">token_loss</span> <span class="o">*</span> <span class="nb">getattr</span><span class="p">(</span>
</span><span data-line="1977">                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;token_loss_coef&quot;</span><span class="p">,</span> <span class="mf">1.0</span>
</span><span data-line="1978">            <span class="p">)</span>
</span><span data-line="1979">            <span class="k">return</span> <span class="n">total_loss</span>
</span><span data-line="1980">
</span><span data-line="1981">        <span class="k">return</span> <span class="n">token_loss</span></div>
</div>

</span><span data-line="1982">
</span><span data-line="1983">
<div class="viewcode-block" id="UniEncoderSpanRelexModel">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderSpanRelexModel">[docs]</a>
</span><span data-line="1984"><span class="k">class</span><span class="w"> </span><span class="nc">UniEncoderSpanRelexModel</span><span class="p">(</span><span class="n">UniEncoderSpanModel</span><span class="p">):</span>
</span><span data-line="1985"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Span-based NER model with relation extraction capabilities.</span>
</span><span data-line="1986">
</span><span data-line="1987"><span class="sd">    This model extends span-based NER to also extract relations between</span>
</span><span data-line="1988"><span class="sd">    identified entities, predicting both entity types and relation types</span>
</span><span data-line="1989"><span class="sd">    in a joint model.</span>
</span><span data-line="1990">
</span><span data-line="1991"><span class="sd">    Attributes:</span>
</span><span data-line="1992"><span class="sd">        relations_rep_layer (Optional[RelationsRepLayer]): Layer for computing</span>
</span><span data-line="1993"><span class="sd">            pairwise entity relations (adjacency matrix).</span>
</span><span data-line="1994"><span class="sd">        triples_score_layer (Optional[TriplesScoreLayer]): Layer for scoring</span>
</span><span data-line="1995"><span class="sd">            (head, relation, tail) triples.</span>
</span><span data-line="1996"><span class="sd">        pair_rep_layer (Optional[nn.Module]): Alternative layer for relation</span>
</span><span data-line="1997"><span class="sd">            scoring via concatenation.</span>
</span><span data-line="1998"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="1999">
<div class="viewcode-block" id="UniEncoderSpanRelexModel.__init__">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderSpanRelexModel.__init__">[docs]</a>
</span><span data-line="2000">    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span data-line="2001">        <span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="2002">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="2003"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the span-based relation extraction model.</span>
</span><span data-line="2004">
</span><span data-line="2005"><span class="sd">        Args:</span>
</span><span data-line="2006"><span class="sd">            config: Model configuration object.</span>
</span><span data-line="2007"><span class="sd">            from_pretrained: Whether to load from pretrained weights.</span>
</span><span data-line="2008"><span class="sd">            cache_dir: Directory for caching pretrained models.</span>
</span><span data-line="2009"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="2010">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">)</span>
</span><span data-line="2011">
</span><span data-line="2012">        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">relations_layer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="2013">            <span class="bp">self</span><span class="o">.</span><span class="n">relations_rep_layer</span> <span class="o">=</span> <span class="n">RelationsRepLayer</span><span class="p">(</span>
</span><span data-line="2014">                <span class="n">in_dim</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">relation_mode</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">relations_layer</span>
</span><span data-line="2015">            <span class="p">)</span>
</span><span data-line="2016">
</span><span data-line="2017">            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">triples_layer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="2018">                <span class="bp">self</span><span class="o">.</span><span class="n">triples_score_layer</span> <span class="o">=</span> <span class="n">TriplesScoreLayer</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">triples_layer</span><span class="p">)</span>
</span><span data-line="2019">            <span class="k">else</span><span class="p">:</span>
</span><span data-line="2020">                <span class="bp">self</span><span class="o">.</span><span class="n">pair_rep_layer</span> <span class="o">=</span> <span class="n">create_projection_layer</span><span class="p">(</span>
</span><span data-line="2021">                    <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span>
</span><span data-line="2022">                <span class="p">)</span></div>

</span><span data-line="2023">
<div class="viewcode-block" id="UniEncoderSpanRelexModel.select_span_target_embedding">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderSpanRelexModel.select_span_target_embedding">[docs]</a>
</span><span data-line="2024">    <span class="k">def</span><span class="w"> </span><span class="nf">select_span_target_embedding</span><span class="p">(</span>
</span><span data-line="2025">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="2026">        <span class="n">span_rep</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">,</span>
</span><span data-line="2027">        <span class="n">span_scores</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">,</span>
</span><span data-line="2028">        <span class="n">span_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">,</span>
</span><span data-line="2029">        <span class="n">span_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="2030">        <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
</span><span data-line="2031">        <span class="n">top_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="2032">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span data-line="2033"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Select entity spans for relation extraction.</span>
</span><span data-line="2034">
</span><span data-line="2035"><span class="sd">        Filters spans based on entity classification scores or ground truth labels,</span>
</span><span data-line="2036"><span class="sd">        keeping only high-confidence or positive entity spans for relation modeling.</span>
</span><span data-line="2037">
</span><span data-line="2038"><span class="sd">        Args:</span>
</span><span data-line="2039"><span class="sd">            span_rep: Span representations of shape (B, L, K, D).</span>
</span><span data-line="2040"><span class="sd">            span_scores: Span classification scores of shape (B, L, K, C).</span>
</span><span data-line="2041"><span class="sd">            span_mask: Mask for valid spans of shape (B, L, K).</span>
</span><span data-line="2042"><span class="sd">            span_labels: Optional ground truth labels of shape (B, L, K, C).</span>
</span><span data-line="2043"><span class="sd">            threshold: Confidence threshold for selecting spans.</span>
</span><span data-line="2044"><span class="sd">            top_k: Optional limit on number of spans to select.</span>
</span><span data-line="2045">
</span><span data-line="2046"><span class="sd">        Returns:</span>
</span><span data-line="2047"><span class="sd">            Tuple containing:</span>
</span><span data-line="2048"><span class="sd">                - target_rep: Selected span representations of shape (B, E, D).</span>
</span><span data-line="2049"><span class="sd">                - target_mask: Mask for selected spans of shape (B, E).</span>
</span><span data-line="2050"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="2051">        <span class="n">B</span> <span class="o">=</span> <span class="n">span_rep</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span data-line="2052">        <span class="n">D</span> <span class="o">=</span> <span class="n">span_rep</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="2053">
</span><span data-line="2054">        <span class="n">span_rep_flat</span> <span class="o">=</span> <span class="n">span_rep</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
</span><span data-line="2055">        <span class="n">span_mask_flat</span> <span class="o">=</span> <span class="n">span_mask</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="2056">
</span><span data-line="2057">        <span class="k">if</span> <span class="n">span_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="2058">            <span class="n">span_prob_flat</span> <span class="o">=</span> <span class="n">span_labels</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="2059">            <span class="n">keep</span> <span class="o">=</span> <span class="p">(</span><span class="n">span_prob_flat</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
</span><span data-line="2060">        <span class="k">else</span><span class="p">:</span>
</span><span data-line="2061">            <span class="n">span_prob_flat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">span_scores</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="2062">            <span class="n">keep</span> <span class="o">=</span> <span class="p">(</span><span class="n">span_prob_flat</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">span_mask_flat</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
</span><span data-line="2063">
</span><span data-line="2064">        <span class="k">if</span> <span class="n">top_k</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">top_k</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span data-line="2065">            <span class="n">sel_scores</span> <span class="o">=</span> <span class="n">span_prob_flat</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="o">~</span><span class="n">keep</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">)</span>
</span><span data-line="2066">            <span class="n">top_idx</span> <span class="o">=</span> <span class="n">sel_scores</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">top_k</span><span class="p">,</span> <span class="n">sel_scores</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">indices</span>
</span><span data-line="2067">            <span class="n">keep</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">keep</span><span class="p">)</span>
</span><span data-line="2068">            <span class="n">keep</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">top_idx</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</span><span data-line="2069">
</span><span data-line="2070">        <span class="n">rep_mask</span> <span class="o">=</span> <span class="n">keep</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
</span><span data-line="2071">
</span><span data-line="2072">        <span class="n">target_rep</span><span class="p">,</span> <span class="n">target_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_target_embedding</span><span class="p">(</span><span class="n">representations</span><span class="o">=</span><span class="n">span_rep_flat</span><span class="p">,</span> <span class="n">rep_mask</span><span class="o">=</span><span class="n">rep_mask</span><span class="p">)</span>
</span><span data-line="2073">
</span><span data-line="2074">        <span class="k">return</span> <span class="n">target_rep</span><span class="p">,</span> <span class="n">target_mask</span></div>

</span><span data-line="2075">
<div class="viewcode-block" id="UniEncoderSpanRelexModel.select_target_embedding">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderSpanRelexModel.select_target_embedding">[docs]</a>
</span><span data-line="2076">    <span class="k">def</span><span class="w"> </span><span class="nf">select_target_embedding</span><span class="p">(</span>
</span><span data-line="2077">        <span class="bp">self</span><span class="p">,</span> <span class="n">representations</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">rep_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="2078">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span data-line="2079"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Pack valid representations by removing masked positions.</span>
</span><span data-line="2080">
</span><span data-line="2081"><span class="sd">        Args:</span>
</span><span data-line="2082"><span class="sd">            representations: Tensor of shape (B, N, D).</span>
</span><span data-line="2083"><span class="sd">            rep_mask: Mask of shape (B, N) where 1 indicates valid position.</span>
</span><span data-line="2084">
</span><span data-line="2085"><span class="sd">        Returns:</span>
</span><span data-line="2086"><span class="sd">            Tuple containing:</span>
</span><span data-line="2087"><span class="sd">                - target_rep: Packed representations of shape (B, M, D).</span>
</span><span data-line="2088"><span class="sd">                - target_mask: Packed mask of shape (B, M).</span>
</span><span data-line="2089"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="2090">        <span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="n">representations</span><span class="o">.</span><span class="n">shape</span>
</span><span data-line="2091">        <span class="n">lengths</span> <span class="o">=</span> <span class="n">rep_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="2092">        <span class="n">max_len</span> <span class="o">=</span> <span class="n">lengths</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span><span data-line="2093">
</span><span data-line="2094">        <span class="k">if</span> <span class="n">max_len</span> <span class="o">!=</span> <span class="n">N</span><span class="p">:</span>
</span><span data-line="2095">            <span class="n">target_rep</span> <span class="o">=</span> <span class="n">representations</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
</span><span data-line="2096">            <span class="n">target_mask</span> <span class="o">=</span> <span class="n">rep_mask</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">max_len</span><span class="p">)</span>
</span><span data-line="2097">
</span><span data-line="2098">            <span class="n">new_col_idx</span> <span class="o">=</span> <span class="n">rep_mask</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
</span><span data-line="2099">            <span class="n">keep</span> <span class="o">=</span> <span class="n">rep_mask</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
</span><span data-line="2100">
</span><span data-line="2101">            <span class="n">batch_idx</span><span class="p">,</span> <span class="n">old_col_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">keep</span><span class="p">)</span>
</span><span data-line="2102">            <span class="n">new_col_idx</span> <span class="o">=</span> <span class="n">new_col_idx</span><span class="p">[</span><span class="n">keep</span><span class="p">]</span>
</span><span data-line="2103">
</span><span data-line="2104">            <span class="n">target_rep</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">,</span> <span class="n">new_col_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">representations</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">,</span> <span class="n">old_col_idx</span><span class="p">]</span>
</span><span data-line="2105">            <span class="n">target_mask</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">,</span> <span class="n">new_col_idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span data-line="2106">        <span class="k">else</span><span class="p">:</span>
</span><span data-line="2107">            <span class="n">target_rep</span> <span class="o">=</span> <span class="n">representations</span>
</span><span data-line="2108">            <span class="n">target_mask</span> <span class="o">=</span> <span class="n">rep_mask</span>
</span><span data-line="2109">
</span><span data-line="2110">        <span class="k">return</span> <span class="n">target_rep</span><span class="p">,</span> <span class="n">target_mask</span></div>

</span><span data-line="2111">
<div class="viewcode-block" id="UniEncoderSpanRelexModel.represent_spans">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderSpanRelexModel.represent_spans">[docs]</a>
</span><span data-line="2112">    <span class="k">def</span><span class="w"> </span><span class="nf">represent_spans</span><span class="p">(</span>
</span><span data-line="2113">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="2114">        <span class="n">words_embeddings</span><span class="p">,</span>
</span><span data-line="2115">        <span class="n">words_mask</span><span class="p">,</span>
</span><span data-line="2116">        <span class="n">prompts_embeddings</span><span class="p">,</span>
</span><span data-line="2117">        <span class="n">span_idx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="2118">        <span class="n">span_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="2119">        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="2120">        <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
</span><span data-line="2121">    <span class="p">):</span>
</span><span data-line="2122">        <span class="n">span_idx</span> <span class="o">=</span> <span class="n">span_idx</span> <span class="o">*</span> <span class="n">span_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
</span><span data-line="2123">        <span class="n">span_rep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">span_rep_layer</span><span class="p">(</span><span class="n">words_embeddings</span><span class="p">,</span> <span class="n">span_idx</span><span class="p">)</span>
</span><span data-line="2124">        <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;BLKD,BCD-&gt;BLKC&quot;</span><span class="p">,</span> <span class="n">span_rep</span><span class="p">,</span> <span class="n">prompts_embeddings</span><span class="p">)</span>
</span><span data-line="2125">
</span><span data-line="2126">        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;relations_rep_layer&quot;</span><span class="p">):</span>
</span><span data-line="2127">            <span class="n">target_span_rep</span><span class="p">,</span> <span class="n">target_span_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_span_target_embedding</span><span class="p">(</span>
</span><span data-line="2128">                <span class="n">span_rep</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">span_mask</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">threshold</span>
</span><span data-line="2129">            <span class="p">)</span>
</span><span data-line="2130">        <span class="k">else</span><span class="p">:</span>
</span><span data-line="2131">            <span class="n">target_span_rep</span><span class="p">,</span> <span class="n">target_span_mask</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
</span><span data-line="2132">        <span class="k">return</span> <span class="n">scores</span><span class="p">,</span> <span class="n">target_span_rep</span><span class="p">,</span> <span class="n">target_span_mask</span></div>

</span><span data-line="2133">
<div class="viewcode-block" id="UniEncoderSpanRelexModel.forward">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderSpanRelexModel.forward">[docs]</a>
</span><span data-line="2134">    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span data-line="2135">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="2136">        <span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="2137">        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="2138">        <span class="n">words_embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="2139">        <span class="n">mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="2140">        <span class="n">prompts_embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="2141">        <span class="n">prompts_embedding_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="2142">        <span class="n">words_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="2143">        <span class="n">text_lengths</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="2144">        <span class="n">span_idx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="2145">        <span class="n">span_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="2146">        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="2147">        <span class="n">adj_matrix</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="2148">        <span class="n">rel_matrix</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="2149">        <span class="n">threshold</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
</span><span data-line="2150">        <span class="n">adjacency_threshold</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
</span><span data-line="2151">        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span data-line="2152">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GLiNERRelexOutput</span><span class="p">:</span>
</span><span data-line="2153"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward pass through the relation extraction model.</span>
</span><span data-line="2154">
</span><span data-line="2155"><span class="sd">        Args:</span>
</span><span data-line="2156"><span class="sd">            input_ids: Input token IDs of shape (B, L).</span>
</span><span data-line="2157"><span class="sd">            attention_mask: Attention mask of shape (B, L).</span>
</span><span data-line="2158"><span class="sd">            words_embedding: Pre-computed word embeddings.</span>
</span><span data-line="2159"><span class="sd">            mask: Mask for words.</span>
</span><span data-line="2160"><span class="sd">            prompts_embedding: Pre-computed entity type embeddings.</span>
</span><span data-line="2161"><span class="sd">            prompts_embedding_mask: Mask for entity types.</span>
</span><span data-line="2162"><span class="sd">            words_mask: Word boundary mask.</span>
</span><span data-line="2163"><span class="sd">            text_lengths: Length of each text sequence.</span>
</span><span data-line="2164"><span class="sd">            span_idx: Span indices of shape (B, L*K, 2).</span>
</span><span data-line="2165"><span class="sd">            span_mask: Mask for valid spans of shape (B, L, K).</span>
</span><span data-line="2166"><span class="sd">            labels: Ground truth entity labels of shape (B, L, K, C).</span>
</span><span data-line="2167"><span class="sd">            adj_matrix: Ground truth adjacency matrix of shape (B, E, E).</span>
</span><span data-line="2168"><span class="sd">            rel_matrix: Ground truth relation labels of shape (B, N, C_rel).</span>
</span><span data-line="2169"><span class="sd">            threshold: Confidence threshold for entity selection.</span>
</span><span data-line="2170"><span class="sd">            adjacency_threshold: Threshold for relation adjacency.</span>
</span><span data-line="2171"><span class="sd">            **kwargs: Additional arguments.</span>
</span><span data-line="2172">
</span><span data-line="2173"><span class="sd">        Returns:</span>
</span><span data-line="2174"><span class="sd">            GLiNERRelexOutput containing entity and relation predictions.</span>
</span><span data-line="2175"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="2176">        <span class="n">encoder_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">kwargs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;packing_config&quot;</span><span class="p">,</span> <span class="s2">&quot;pair_attention_mask&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">}</span>
</span><span data-line="2177">
</span><span data-line="2178">        <span class="n">token_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_rep_layer</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="o">**</span><span class="n">encoder_kwargs</span><span class="p">)</span>
</span><span data-line="2179">
</span><span data-line="2180">        <span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">,</span> <span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span>
</span><span data-line="2181">            <span class="bp">self</span><span class="o">.</span><span class="n">_extract_prompt_features_and_word_embeddings</span><span class="p">(</span>
</span><span data-line="2182">                <span class="n">token_embeds</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">text_lengths</span><span class="p">,</span> <span class="n">words_mask</span>
</span><span data-line="2183">            <span class="p">)</span>
</span><span data-line="2184">        <span class="p">)</span>
</span><span data-line="2185">
</span><span data-line="2186">        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;rnn&quot;</span><span class="p">):</span>
</span><span data-line="2187">            <span class="n">words_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
</span><span data-line="2188">
</span><span data-line="2189">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">span_mode</span> <span class="o">==</span> <span class="s2">&quot;token_level&quot;</span><span class="p">:</span>
</span><span data-line="2190">            <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="2191">                <span class="n">target_W</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span data-line="2192">                <span class="n">target_C</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">prompts_embedding</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">))</span>
</span><span data-line="2193">            <span class="k">else</span><span class="p">:</span>
</span><span data-line="2194">                <span class="n">target_W</span> <span class="o">=</span> <span class="n">words_embedding</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="2195">                <span class="n">target_C</span> <span class="o">=</span> <span class="n">prompts_embedding</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="2196">        <span class="k">else</span><span class="p">:</span>
</span><span data-line="2197">            <span class="n">target_W</span> <span class="o">=</span> <span class="n">span_idx</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_width</span>
</span><span data-line="2198">            <span class="n">target_C</span> <span class="o">=</span> <span class="n">prompts_embedding</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="2199">            <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="2200">                <span class="n">target_C</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">target_C</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span data-line="2201">
</span><span data-line="2202">        <span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_length</span><span class="p">(</span><span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">target_W</span><span class="p">)</span>
</span><span data-line="2203">
</span><span data-line="2204">        <span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_length</span><span class="p">(</span>
</span><span data-line="2205">            <span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">,</span> <span class="n">target_C</span>
</span><span data-line="2206">        <span class="p">)</span>
</span><span data-line="2207">
</span><span data-line="2208">        <span class="n">prompts_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_rep_layer</span><span class="p">(</span><span class="n">prompts_embedding</span><span class="p">)</span>
</span><span data-line="2209">        <span class="n">batch_size</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">embed_dim</span> <span class="o">=</span> <span class="n">prompts_embedding</span><span class="o">.</span><span class="n">shape</span>
</span><span data-line="2210">
</span><span data-line="2211">        <span class="n">scores</span><span class="p">,</span> <span class="n">target_span_rep</span><span class="p">,</span> <span class="n">target_span_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">represent_spans</span><span class="p">(</span>
</span><span data-line="2212">            <span class="n">words_embedding</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">prompts_embedding</span><span class="p">,</span> <span class="n">span_idx</span><span class="p">,</span> <span class="n">span_mask</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">threshold</span>
</span><span data-line="2213">        <span class="p">)</span>
</span><span data-line="2214">
</span><span data-line="2215">        <span class="n">pair_idx</span><span class="p">,</span> <span class="n">pair_mask</span><span class="p">,</span> <span class="n">pair_scores</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
</span><span data-line="2216">        <span class="n">rel_prompts_embedding_mask</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="2217">        <span class="n">pred_adj_matrix</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="2218">
</span><span data-line="2219">        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;relations_rep_layer&quot;</span><span class="p">):</span>
</span><span data-line="2220">            <span class="n">pred_adj_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relations_rep_layer</span><span class="p">(</span><span class="n">target_span_rep</span><span class="p">,</span> <span class="n">target_span_mask</span><span class="p">)</span>
</span><span data-line="2221">
</span><span data-line="2222">            <span class="n">rel_prompts_embedding</span><span class="p">,</span> <span class="n">rel_prompts_embedding_mask</span> <span class="o">=</span> <span class="n">extract_prompt_features</span><span class="p">(</span>
</span><span data-line="2223">                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">rel_token_index</span><span class="p">,</span>
</span><span data-line="2224">                <span class="n">token_embeds</span><span class="p">,</span>
</span><span data-line="2225">                <span class="n">input_ids</span><span class="p">,</span>
</span><span data-line="2226">                <span class="n">attention_mask</span><span class="p">,</span>
</span><span data-line="2227">                <span class="n">batch_size</span><span class="p">,</span>
</span><span data-line="2228">                <span class="n">embed_dim</span><span class="p">,</span>
</span><span data-line="2229">                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">embed_rel_token</span><span class="p">,</span>
</span><span data-line="2230">            <span class="p">)</span>
</span><span data-line="2231">
</span><span data-line="2232">            <span class="n">B</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="n">target_span_rep</span><span class="o">.</span><span class="n">shape</span>
</span><span data-line="2233">            <span class="n">C_rel</span> <span class="o">=</span> <span class="n">rel_prompts_embedding</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="2234">
</span><span data-line="2235">            <span class="n">adj_for_selection</span> <span class="o">=</span> <span class="n">adj_matrix</span> <span class="k">if</span> <span class="p">(</span><span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">adj_matrix</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="k">else</span> <span class="n">pred_adj_matrix</span>
</span><span data-line="2236">
</span><span data-line="2237">            <span class="n">pair_idx</span><span class="p">,</span> <span class="n">pair_mask</span><span class="p">,</span> <span class="n">head_rep_selected</span><span class="p">,</span> <span class="n">tail_rep_selected</span> <span class="o">=</span> <span class="n">build_entity_pairs</span><span class="p">(</span>
</span><span data-line="2238">                <span class="n">adj_for_selection</span><span class="p">,</span> <span class="n">target_span_rep</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="n">adjacency_threshold</span>
</span><span data-line="2239">            <span class="p">)</span>
</span><span data-line="2240">
</span><span data-line="2241">            <span class="n">N</span> <span class="o">=</span> <span class="n">head_rep_selected</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="2242">
</span><span data-line="2243">            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;pair_rep_layer&quot;</span><span class="p">):</span>
</span><span data-line="2244">                <span class="n">pair_rep</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">head_rep_selected</span><span class="p">,</span> <span class="n">tail_rep_selected</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="2245">                <span class="n">pair_rep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pair_rep_layer</span><span class="p">(</span><span class="n">pair_rep</span><span class="p">)</span>
</span><span data-line="2246">                <span class="n">pair_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;BND,BCD-&gt;BNC&quot;</span><span class="p">,</span> <span class="n">pair_rep</span><span class="p">,</span> <span class="n">rel_prompts_embedding</span><span class="p">)</span>
</span><span data-line="2247">
</span><span data-line="2248">            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;triples_score_layer&quot;</span><span class="p">):</span>
</span><span data-line="2249">                <span class="n">h</span> <span class="o">=</span> <span class="n">head_rep_selected</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">C_rel</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
</span><span data-line="2250">                <span class="n">t</span> <span class="o">=</span> <span class="n">tail_rep_selected</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">C_rel</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
</span><span data-line="2251">                <span class="n">r</span> <span class="o">=</span> <span class="n">rel_prompts_embedding</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">C_rel</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
</span><span data-line="2252">
</span><span data-line="2253">                <span class="n">h_flat</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span> <span class="o">*</span> <span class="n">N</span> <span class="o">*</span> <span class="n">C_rel</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
</span><span data-line="2254">                <span class="n">t_flat</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span> <span class="o">*</span> <span class="n">N</span> <span class="o">*</span> <span class="n">C_rel</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
</span><span data-line="2255">                <span class="n">r_flat</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span> <span class="o">*</span> <span class="n">N</span> <span class="o">*</span> <span class="n">C_rel</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
</span><span data-line="2256">
</span><span data-line="2257">                <span class="n">triple_scores_flat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">triples_score_layer</span><span class="p">(</span><span class="n">h_flat</span><span class="p">,</span> <span class="n">r_flat</span><span class="p">,</span> <span class="n">t_flat</span><span class="p">)</span>
</span><span data-line="2258">                <span class="n">pair_scores</span> <span class="o">=</span> <span class="n">triple_scores_flat</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">C_rel</span><span class="p">)</span>
</span><span data-line="2259">
</span><span data-line="2260">        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="2261">        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="2262">            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">prompts_embedding_mask</span><span class="p">,</span> <span class="n">span_mask</span><span class="o">=</span><span class="n">span_mask</span><span class="p">,</span> <span class="n">word_mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span data-line="2263">
</span><span data-line="2264">            <span class="k">if</span> <span class="n">adj_matrix</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">rel_matrix</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;relations_rep_layer&quot;</span><span class="p">):</span>
</span><span data-line="2265">                <span class="n">adj_mask</span> <span class="o">=</span> <span class="n">target_span_mask</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">target_span_mask</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span><span data-line="2266">                <span class="n">adj_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">adj_loss</span><span class="p">(</span><span class="n">pred_adj_matrix</span><span class="p">,</span> <span class="n">adj_matrix</span><span class="p">,</span> <span class="n">adj_mask</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span data-line="2267">
</span><span data-line="2268">                <span class="n">rel_labels_selected</span> <span class="o">=</span> <span class="n">rel_matrix</span>
</span><span data-line="2269">                <span class="n">rel_mask_selected</span> <span class="o">=</span> <span class="n">pair_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">C_rel</span><span class="p">)</span>
</span><span data-line="2270">                <span class="n">class_mask</span> <span class="o">=</span> <span class="n">rel_prompts_embedding_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">C_rel</span><span class="p">)</span>
</span><span data-line="2271">
</span><span data-line="2272">                <span class="n">rel_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rel_loss</span><span class="p">(</span><span class="n">pair_scores</span><span class="p">,</span> <span class="n">rel_labels_selected</span><span class="p">,</span> <span class="n">rel_mask_selected</span><span class="p">,</span> <span class="n">class_mask</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span data-line="2273">
</span><span data-line="2274">                <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span>
</span><span data-line="2275">                    <span class="n">loss</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">span_loss_coef</span>
</span><span data-line="2276">                    <span class="o">+</span> <span class="n">adj_loss</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">adjacency_loss_coef</span>
</span><span data-line="2277">                    <span class="o">+</span> <span class="n">rel_loss</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">relation_loss_coef</span>
</span><span data-line="2278">                <span class="p">)</span>
</span><span data-line="2279">
</span><span data-line="2280">        <span class="n">output</span> <span class="o">=</span> <span class="n">GLiNERRelexOutput</span><span class="p">(</span>
</span><span data-line="2281">            <span class="n">logits</span><span class="o">=</span><span class="n">scores</span><span class="p">,</span>
</span><span data-line="2282">            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
</span><span data-line="2283">            <span class="n">prompts_embedding</span><span class="o">=</span><span class="n">prompts_embedding</span><span class="p">,</span>
</span><span data-line="2284">            <span class="n">prompts_embedding_mask</span><span class="o">=</span><span class="n">prompts_embedding_mask</span><span class="p">,</span>
</span><span data-line="2285">            <span class="n">words_embedding</span><span class="o">=</span><span class="n">words_embedding</span><span class="p">,</span>
</span><span data-line="2286">            <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span>
</span><span data-line="2287">            <span class="n">rel_idx</span><span class="o">=</span><span class="n">pair_idx</span><span class="p">,</span>
</span><span data-line="2288">            <span class="n">rel_logits</span><span class="o">=</span><span class="n">pair_scores</span><span class="p">,</span>
</span><span data-line="2289">            <span class="n">rel_mask</span><span class="o">=</span><span class="n">pair_mask</span><span class="p">,</span>
</span><span data-line="2290">        <span class="p">)</span>
</span><span data-line="2291">        <span class="k">return</span> <span class="n">output</span></div>

</span><span data-line="2292">
<div class="viewcode-block" id="UniEncoderSpanRelexModel.adj_loss">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderSpanRelexModel.adj_loss">[docs]</a>
</span><span data-line="2293">    <span class="k">def</span><span class="w"> </span><span class="nf">adj_loss</span><span class="p">(</span>
</span><span data-line="2294">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="2295">        <span class="n">logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="2296">        <span class="n">labels</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="2297">        <span class="n">adj_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="2298">        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span>
</span><span data-line="2299">        <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="2300">        <span class="n">prob_margin</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="2301">        <span class="n">label_smoothing</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="2302">        <span class="n">reduction</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sum&quot;</span><span class="p">,</span>
</span><span data-line="2303">        <span class="n">masking</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;span&quot;</span><span class="p">,</span>
</span><span data-line="2304">        <span class="n">negatives</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span data-line="2305">        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span data-line="2306">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span data-line="2307"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute adjacency matrix loss for entity pair relations.</span>
</span><span data-line="2308">
</span><span data-line="2309"><span class="sd">        Args:</span>
</span><span data-line="2310"><span class="sd">            logits: Predicted adjacency scores of shape (B, E, E).</span>
</span><span data-line="2311"><span class="sd">            labels: Ground truth adjacency of shape (B, E, E).</span>
</span><span data-line="2312"><span class="sd">            adj_mask: Mask for valid entity pairs of shape (B, E, E).</span>
</span><span data-line="2313"><span class="sd">            alpha: Focal loss alpha parameter.</span>
</span><span data-line="2314"><span class="sd">            gamma: Focal loss gamma parameter.</span>
</span><span data-line="2315"><span class="sd">            prob_margin: Margin for probability adjustment.</span>
</span><span data-line="2316"><span class="sd">            label_smoothing: Label smoothing factor.</span>
</span><span data-line="2317"><span class="sd">            reduction: Loss reduction method (&#39;sum&#39; or &#39;mean&#39;).</span>
</span><span data-line="2318"><span class="sd">            masking: Masking strategy for negative sampling.</span>
</span><span data-line="2319"><span class="sd">            negatives: Negative sampling probability.</span>
</span><span data-line="2320"><span class="sd">            **kwargs: Additional arguments.</span>
</span><span data-line="2321">
</span><span data-line="2322"><span class="sd">        Returns:</span>
</span><span data-line="2323"><span class="sd">            Scalar adjacency loss tensor.</span>
</span><span data-line="2324"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="2325">        <span class="n">B</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span data-line="2326">
</span><span data-line="2327">        <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span data-line="2328">        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span data-line="2329">
</span><span data-line="2330">        <span class="n">all_losses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span>
</span><span data-line="2331">            <span class="n">logits</span><span class="p">,</span>
</span><span data-line="2332">            <span class="n">labels</span><span class="p">,</span>
</span><span data-line="2333">            <span class="n">alpha</span><span class="p">,</span>
</span><span data-line="2334">            <span class="n">gamma</span><span class="p">,</span>
</span><span data-line="2335">            <span class="n">prob_margin</span><span class="p">,</span>
</span><span data-line="2336">            <span class="n">label_smoothing</span><span class="p">,</span>
</span><span data-line="2337">            <span class="n">negatives</span><span class="o">=</span><span class="n">negatives</span><span class="p">,</span>
</span><span data-line="2338">            <span class="n">masking</span><span class="o">=</span><span class="n">masking</span><span class="p">,</span>
</span><span data-line="2339">            <span class="n">normalize_prob</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span><span data-line="2340">        <span class="p">)</span>
</span><span data-line="2341">
</span><span data-line="2342">        <span class="n">masked_loss</span> <span class="o">=</span> <span class="n">all_losses</span> <span class="o">*</span> <span class="n">adj_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span data-line="2343">
</span><span data-line="2344">        <span class="k">if</span> <span class="n">reduction</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
</span><span data-line="2345">            <span class="n">num_valid</span> <span class="o">=</span> <span class="n">adj_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span data-line="2346">            <span class="n">loss</span> <span class="o">=</span> <span class="n">masked_loss</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">num_valid</span> <span class="k">if</span> <span class="n">num_valid</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">logits</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span data-line="2347">        <span class="k">elif</span> <span class="n">reduction</span> <span class="o">==</span> <span class="s2">&quot;sum&quot;</span><span class="p">:</span>
</span><span data-line="2348">            <span class="n">loss</span> <span class="o">=</span> <span class="n">masked_loss</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span data-line="2349">        <span class="k">else</span><span class="p">:</span>
</span><span data-line="2350">            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
</span><span data-line="2351">                <span class="sa">f</span><span class="s2">&quot;Invalid Value for config &#39;loss_reduction&#39;: &#39;</span><span class="si">{</span><span class="n">reduction</span><span class="si">}</span><span class="s2">&#39; </span><span class="se">\n</span><span class="s2"> Supported reduction modes:&quot;</span>
</span><span data-line="2352">                <span class="sa">f</span><span class="s2">&quot; &#39;none&#39;, &#39;mean&#39;, &#39;sum&#39;. It will be used &#39;sum&#39; instead.&quot;</span><span class="p">,</span>
</span><span data-line="2353">                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span data-line="2354">            <span class="p">)</span>
</span><span data-line="2355">            <span class="n">loss</span> <span class="o">=</span> <span class="n">masked_loss</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span data-line="2356">        <span class="k">return</span> <span class="n">loss</span></div>

</span><span data-line="2357">
<div class="viewcode-block" id="UniEncoderSpanRelexModel.rel_loss">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderSpanRelexModel.rel_loss">[docs]</a>
</span><span data-line="2358">    <span class="k">def</span><span class="w"> </span><span class="nf">rel_loss</span><span class="p">(</span>
</span><span data-line="2359">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="2360">        <span class="n">logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="2361">        <span class="n">labels</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="2362">        <span class="n">pair_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="2363">        <span class="n">class_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="2364">        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span>
</span><span data-line="2365">        <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="2366">        <span class="n">prob_margin</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="2367">        <span class="n">label_smoothing</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="2368">        <span class="n">reduction</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sum&quot;</span><span class="p">,</span>
</span><span data-line="2369">        <span class="n">negatives</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span data-line="2370">        <span class="n">masking</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;span&quot;</span><span class="p">,</span>
</span><span data-line="2371">        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span data-line="2372">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span data-line="2373"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute relation classification loss for selected entity pairs.</span>
</span><span data-line="2374">
</span><span data-line="2375"><span class="sd">        Args:</span>
</span><span data-line="2376"><span class="sd">            logits: Predicted relation scores of shape (B, N, C).</span>
</span><span data-line="2377"><span class="sd">            labels: Ground truth relation labels of shape (B, N, C).</span>
</span><span data-line="2378"><span class="sd">            pair_mask: Mask for valid pairs of shape (B, N, C).</span>
</span><span data-line="2379"><span class="sd">            class_mask: Mask for valid relation classes of shape (B, N, C).</span>
</span><span data-line="2380"><span class="sd">            alpha: Focal loss alpha parameter.</span>
</span><span data-line="2381"><span class="sd">            gamma: Focal loss gamma parameter.</span>
</span><span data-line="2382"><span class="sd">            prob_margin: Margin for probability adjustment.</span>
</span><span data-line="2383"><span class="sd">            label_smoothing: Label smoothing factor.</span>
</span><span data-line="2384"><span class="sd">            reduction: Loss reduction method (&#39;sum&#39; or &#39;mean&#39;).</span>
</span><span data-line="2385"><span class="sd">            negatives: Negative sampling probability.</span>
</span><span data-line="2386"><span class="sd">            masking: Masking strategy for negative sampling.</span>
</span><span data-line="2387"><span class="sd">            **kwargs: Additional arguments.</span>
</span><span data-line="2388">
</span><span data-line="2389"><span class="sd">        Returns:</span>
</span><span data-line="2390"><span class="sd">            Scalar relation classification loss tensor.</span>
</span><span data-line="2391"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="2392">        <span class="n">B</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span>
</span><span data-line="2393">
</span><span data-line="2394">        <span class="n">all_losses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span>
</span><span data-line="2395">            <span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">prob_margin</span><span class="p">,</span> <span class="n">label_smoothing</span><span class="p">,</span> <span class="n">negatives</span><span class="o">=</span><span class="n">negatives</span><span class="p">,</span> <span class="n">masking</span><span class="o">=</span><span class="n">masking</span>
</span><span data-line="2396">        <span class="p">)</span>
</span><span data-line="2397">
</span><span data-line="2398">        <span class="n">combined_mask</span> <span class="o">=</span> <span class="n">pair_mask</span> <span class="o">*</span> <span class="n">class_mask</span>
</span><span data-line="2399">        <span class="n">masked_loss</span> <span class="o">=</span> <span class="n">all_losses</span> <span class="o">*</span> <span class="n">combined_mask</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span>
</span><span data-line="2400">
</span><span data-line="2401">        <span class="k">if</span> <span class="n">reduction</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
</span><span data-line="2402">            <span class="n">num_valid</span> <span class="o">=</span> <span class="n">combined_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span data-line="2403">            <span class="n">loss</span> <span class="o">=</span> <span class="n">masked_loss</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">num_valid</span> <span class="k">if</span> <span class="n">num_valid</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">logits</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span data-line="2404">        <span class="k">elif</span> <span class="n">reduction</span> <span class="o">==</span> <span class="s2">&quot;sum&quot;</span><span class="p">:</span>
</span><span data-line="2405">            <span class="n">loss</span> <span class="o">=</span> <span class="n">masked_loss</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span data-line="2406">        <span class="k">else</span><span class="p">:</span>
</span><span data-line="2407">            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
</span><span data-line="2408">                <span class="sa">f</span><span class="s2">&quot;Invalid Value for config &#39;loss_reduction&#39;: &#39;</span><span class="si">{</span><span class="n">reduction</span><span class="si">}</span><span class="s2">&#39; </span><span class="se">\n</span><span class="s2"> Supported reduction modes:&quot;</span>
</span><span data-line="2409">                <span class="sa">f</span><span class="s2">&quot; &#39;none&#39;, &#39;mean&#39;, &#39;sum&#39;. It will be used &#39;sum&#39; instead.&quot;</span><span class="p">,</span>
</span><span data-line="2410">                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span data-line="2411">            <span class="p">)</span>
</span><span data-line="2412">            <span class="n">loss</span> <span class="o">=</span> <span class="n">masked_loss</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span data-line="2413">
</span><span data-line="2414">        <span class="k">return</span> <span class="n">loss</span></div>
</div>

</span><span data-line="2415">
</span><span data-line="2416">
<div class="viewcode-block" id="UniEncoderTokenRelexModel">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderTokenRelexModel">[docs]</a>
</span><span data-line="2417"><span class="k">class</span><span class="w"> </span><span class="nc">UniEncoderTokenRelexModel</span><span class="p">(</span><span class="n">UniEncoderSpanRelexModel</span><span class="p">):</span>
</span><span data-line="2418"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Token-level NER model with relation extraction capabilities.</span>
</span><span data-line="2419">
</span><span data-line="2420"><span class="sd">    This model extends token-based NER to also extract relations between</span>
</span><span data-line="2421"><span class="sd">    identified entities, predicting both entity types and relation types</span>
</span><span data-line="2422"><span class="sd">    in a joint model.</span>
</span><span data-line="2423">
</span><span data-line="2424"><span class="sd">    Attributes:</span>
</span><span data-line="2425"><span class="sd">        relations_rep_layer (Optional[RelationsRepLayer]): Layer for computing</span>
</span><span data-line="2426"><span class="sd">            pairwise entity relations (adjacency matrix).</span>
</span><span data-line="2427"><span class="sd">        triples_score_layer (Optional[TriplesScoreLayer]): Layer for scoring</span>
</span><span data-line="2428"><span class="sd">            (head, relation, tail) triples.</span>
</span><span data-line="2429"><span class="sd">        pair_rep_layer (Optional[nn.Module]): Alternative layer for relation</span>
</span><span data-line="2430"><span class="sd">            scoring via concatenation.</span>
</span><span data-line="2431"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="2432">
<div class="viewcode-block" id="UniEncoderTokenRelexModel.__init__">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderTokenRelexModel.__init__">[docs]</a>
</span><span data-line="2433">    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span data-line="2434">        <span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="2435">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="2436"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the span-based relation extraction model.</span>
</span><span data-line="2437">
</span><span data-line="2438"><span class="sd">        Args:</span>
</span><span data-line="2439"><span class="sd">            config: Model configuration object.</span>
</span><span data-line="2440"><span class="sd">            from_pretrained: Whether to load from pretrained weights.</span>
</span><span data-line="2441"><span class="sd">            cache_dir: Directory for caching pretrained models.</span>
</span><span data-line="2442"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="2443">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">)</span>
</span><span data-line="2444">        <span class="bp">self</span><span class="o">.</span><span class="n">scorer</span> <span class="o">=</span> <span class="n">Scorer</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">dropout</span><span class="p">)</span></div>

</span><span data-line="2445">
<div class="viewcode-block" id="UniEncoderTokenRelexModel.loss">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderTokenRelexModel.loss">[docs]</a>
</span><span data-line="2446">    <span class="k">def</span><span class="w"> </span><span class="nf">loss</span><span class="p">(</span>
</span><span data-line="2447">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="2448">        <span class="n">scores</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="2449">        <span class="n">labels</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="2450">        <span class="n">prompts_embedding_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="2451">        <span class="n">word_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="2452">        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span>
</span><span data-line="2453">        <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="2454">        <span class="n">prob_margin</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="2455">        <span class="n">label_smoothing</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="2456">        <span class="n">reduction</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sum&quot;</span><span class="p">,</span>
</span><span data-line="2457">        <span class="n">negatives</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span data-line="2458">        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span data-line="2459">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span data-line="2460"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute token classification loss.</span>
</span><span data-line="2461">
</span><span data-line="2462"><span class="sd">        Args:</span>
</span><span data-line="2463"><span class="sd">            scores: Predicted scores of shape (B, W, C).</span>
</span><span data-line="2464"><span class="sd">            labels: Ground truth labels of shape (B, W, C).</span>
</span><span data-line="2465"><span class="sd">            prompts_embedding_mask: Mask for valid entity types of shape (B, C).</span>
</span><span data-line="2466"><span class="sd">            word_mask: Mask for valid tokens of shape (B, W).</span>
</span><span data-line="2467"><span class="sd">            alpha: Focal loss alpha parameter.</span>
</span><span data-line="2468"><span class="sd">            gamma: Focal loss gamma parameter.</span>
</span><span data-line="2469"><span class="sd">            prob_margin: Margin for probability adjustment.</span>
</span><span data-line="2470"><span class="sd">            label_smoothing: Label smoothing factor.</span>
</span><span data-line="2471"><span class="sd">            reduction: Loss reduction method (&#39;sum&#39; or &#39;mean&#39;).</span>
</span><span data-line="2472"><span class="sd">            negatives: Negative sampling probability.</span>
</span><span data-line="2473"><span class="sd">            **kwargs: Additional arguments.</span>
</span><span data-line="2474">
</span><span data-line="2475"><span class="sd">        Returns:</span>
</span><span data-line="2476"><span class="sd">            Scalar loss tensor.</span>
</span><span data-line="2477"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="2478">        <span class="n">all_losses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">prob_margin</span><span class="p">,</span> <span class="n">label_smoothing</span><span class="p">,</span> <span class="n">negatives</span><span class="p">)</span>
</span><span data-line="2479">
</span><span data-line="2480">        <span class="n">all_losses</span> <span class="o">=</span> <span class="n">all_losses</span> <span class="o">*</span> <span class="p">(</span><span class="n">word_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">prompts_embedding_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="2481">
</span><span data-line="2482">        <span class="k">if</span> <span class="n">reduction</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
</span><span data-line="2483">            <span class="n">loss</span> <span class="o">=</span> <span class="n">all_losses</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span data-line="2484">        <span class="k">elif</span> <span class="n">reduction</span> <span class="o">==</span> <span class="s2">&quot;sum&quot;</span><span class="p">:</span>
</span><span data-line="2485">            <span class="n">loss</span> <span class="o">=</span> <span class="n">all_losses</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span data-line="2486">        <span class="k">else</span><span class="p">:</span>
</span><span data-line="2487">            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
</span><span data-line="2488">                <span class="sa">f</span><span class="s2">&quot;Invalid Value for config &#39;loss_reduction&#39;: &#39;</span><span class="si">{</span><span class="n">reduction</span><span class="si">}</span><span class="s2">&#39; </span><span class="se">\n</span><span class="s2"> Supported reduction modes:&quot;</span>
</span><span data-line="2489">                <span class="sa">f</span><span class="s2">&quot; &#39;none&#39;, &#39;mean&#39;, &#39;sum&#39;. It will be used &#39;sum&#39; instead.&quot;</span><span class="p">,</span>
</span><span data-line="2490">                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span data-line="2491">            <span class="p">)</span>
</span><span data-line="2492">            <span class="n">loss</span> <span class="o">=</span> <span class="n">all_losses</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span data-line="2493">        <span class="k">return</span> <span class="n">loss</span></div>

</span><span data-line="2494">
<div class="viewcode-block" id="UniEncoderTokenRelexModel.represent_spans">
<a class="viewcode-back" href="../../../api/gliner.modeling.base.html#gliner.modeling.base.UniEncoderTokenRelexModel.represent_spans">[docs]</a>
</span><span data-line="2495">    <span class="k">def</span><span class="w"> </span><span class="nf">represent_spans</span><span class="p">(</span>
</span><span data-line="2496">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="2497">        <span class="n">words_embeddings</span><span class="p">,</span>
</span><span data-line="2498">        <span class="n">words_mask</span><span class="p">,</span>
</span><span data-line="2499">        <span class="n">prompts_embeddings</span><span class="p">,</span>
</span><span data-line="2500">        <span class="n">span_idx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="2501">        <span class="n">span_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="2502">        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="2503">        <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
</span><span data-line="2504">    <span class="p">):</span>
</span><span data-line="2505">        <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scorer</span><span class="p">(</span><span class="n">words_embeddings</span><span class="p">,</span> <span class="n">prompts_embeddings</span><span class="p">)</span>
</span><span data-line="2506">
</span><span data-line="2507">        <span class="k">if</span> <span class="n">span_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="2508">            <span class="n">span_idx</span><span class="p">,</span> <span class="n">span_mask</span> <span class="o">=</span> <span class="n">extract_spans_from_tokens</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span>
</span><span data-line="2509">            <span class="n">span_idx</span> <span class="o">=</span> <span class="n">span_idx</span> <span class="o">*</span> <span class="n">span_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
</span><span data-line="2510">        <span class="n">target_span_rep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">span_rep_layer</span><span class="p">(</span><span class="n">words_embeddings</span><span class="p">,</span> <span class="n">span_idx</span><span class="p">)</span>
</span><span data-line="2511">
</span><span data-line="2512">        <span class="k">return</span> <span class="n">scores</span><span class="p">,</span> <span class="n">target_span_rep</span><span class="p">,</span> <span class="n">span_mask</span></div>
</div>

</span></pre></div>
        </article><button class="back-to-top" type="button">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
  </svg>
  <span>Back to top</span>
</button><div class="navigation flex print:hidden"></div></div>
    </div>
  </main>
</div>
<footer class="sy-foot">
  <div class="sy-foot-inner sy-container mx-auto">
    <div class="sy-foot-reserved md:flex justify-between items-center">
      <div class="sy-foot-copyright"><p>2025, GLiNER community</p>
  
  <p>
    Made with
    
    <a href="https://www.sphinx-doc.org/">Sphinx</a> and
    
    <a href="https://shibuya.lepture.com">Shibuya theme</a>.
  </p>
</div>
      <div class="sy-foot-socials"></div>
    </div>
  </div>
</footer>
      <script src="../../../_static/documentation_options.js?v=dc91f075"></script>
      <script src="../../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../../_static/shibuya.js?v=9b0e4dde"></script></body>
</html>