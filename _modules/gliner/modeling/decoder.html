<!DOCTYPE html>
<html lang="en" data-accent-color="violet" data-content_root="../../../">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>gliner.modeling.decoder - Home 0.2.24 documentation</title><link rel="index" title="Index" href="../../../genindex.html" /><link rel="search" title="Search" href="../../../search.html" /><script>
    function setColorMode(t){let e=document.documentElement;e.setAttribute("data-color-mode",t);let a=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,s=t;"auto"===t&&(s=a?"dark":"light"),"light"===s?(e.classList.remove("dark"),e.classList.add("light")):(e.classList.remove("light"),e.classList.add("dark"))}
    setColorMode(localStorage._theme||"auto");
  </script><link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=e1a1ceaf" />
    <link rel="stylesheet" type="text/css" href="../../../_static/shibuya.css?v=d140fbf8" />
    <link media="print" rel="stylesheet" type="text/css" href="../../../_static/print.css?v=20ff2c19" />
    <link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
<style>
:root {
  --sy-f-text: "Inter", var(--sy-f-sys), var(--sy-f-cjk), sans-serif;
  --sy-f-heading: "Inter", var(--sy-f-sys), var(--sy-f-cjk), sans-serif;
}
</style>
    <meta property="og:type" content="website"/><meta property="og:title" content="gliner.modeling.decoder"/>
<meta name="twitter:card" content="summary"/>
  </head>
<body><div class="sy-head">
  <div class="sy-head-blur"></div>
  <div class="sy-head-inner sy-container mx-auto">
    <a class="sy-head-brand" href="../../../index.html">
      
      
      <strong>Home</strong>
    </a>
    <div class="sy-head-nav" id="head-nav">
      <nav class="sy-head-links"></nav>
      <div class="sy-head-extra flex items-center print:hidden"><form class="searchbox flex items-center" action="../../../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <kbd>/</kbd>
</form><div class="sy-head-socials"></div></div>
    </div>
    <div class="sy-head-actions flex items-center shrink-0 print:hidden"><button class="js-theme theme-switch flex items-center"
data-aria-auto="Switch to light color mode"
data-aria-light="Switch to dark color mode"
data-aria-dark="Switch to auto color mode">
<i class="i-lucide theme-icon"></i>
</button><button class="md:hidden flex items-center js-menu" aria-label="Menu" type="button" aria-controls="head-nav" aria-expanded="false">
        <div class="hamburger">
          <span class="hamburger_1"></span>
          <span class="hamburger_2"></span>
          <span class="hamburger_3"></span>
        </div>
      </button>
    </div>
  </div>
</div>
<div class="sy-page sy-container flex mx-auto">
  <aside id="lside" class="sy-lside md:w-72 md:shrink-0 print:hidden">
    <div class="sy-lside-inner md:sticky">
      <div class="sy-scrollbar p-6">
        <div class="globaltoc" data-expand-depth="0"><p class="caption" role="heading" aria-level="3"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../intro.html">Introduction to ðŸ‘‘ GLiNER</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../instalation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage.html">Advanced Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../configs.html">Components &amp; Configs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../training.html">Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../architectures.html">Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../convert_to_onnx.html">ONNX Export &amp; Deployment</a></li>
</ul>
<p class="caption" role="heading" aria-level="3"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.model.html">gliner.model module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.config.html">gliner.config module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.training.html">gliner.training package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.training.trainer.html">gliner.training.trainer module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.modeling.html">gliner.modeling package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.multitask.html">gliner.modeling.multitask package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gliner.modeling.multitask.relations_layers.html">gliner.modeling.multitask.relations_layers module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gliner.modeling.multitask.triples_layers.html">gliner.modeling.multitask.triples_layers module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.base.html">gliner.modeling.base module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.decoder.html">gliner.modeling.decoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.encoder.html">gliner.modeling.encoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.layers.html">gliner.modeling.layers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.loss_functions.html">gliner.modeling.loss_functions module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.outputs.html">gliner.modeling.outputs module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.scorers.html">gliner.modeling.scorers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.span_rep.html">gliner.modeling.span_rep module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.utils.html">gliner.modeling.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.data_processing.html">gliner.data_processing package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.data_processing.collator.html">gliner.data_processing.collator module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.data_processing.processor.html">gliner.data_processing.processor module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.data_processing.tokenizer.html">gliner.data_processing.tokenizer module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.data_processing.utils.html">gliner.data_processing.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.evaluation.html">gliner.evaluation package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.evaluation.evaluate_ner.html">gliner.evaluation.evaluate_ner module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.evaluation.evaluator.html">gliner.evaluation.evaluator module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.evaluation.utils.html">gliner.evaluation.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.onnx.html">gliner.onnx package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.onnx.model.html">gliner.onnx.model module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.decoding.html">gliner.decoding package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.decoding.trie.html">gliner.decoding.trie package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gliner.decoding.trie.labels_trie.html">gliner.decoding.trie.labels_trie module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gliner.decoding.trie.python_labels_trie.html">gliner.decoding.trie.python_labels_trie module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.decoding.decoder.html">gliner.decoding.decoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.decoding.utils.html">gliner.decoding.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.utils.html">gliner.utils module</a></li>
</ul>

        </div>
      </div>
    </div>
  </aside>
  <div class="lside-overlay js-menu" role="button" aria-label="Close left sidebar" aria-controls="lside" aria-expanded="false"></div>
  <aside id="rside" class="sy-rside pb-3 w-64 shrink-0 order-last">
    <button class="rside-close js-menu xl:hidden" aria-label="Close Table of Contents" type="button" aria-controls="rside" aria-expanded="false">
      <i class="i-lucide close"></i>
    </button>
    <div class="sy-scrollbar sy-rside-inner px-6 xl:top-16 xl:sticky xl:pl-0 pt-6 pb-4"><div id="ethical-ad-placement" data-ea-publisher="readthedocs"></div></div>
  </aside>
  <div class="rside-overlay js-menu" role="button" aria-label="Close Table of Contents" aria-controls="rside" aria-expanded="false"></div>
  <main class="sy-main w-full max-sm:max-w-full print:pt-6">
<div class="sy-breadcrumbs" role="navigation">
  <div class="sy-breadcrumbs-inner flex items-center">
    <div class="md:hidden mr-3">
      <button class="js-menu" aria-label="Menu" type="button" aria-controls="lside" aria-expanded="false">
        <i class="i-lucide menu"></i>
      </button>
    </div>
    <ol class="flex-1" itemscope itemtype="https://schema.org/BreadcrumbList"><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <a itemprop="item" href="../../../index.html"><span itemprop="name">Home</span></a>
        <span>/</span>
        <meta itemprop="position" content="1" />
      </li><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <a itemprop="item" href="../../index.html"><span itemprop="name">Module code</span></a>
        <span>/</span>
        <meta itemprop="position" content="2" />
      </li><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <strong itemprop="name">gliner.modeling.decoder</strong>
        <meta itemprop="position" content="3" />
      </li></ol>
    <div class="xl:hidden ml-1">
      <button class="js-menu" aria-label="Show table of contents" type="button" aria-controls="rside"
        aria-expanded="false">
        <i class="i-lucide outdent"></i>
      </button>
    </div>
  </div>
</div><div class="flex flex-col break-words justify-between">
      <div class="min-w-0 max-w-6xl px-6 pb-6 pt-8 xl:px-12">
        <article class="yue" role="main">
          <h1>Source code for gliner.modeling.decoder</h1><div class="highlight"><pre>
<span></span><span data-line="1"><span class="sd">&quot;&quot;&quot;Decoder modules for autoregressive text generation with optional constraints.</span>
</span><span data-line="2">
</span><span data-line="3"><span class="sd">This module provides decoder architectures built on causal language models, supporting</span>
</span><span data-line="4"><span class="sd">both standard generation and prefix-constrained decoding using trie structures. It</span>
</span><span data-line="5"><span class="sd">includes custom generation implementations and numerical stability improvements.</span>
</span><span data-line="6"><span class="sd">&quot;&quot;&quot;</span>
</span><span data-line="7">
</span><span data-line="8"><span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
</span><span data-line="9"><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Optional</span>
</span><span data-line="10"><span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
</span><span data-line="11">
</span><span data-line="12"><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span data-line="13"><span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
</span><span data-line="14"><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoConfig</span><span class="p">,</span> <span class="n">LogitsProcessor</span><span class="p">,</span> <span class="n">LogitsProcessorList</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span>
</span><span data-line="15">
</span><span data-line="16"><span class="kn">from</span><span class="w"> </span><span class="nn">..utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">is_module_available</span>
</span><span data-line="17"><span class="kn">from</span><span class="w"> </span><span class="nn">..decoding.trie</span><span class="w"> </span><span class="kn">import</span> <span class="n">LabelsTrie</span>
</span><span data-line="18">
</span><span data-line="19"><span class="c1"># Check for optional dependencies</span>
</span><span data-line="20"><span class="n">IS_PEFT</span> <span class="o">=</span> <span class="n">is_module_available</span><span class="p">(</span><span class="s2">&quot;peft&quot;</span><span class="p">)</span>
</span><span data-line="21">
</span><span data-line="22"><span class="k">if</span> <span class="n">IS_PEFT</span><span class="p">:</span>
</span><span data-line="23">    <span class="kn">from</span><span class="w"> </span><span class="nn">peft</span><span class="w"> </span><span class="kn">import</span> <span class="n">LoraConfig</span><span class="p">,</span> <span class="n">get_peft_model</span>
</span><span data-line="24">
</span><span data-line="25">
<div class="viewcode-block" id="NumericalStabilityProcessor">
<a class="viewcode-back" href="../../../api/gliner.modeling.decoder.html#gliner.modeling.decoder.NumericalStabilityProcessor">[docs]</a>
</span><span data-line="26"><span class="k">class</span><span class="w"> </span><span class="nc">NumericalStabilityProcessor</span><span class="p">(</span><span class="n">LogitsProcessor</span><span class="p">):</span>
</span><span data-line="27"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Logits processor that ensures numerical stability during generation.</span>
</span><span data-line="28">
</span><span data-line="29"><span class="sd">    This processor handles edge cases in logit values by replacing negative infinity</span>
</span><span data-line="30"><span class="sd">    values with the minimum representable value for the dtype, clamping extreme values,</span>
</span><span data-line="31"><span class="sd">    and adding a small epsilon for stability.</span>
</span><span data-line="32">
</span><span data-line="33"><span class="sd">    Attributes:</span>
</span><span data-line="34"><span class="sd">        epsilon: Small constant added to logits for numerical stability.</span>
</span><span data-line="35"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="36">
<div class="viewcode-block" id="NumericalStabilityProcessor.__init__">
<a class="viewcode-back" href="../../../api/gliner.modeling.decoder.html#gliner.modeling.decoder.NumericalStabilityProcessor.__init__">[docs]</a>
</span><span data-line="37">    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="38"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initializes the numerical stability processor.</span>
</span><span data-line="39">
</span><span data-line="40"><span class="sd">        Args:</span>
</span><span data-line="41"><span class="sd">            epsilon: Small constant to add to logits. Defaults to 1e-6.</span>
</span><span data-line="42"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="43">        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span></div>

</span><span data-line="44">
</span><span data-line="45">    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">,</span> <span class="n">scores</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">:</span>
</span><span data-line="46"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Processes logits to ensure numerical stability.</span>
</span><span data-line="47">
</span><span data-line="48"><span class="sd">        Replaces negative infinity values, clamps extreme values to prevent</span>
</span><span data-line="49"><span class="sd">        overflow/underflow, and adds epsilon for stability.</span>
</span><span data-line="50">
</span><span data-line="51"><span class="sd">        Args:</span>
</span><span data-line="52"><span class="sd">            input_ids: Previously generated token IDs of shape (batch_size, seq_len).</span>
</span><span data-line="53"><span class="sd">            scores: Raw logit scores of shape (batch_size, vocab_size).</span>
</span><span data-line="54">
</span><span data-line="55"><span class="sd">        Returns:</span>
</span><span data-line="56"><span class="sd">            Stabilized logit scores of shape (batch_size, vocab_size).</span>
</span><span data-line="57"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="58">        <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
</span><span data-line="59">            <span class="n">torch</span><span class="o">.</span><span class="n">isneginf</span><span class="p">(</span><span class="n">scores</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">min</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">scores</span>
</span><span data-line="60">        <span class="p">)</span>
</span><span data-line="61">        <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mf">1e9</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">1e9</span><span class="p">)</span>
</span><span data-line="62">        <span class="k">return</span> <span class="n">scores</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span></div>

</span><span data-line="63">
</span><span data-line="64">
<div class="viewcode-block" id="DecoderTransformer">
<a class="viewcode-back" href="../../../api/gliner.modeling.decoder.html#gliner.modeling.decoder.DecoderTransformer">[docs]</a>
</span><span data-line="65"><span class="k">class</span><span class="w"> </span><span class="nc">DecoderTransformer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span data-line="66"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Wrapper for causal language model decoders with adapter support.</span>
</span><span data-line="67">
</span><span data-line="68"><span class="sd">    This class provides a unified interface for autoregressive decoder models,</span>
</span><span data-line="69"><span class="sd">    supporting loading from pretrained weights or initialization from config.</span>
</span><span data-line="70"><span class="sd">    It also handles PEFT/LoRA adapter loading when available.</span>
</span><span data-line="71">
</span><span data-line="72"><span class="sd">    Attributes:</span>
</span><span data-line="73"><span class="sd">        model: The underlying causal language model instance.</span>
</span><span data-line="74"><span class="sd">        config: Configuration object containing model hyperparameters.</span>
</span><span data-line="75"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="76">
<div class="viewcode-block" id="DecoderTransformer.__init__">
<a class="viewcode-back" href="../../../api/gliner.modeling.decoder.html#gliner.modeling.decoder.DecoderTransformer.__init__">[docs]</a>
</span><span data-line="77">    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span data-line="78">        <span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="79">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="80"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initializes the decoder transformer.</span>
</span><span data-line="81">
</span><span data-line="82"><span class="sd">        Args:</span>
</span><span data-line="83"><span class="sd">            model_name: Name or path of the pretrained model to load.</span>
</span><span data-line="84"><span class="sd">            config: Configuration object containing model hyperparameters. Must have</span>
</span><span data-line="85"><span class="sd">                a `labels_decoder_config` attribute.</span>
</span><span data-line="86"><span class="sd">            from_pretrained: If True, loads pretrained weights. If False, initializes</span>
</span><span data-line="87"><span class="sd">                from config only. Defaults to False.</span>
</span><span data-line="88"><span class="sd">            cache_dir: Optional directory for caching downloaded models. Defaults to None.</span>
</span><span data-line="89">
</span><span data-line="90"><span class="sd">        Raises:</span>
</span><span data-line="91"><span class="sd">            Warning: If adapter config is found but PEFT package is not installed.</span>
</span><span data-line="92"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="93">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span data-line="94">        <span class="n">decoder_config</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">labels_decoder_config</span>
</span><span data-line="95">        <span class="k">if</span> <span class="n">decoder_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="96">            <span class="n">decoder_config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">cache_dir</span><span class="o">=</span><span class="n">cache_dir</span><span class="p">)</span>
</span><span data-line="97">
</span><span data-line="98">        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
</span><span data-line="99">        <span class="n">custom</span> <span class="o">=</span> <span class="kc">False</span>
</span><span data-line="100">        <span class="n">ModelClass</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span>
</span><span data-line="101">
</span><span data-line="102">        <span class="k">if</span> <span class="n">from_pretrained</span><span class="p">:</span>
</span><span data-line="103">            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelClass</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span data-line="104">        <span class="k">elif</span> <span class="ow">not</span> <span class="n">custom</span><span class="p">:</span>
</span><span data-line="105">            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelClass</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">decoder_config</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span data-line="106">        <span class="k">else</span><span class="p">:</span>
</span><span data-line="107">            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelClass</span><span class="p">(</span><span class="n">decoder_config</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span data-line="108">
</span><span data-line="109">        <span class="n">adapter_config_file</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;adapter_config.json&quot;</span>
</span><span data-line="110">
</span><span data-line="111">        <span class="k">if</span> <span class="n">adapter_config_file</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
</span><span data-line="112">            <span class="k">if</span> <span class="ow">not</span> <span class="n">IS_PEFT</span><span class="p">:</span>
</span><span data-line="113">                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
</span><span data-line="114">                    <span class="s2">&quot;Adapter configs were detected, if you want to apply them you need to install peft package.&quot;</span><span class="p">,</span>
</span><span data-line="115">                    <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span data-line="116">                <span class="p">)</span>
</span><span data-line="117">            <span class="k">else</span><span class="p">:</span>
</span><span data-line="118">                <span class="n">adapter_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
</span><span data-line="119">                <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">adapter_config</span><span class="p">)</span>
</span><span data-line="120">
</span><span data-line="121">        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span></div>

</span><span data-line="122">
<div class="viewcode-block" id="DecoderTransformer.forward">
<a class="viewcode-back" href="../../../api/gliner.modeling.decoder.html#gliner.modeling.decoder.DecoderTransformer.forward">[docs]</a>
</span><span data-line="123">    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span data-line="124"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward pass through the decoder model.</span>
</span><span data-line="125">
</span><span data-line="126"><span class="sd">        Args:</span>
</span><span data-line="127"><span class="sd">            *args: Variable positional arguments passed to the model.</span>
</span><span data-line="128"><span class="sd">            **kwargs: Variable keyword arguments passed to the model.</span>
</span><span data-line="129">
</span><span data-line="130"><span class="sd">        Returns:</span>
</span><span data-line="131"><span class="sd">            Logits tensor of shape (batch_size, seq_len, vocab_size).</span>
</span><span data-line="132"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="133">        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span data-line="134">        <span class="n">encoder_layer</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span data-line="135">        <span class="k">return</span> <span class="n">encoder_layer</span></div>
</div>

</span><span data-line="136">
</span><span data-line="137">
<div class="viewcode-block" id="Decoder">
<a class="viewcode-back" href="../../../api/gliner.modeling.decoder.html#gliner.modeling.decoder.Decoder">[docs]</a>
</span><span data-line="138"><span class="k">class</span><span class="w"> </span><span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span data-line="139"><span class="w">    </span><span class="sd">&quot;&quot;&quot;High-level decoder interface for autoregressive generation.</span>
</span><span data-line="140">
</span><span data-line="141"><span class="sd">    This class provides a unified interface for text generation from embeddings,</span>
</span><span data-line="142"><span class="sd">    supporting both standard generation and constrained decoding using trie structures.</span>
</span><span data-line="143"><span class="sd">    It includes custom generation implementations and integrates with Hugging Face&#39;s</span>
</span><span data-line="144"><span class="sd">    generation API.</span>
</span><span data-line="145">
</span><span data-line="146"><span class="sd">    Attributes:</span>
</span><span data-line="147"><span class="sd">        decoder_layer: The underlying DecoderTransformer instance.</span>
</span><span data-line="148"><span class="sd">        decoder_hidden_size: Hidden dimension size of the decoder model.</span>
</span><span data-line="149"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="150">
<div class="viewcode-block" id="Decoder.__init__">
<a class="viewcode-back" href="../../../api/gliner.modeling.decoder.html#gliner.modeling.decoder.Decoder.__init__">[docs]</a>
</span><span data-line="151">    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span data-line="152">        <span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="153">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="154"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initializes the decoder.</span>
</span><span data-line="155">
</span><span data-line="156"><span class="sd">        Args:</span>
</span><span data-line="157"><span class="sd">            config: Configuration object containing model hyperparameters including</span>
</span><span data-line="158"><span class="sd">                `labels_decoder` (model name) and decoder-specific settings.</span>
</span><span data-line="159"><span class="sd">            from_pretrained: If True, loads pretrained weights for the decoder.</span>
</span><span data-line="160"><span class="sd">                Defaults to False.</span>
</span><span data-line="161"><span class="sd">            cache_dir: Optional directory for caching downloaded models. Defaults to None.</span>
</span><span data-line="162"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="163">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span data-line="164">
</span><span data-line="165">        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_layer</span> <span class="o">=</span> <span class="n">DecoderTransformer</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">labels_decoder</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">from_pretrained</span><span class="p">,</span> <span class="n">cache_dir</span><span class="o">=</span><span class="n">cache_dir</span><span class="p">)</span>
</span><span data-line="166">
</span><span data-line="167">        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_hidden_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_layer</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span></div>

</span><span data-line="168">
<div class="viewcode-block" id="Decoder.ids_to_embeds">
<a class="viewcode-back" href="../../../api/gliner.modeling.decoder.html#gliner.modeling.decoder.Decoder.ids_to_embeds">[docs]</a>
</span><span data-line="169">    <span class="k">def</span><span class="w"> </span><span class="nf">ids_to_embeds</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">:</span>
</span><span data-line="170"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Converts token IDs to their corresponding embeddings.</span>
</span><span data-line="171">
</span><span data-line="172"><span class="sd">        Args:</span>
</span><span data-line="173"><span class="sd">            input_ids: Token IDs of shape (batch_size, seq_len).</span>
</span><span data-line="174">
</span><span data-line="175"><span class="sd">        Returns:</span>
</span><span data-line="176"><span class="sd">            Token embeddings of shape (batch_size, seq_len, hidden_size).</span>
</span><span data-line="177"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="178">        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder_layer</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span data-line="179">        <span class="n">embedding_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_layer</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">()</span>
</span><span data-line="180">        <span class="k">return</span> <span class="n">embedding_layer</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span></div>

</span><span data-line="181">
<div class="viewcode-block" id="Decoder.generate_from_embeds_custom">
<a class="viewcode-back" href="../../../api/gliner.modeling.decoder.html#gliner.modeling.decoder.Decoder.generate_from_embeds_custom">[docs]</a>
</span><span data-line="182">    <span class="nd">@torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">()</span>
</span><span data-line="183">    <span class="k">def</span><span class="w"> </span><span class="nf">generate_from_embeds_custom</span><span class="p">(</span>
</span><span data-line="184">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="185">        <span class="n">inputs_embeds</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="186">        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="187">        <span class="n">max_new_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
</span><span data-line="188">        <span class="n">eos_token_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="189">        <span class="n">pad_token_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="190">        <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span data-line="191">        <span class="n">do_sample</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span data-line="192">        <span class="n">labels_trie</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LabelsTrie</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="193">        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span data-line="194">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">:</span>
</span><span data-line="195"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Custom generation implementation from embeddings with optional trie constraints.</span>
</span><span data-line="196">
</span><span data-line="197"><span class="sd">        This method implements token-by-token generation with KV caching and support for</span>
</span><span data-line="198"><span class="sd">        trie-based constrained decoding. Unlike the standard generate method, this</span>
</span><span data-line="199"><span class="sd">        implementation provides more control over the generation process and handles</span>
</span><span data-line="200"><span class="sd">        trie constraints at each step.</span>
</span><span data-line="201">
</span><span data-line="202"><span class="sd">        Args:</span>
</span><span data-line="203"><span class="sd">            inputs_embeds: Input embeddings of shape (batch_size, prefix_len, hidden_size)</span>
</span><span data-line="204"><span class="sd">                serving as the generation prefix.</span>
</span><span data-line="205"><span class="sd">            attention_mask: Optional attention mask of shape (batch_size, prefix_len).</span>
</span><span data-line="206"><span class="sd">                If None, assumes all prefix tokens are valid. Defaults to None.</span>
</span><span data-line="207"><span class="sd">            max_new_tokens: Maximum number of new tokens to generate. Defaults to 32.</span>
</span><span data-line="208"><span class="sd">            eos_token_id: Token ID marking end of sequence. If None, uses model&#39;s</span>
</span><span data-line="209"><span class="sd">                default. Defaults to None.</span>
</span><span data-line="210"><span class="sd">            pad_token_id: Token ID for padding. If None, uses model&#39;s default or</span>
</span><span data-line="211"><span class="sd">                eos_token_id. Defaults to None.</span>
</span><span data-line="212"><span class="sd">            temperature: Sampling temperature for controlling randomness. Values &lt; 1</span>
</span><span data-line="213"><span class="sd">                make distribution sharper, &gt; 1 make it more uniform. Defaults to 1.0.</span>
</span><span data-line="214"><span class="sd">            do_sample: If True, uses multinomial sampling. If False, uses greedy</span>
</span><span data-line="215"><span class="sd">                decoding (argmax). Defaults to False.</span>
</span><span data-line="216"><span class="sd">            labels_trie: Optional trie structure for constrained decoding. At each</span>
</span><span data-line="217"><span class="sd">                step, only tokens that follow valid trie paths are allowed.</span>
</span><span data-line="218"><span class="sd">                Defaults to None.</span>
</span><span data-line="219"><span class="sd">            **kwargs: Additional keyword arguments (currently unused).</span>
</span><span data-line="220">
</span><span data-line="221"><span class="sd">        Returns:</span>
</span><span data-line="222"><span class="sd">            Generated token IDs of shape (batch_size, generated_len) where generated_len</span>
</span><span data-line="223"><span class="sd">            varies per sequence based on when EOS is reached. Sequences are padded to</span>
</span><span data-line="224"><span class="sd">            the same length with pad_token_id.</span>
</span><span data-line="225"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="226">        <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_layer</span><span class="o">.</span><span class="n">model</span>
</span><span data-line="227">        <span class="n">device</span><span class="p">,</span> <span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">L0</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="n">inputs_embeds</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">inputs_embeds</span><span class="o">.</span><span class="n">shape</span>
</span><span data-line="228">        <span class="n">cfg</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span>
</span><span data-line="229">
</span><span data-line="230">        <span class="n">eos_token_id</span> <span class="o">=</span> <span class="n">eos_token_id</span> <span class="ow">or</span> <span class="n">cfg</span><span class="o">.</span><span class="n">eos_token_id</span>
</span><span data-line="231">        <span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">pad_token_id</span> <span class="ow">or</span> <span class="n">cfg</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="ow">or</span> <span class="n">eos_token_id</span>
</span><span data-line="232">
</span><span data-line="233">        <span class="c1"># prefix mask</span>
</span><span data-line="234">        <span class="k">if</span> <span class="n">attention_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="235">            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">L0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span data-line="236">
</span><span data-line="237">        <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs_embeds</span><span class="o">=</span><span class="n">inputs_embeds</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">use_cache</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span data-line="238">        <span class="n">past_key_values</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">past_key_values</span>
</span><span data-line="239">        <span class="n">next_logits</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">logits</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># (B, V)</span>
</span><span data-line="240">
</span><span data-line="241">        <span class="n">unfinished</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span data-line="242">        <span class="n">generated</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">)]</span>
</span><span data-line="243">
</span><span data-line="244">        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_new_tokens</span><span class="p">):</span>
</span><span data-line="245">            <span class="k">if</span> <span class="n">labels_trie</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="246">                <span class="n">V</span> <span class="o">=</span> <span class="n">next_logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span data-line="247">                <span class="n">mask_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">B</span><span class="p">,</span> <span class="n">V</span><span class="p">),</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span data-line="248">                <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
</span><span data-line="249">                    <span class="k">if</span> <span class="n">unfinished</span><span class="p">[</span><span class="n">b</span><span class="p">]:</span>
</span><span data-line="250">                        <span class="n">current_seq</span> <span class="o">=</span> <span class="n">generated</span><span class="p">[</span><span class="n">b</span><span class="p">]</span>  <span class="c1"># Tokens generated so far</span>
</span><span data-line="251">
</span><span data-line="252">                        <span class="n">allowed_tokens</span> <span class="o">=</span> <span class="n">labels_trie</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">current_seq</span><span class="p">)</span>
</span><span data-line="253">
</span><span data-line="254">                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">allowed_tokens</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span data-line="255">                            <span class="n">allowed_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">eos_token_id</span><span class="p">]</span>
</span><span data-line="256">
</span><span data-line="257">                        <span class="n">mask_tensor</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">allowed_tokens</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span data-line="258">                    <span class="k">else</span><span class="p">:</span>
</span><span data-line="259">                        <span class="n">mask_tensor</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span data-line="260">                <span class="n">next_logits</span> <span class="o">=</span> <span class="n">next_logits</span> <span class="o">+</span> <span class="n">mask_tensor</span>
</span><span data-line="261">
</span><span data-line="262">            <span class="k">if</span> <span class="n">temperature</span> <span class="o">!=</span> <span class="mf">1.0</span><span class="p">:</span>
</span><span data-line="263">                <span class="n">next_logits</span> <span class="o">=</span> <span class="n">next_logits</span> <span class="o">/</span> <span class="n">temperature</span>
</span><span data-line="264">
</span><span data-line="265">            <span class="k">if</span> <span class="n">do_sample</span><span class="p">:</span>
</span><span data-line="266">                <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">next_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="267">                <span class="n">next_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (B, 1)</span>
</span><span data-line="268">            <span class="k">else</span><span class="p">:</span>
</span><span data-line="269">                <span class="n">next_token</span> <span class="o">=</span> <span class="n">next_logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># (B, 1)</span>
</span><span data-line="270">
</span><span data-line="271">            <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
</span><span data-line="272">                <span class="k">if</span> <span class="n">unfinished</span><span class="p">[</span><span class="n">b</span><span class="p">]:</span>
</span><span data-line="273">                    <span class="n">generated</span><span class="p">[</span><span class="n">b</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">next_token</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span><span data-line="274">
</span><span data-line="275">            <span class="n">eos_hit</span> <span class="o">=</span> <span class="n">next_token</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="o">==</span> <span class="n">eos_token_id</span>
</span><span data-line="276">            <span class="n">unfinished</span> <span class="o">=</span> <span class="n">unfinished</span> <span class="o">&amp;</span> <span class="o">~</span><span class="n">eos_hit</span>
</span><span data-line="277">            <span class="k">if</span> <span class="ow">not</span> <span class="n">unfinished</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
</span><span data-line="278">                <span class="k">break</span>
</span><span data-line="279">
</span><span data-line="280">            <span class="n">next_token</span> <span class="o">=</span> <span class="n">next_token</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="o">~</span><span class="n">unfinished</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">pad_token_id</span><span class="p">)</span>
</span><span data-line="281">
</span><span data-line="282">            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
</span><span data-line="283">                <span class="p">[</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)],</span>
</span><span data-line="284">                <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span data-line="285">            <span class="p">)</span>
</span><span data-line="286">
</span><span data-line="287">            <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span>
</span><span data-line="288">                <span class="n">input_ids</span><span class="o">=</span><span class="n">next_token</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">past_key_values</span><span class="o">=</span><span class="n">past_key_values</span><span class="p">,</span> <span class="n">use_cache</span><span class="o">=</span><span class="kc">True</span>
</span><span data-line="289">            <span class="p">)</span>
</span><span data-line="290">            <span class="n">past_key_values</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">past_key_values</span>
</span><span data-line="291">            <span class="n">next_logits</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">logits</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span data-line="292">
</span><span data-line="293">        <span class="n">max_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">seq</span><span class="p">)</span> <span class="k">for</span> <span class="n">seq</span> <span class="ow">in</span> <span class="n">generated</span><span class="p">)</span>
</span><span data-line="294">        <span class="n">out_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">B</span><span class="p">,</span> <span class="n">max_len</span><span class="p">),</span> <span class="n">pad_token_id</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span data-line="295">        <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">seq</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">generated</span><span class="p">):</span>
</span><span data-line="296">            <span class="k">if</span> <span class="n">seq</span><span class="p">:</span>
</span><span data-line="297">                <span class="n">out_ids</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">seq</span><span class="p">)]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">seq</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span data-line="298">
</span><span data-line="299">        <span class="k">return</span> <span class="n">out_ids</span></div>

</span><span data-line="300">
<div class="viewcode-block" id="Decoder.generate_from_embeds">
<a class="viewcode-back" href="../../../api/gliner.modeling.decoder.html#gliner.modeling.decoder.Decoder.generate_from_embeds">[docs]</a>
</span><span data-line="301">    <span class="nd">@torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">()</span>
</span><span data-line="302">    <span class="k">def</span><span class="w"> </span><span class="nf">generate_from_embeds</span><span class="p">(</span>
</span><span data-line="303">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="304">        <span class="n">inputs_embeds</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="305">        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="306">        <span class="n">max_new_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
</span><span data-line="307">        <span class="n">eos_token_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="308">        <span class="n">pad_token_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="309">        <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
</span><span data-line="310">        <span class="n">do_sample</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span data-line="311">        <span class="n">num_return_sequences</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span><span data-line="312">        <span class="n">labels_trie</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LabelsTrie</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="313">        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
</span><span data-line="314">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">:</span>
</span><span data-line="315"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Generation from embeddings using Hugging Face&#39;s generate API.</span>
</span><span data-line="316">
</span><span data-line="317"><span class="sd">        This method wraps the Hugging Face generate() function to support generation</span>
</span><span data-line="318"><span class="sd">        from embeddings with optional trie-based prefix constraints. It provides a</span>
</span><span data-line="319"><span class="sd">        more feature-complete interface than generate_from_embeds_custom but may be</span>
</span><span data-line="320"><span class="sd">        less flexible for custom generation logic.</span>
</span><span data-line="321">
</span><span data-line="322"><span class="sd">        Args:</span>
</span><span data-line="323"><span class="sd">            inputs_embeds: Input embeddings of shape (batch_size, prefix_len, hidden_size)</span>
</span><span data-line="324"><span class="sd">                serving as the generation prefix.</span>
</span><span data-line="325"><span class="sd">            attention_mask: Optional attention mask of shape (batch_size, prefix_len).</span>
</span><span data-line="326"><span class="sd">                If None, creates a mask of all ones. Defaults to None.</span>
</span><span data-line="327"><span class="sd">            max_new_tokens: Maximum number of new tokens to generate. Defaults to 32.</span>
</span><span data-line="328"><span class="sd">            eos_token_id: Token ID marking end of sequence. If None, uses model&#39;s</span>
</span><span data-line="329"><span class="sd">                default. Defaults to None.</span>
</span><span data-line="330"><span class="sd">            pad_token_id: Token ID for padding. If None, uses model&#39;s default or</span>
</span><span data-line="331"><span class="sd">                eos_token_id. Defaults to None.</span>
</span><span data-line="332"><span class="sd">            temperature: Sampling temperature for controlling randomness. Defaults to 1.0.</span>
</span><span data-line="333"><span class="sd">            do_sample: If True, uses sampling. If False, uses greedy/beam search.</span>
</span><span data-line="334"><span class="sd">                Defaults to False.</span>
</span><span data-line="335"><span class="sd">            num_return_sequences: Number of sequences to generate per input. Also</span>
</span><span data-line="336"><span class="sd">                sets num_beams when &gt; 1. Defaults to 1.</span>
</span><span data-line="337"><span class="sd">            labels_trie: Optional trie structure for constrained decoding via</span>
</span><span data-line="338"><span class="sd">                prefix_allowed_tokens_fn. Defaults to None.</span>
</span><span data-line="339"><span class="sd">            **kwargs: Additional keyword arguments passed to model.generate().</span>
</span><span data-line="340">
</span><span data-line="341"><span class="sd">        Returns:</span>
</span><span data-line="342"><span class="sd">            Generated token IDs of shape (batch_size * num_return_sequences, total_len)</span>
</span><span data-line="343"><span class="sd">            where total_len = prefix_len + generated_len. Includes both the input</span>
</span><span data-line="344"><span class="sd">            prefix and newly generated tokens.</span>
</span><span data-line="345"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="346">        <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_layer</span><span class="o">.</span><span class="n">model</span>
</span><span data-line="347">        <span class="n">inputs_embeds</span> <span class="o">=</span> <span class="n">inputs_embeds</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span data-line="348">        <span class="k">if</span> <span class="n">attention_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="349">            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span><span data-line="350">        <span class="n">device</span><span class="p">,</span> <span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">L0</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="n">inputs_embeds</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">inputs_embeds</span><span class="o">.</span><span class="n">shape</span>
</span><span data-line="351">        <span class="n">cfg</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span>
</span><span data-line="352">
</span><span data-line="353">        <span class="c1"># Set token IDs if not provided</span>
</span><span data-line="354">        <span class="n">eos_token_id</span> <span class="o">=</span> <span class="n">eos_token_id</span> <span class="ow">or</span> <span class="n">cfg</span><span class="o">.</span><span class="n">eos_token_id</span>
</span><span data-line="355">        <span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">pad_token_id</span> <span class="ow">or</span> <span class="n">cfg</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="ow">or</span> <span class="n">eos_token_id</span>
</span><span data-line="356">
</span><span data-line="357">        <span class="c1"># Create attention mask if not provided</span>
</span><span data-line="358">        <span class="k">if</span> <span class="n">attention_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="359">            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">L0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span data-line="360">
</span><span data-line="361">        <span class="c1"># Define prefix-constrained token function if trie is provided</span>
</span><span data-line="362">        <span class="k">if</span> <span class="n">labels_trie</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="363">
</span><span data-line="364">            <span class="k">def</span><span class="w"> </span><span class="nf">prefix_allowed_tokens</span><span class="p">(</span><span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
</span><span data-line="365"><span class="w">                </span><span class="sd">&quot;&quot;&quot;Callback function for constrained decoding.</span>
</span><span data-line="366">
</span><span data-line="367"><span class="sd">                Args:</span>
</span><span data-line="368"><span class="sd">                    batch_idx: Index of the sequence in the batch.</span>
</span><span data-line="369"><span class="sd">                    input_ids: Currently generated token IDs.</span>
</span><span data-line="370">
</span><span data-line="371"><span class="sd">                Returns:</span>
</span><span data-line="372"><span class="sd">                    List of allowed token IDs for the next position.</span>
</span><span data-line="373"><span class="sd">                &quot;&quot;&quot;</span>
</span><span data-line="374">                <span class="n">current_seq</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</span><span data-line="375">                <span class="n">allowed_tokens</span> <span class="o">=</span> <span class="n">labels_trie</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">current_seq</span><span class="p">)</span>
</span><span data-line="376">                <span class="k">if</span> <span class="ow">not</span> <span class="n">allowed_tokens</span><span class="p">:</span>  <span class="c1"># Empty or None</span>
</span><span data-line="377">                    <span class="n">allowed_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">eos_token_id</span><span class="p">]</span>
</span><span data-line="378">                <span class="k">return</span> <span class="n">allowed_tokens</span>
</span><span data-line="379">        <span class="k">else</span><span class="p">:</span>
</span><span data-line="380">            <span class="n">prefix_allowed_tokens</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="381">
</span><span data-line="382">        <span class="c1"># Generate new tokens using transformer&#39;s generate method</span>
</span><span data-line="383">        <span class="n">generated_ids</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
</span><span data-line="384">            <span class="n">inputs_embeds</span><span class="o">=</span><span class="n">inputs_embeds</span><span class="p">,</span>
</span><span data-line="385">            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
</span><span data-line="386">            <span class="n">past_key_values</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span><span data-line="387">            <span class="n">max_new_tokens</span><span class="o">=</span><span class="n">max_new_tokens</span><span class="p">,</span>
</span><span data-line="388">            <span class="n">eos_token_id</span><span class="o">=</span><span class="n">eos_token_id</span><span class="p">,</span>
</span><span data-line="389">            <span class="n">pad_token_id</span><span class="o">=</span><span class="n">pad_token_id</span><span class="p">,</span>
</span><span data-line="390">            <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span>
</span><span data-line="391">            <span class="n">do_sample</span><span class="o">=</span><span class="n">do_sample</span><span class="p">,</span>
</span><span data-line="392">            <span class="n">use_cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span data-line="393">            <span class="n">num_return_sequences</span><span class="o">=</span><span class="n">num_return_sequences</span><span class="p">,</span>
</span><span data-line="394">            <span class="n">num_beams</span><span class="o">=</span><span class="n">num_return_sequences</span><span class="p">,</span>
</span><span data-line="395">            <span class="n">prefix_allowed_tokens_fn</span><span class="o">=</span><span class="n">prefix_allowed_tokens</span><span class="p">,</span>
</span><span data-line="396">            <span class="n">logits_processor</span><span class="o">=</span><span class="n">LogitsProcessorList</span><span class="p">(</span>
</span><span data-line="397">                <span class="p">[</span>
</span><span data-line="398">                    <span class="n">NumericalStabilityProcessor</span><span class="p">(),</span>
</span><span data-line="399">                <span class="p">]</span>
</span><span data-line="400">            <span class="p">),</span>
</span><span data-line="401">            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span data-line="402">        <span class="p">)</span>
</span><span data-line="403">
</span><span data-line="404">        <span class="k">return</span> <span class="n">generated_ids</span></div>

</span><span data-line="405">
<div class="viewcode-block" id="Decoder.generate">
<a class="viewcode-back" href="../../../api/gliner.modeling.decoder.html#gliner.modeling.decoder.Decoder.generate">[docs]</a>
</span><span data-line="406">    <span class="k">def</span><span class="w"> </span><span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">:</span>
</span><span data-line="407"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Flexible generation method supporting both embeddings and token IDs.</span>
</span><span data-line="408">
</span><span data-line="409"><span class="sd">        This method routes to the appropriate generation function based on whether</span>
</span><span data-line="410"><span class="sd">        inputs_embeds is provided. If inputs_embeds is in kwargs, uses</span>
</span><span data-line="411"><span class="sd">        generate_from_embeds(). Otherwise, delegates to the model&#39;s native</span>
</span><span data-line="412"><span class="sd">        generate() method.</span>
</span><span data-line="413">
</span><span data-line="414"><span class="sd">        Args:</span>
</span><span data-line="415"><span class="sd">            *args: Variable positional arguments passed to the generation method.</span>
</span><span data-line="416"><span class="sd">            **kwargs: Variable keyword arguments. If &#39;inputs_embeds&#39; is present,</span>
</span><span data-line="417"><span class="sd">                routes to generate_from_embeds(), otherwise routes to model.generate().</span>
</span><span data-line="418">
</span><span data-line="419"><span class="sd">        Returns:</span>
</span><span data-line="420"><span class="sd">            Generated token IDs. Shape depends on the specific generation method used.</span>
</span><span data-line="421"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="422">        <span class="k">if</span> <span class="s2">&quot;inputs_embeds&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
</span><span data-line="423">            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_from_embeds</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span data-line="424">        <span class="k">else</span><span class="p">:</span>
</span><span data-line="425">            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_layer</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

</span><span data-line="426">
<div class="viewcode-block" id="Decoder.forward">
<a class="viewcode-back" href="../../../api/gliner.modeling.decoder.html#gliner.modeling.decoder.Decoder.forward">[docs]</a>
</span><span data-line="427">    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span data-line="428"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward pass through the decoder.</span>
</span><span data-line="429">
</span><span data-line="430"><span class="sd">        Computes logits for the input sequence without generation.</span>
</span><span data-line="431">
</span><span data-line="432"><span class="sd">        Args:</span>
</span><span data-line="433"><span class="sd">            *args: Variable positional arguments passed to the decoder layer.</span>
</span><span data-line="434"><span class="sd">            **kwargs: Variable keyword arguments passed to the decoder layer.</span>
</span><span data-line="435">
</span><span data-line="436"><span class="sd">        Returns:</span>
</span><span data-line="437"><span class="sd">            Logits tensor of shape (batch_size, seq_len, vocab_size).</span>
</span><span data-line="438"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="439">        <span class="n">decoded_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_layer</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span data-line="440">        <span class="k">return</span> <span class="n">decoded_embeddings</span></div>
</div>

</span></pre></div>
        </article><button class="back-to-top" type="button">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
  </svg>
  <span>Back to top</span>
</button><div class="navigation flex print:hidden"></div></div>
    </div>
  </main>
</div>
<footer class="sy-foot">
  <div class="sy-foot-inner sy-container mx-auto">
    <div class="sy-foot-reserved md:flex justify-between items-center">
      <div class="sy-foot-copyright"><p>2025, GLiNER community</p>
  
  <p>
    Made with
    
    <a href="https://www.sphinx-doc.org/">Sphinx</a> and
    
    <a href="https://shibuya.lepture.com">Shibuya theme</a>.
  </p>
</div>
      <div class="sy-foot-socials"></div>
    </div>
  </div>
</footer>
      <script src="../../../_static/documentation_options.js?v=dc91f075"></script>
      <script src="../../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../../_static/shibuya.js?v=9b0e4dde"></script></body>
</html>