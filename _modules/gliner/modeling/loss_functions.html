<!DOCTYPE html>
<html lang="en" data-accent-color="violet" data-content_root="../../../">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>gliner.modeling.loss_functions - Home 0.2.24 documentation</title><link rel="index" title="Index" href="../../../genindex.html" /><link rel="search" title="Search" href="../../../search.html" /><script>
    function setColorMode(t){let e=document.documentElement;e.setAttribute("data-color-mode",t);let a=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,s=t;"auto"===t&&(s=a?"dark":"light"),"light"===s?(e.classList.remove("dark"),e.classList.add("light")):(e.classList.remove("light"),e.classList.add("dark"))}
    setColorMode(localStorage._theme||"auto");
  </script><link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=e1a1ceaf" />
    <link rel="stylesheet" type="text/css" href="../../../_static/shibuya.css?v=d140fbf8" />
    <link media="print" rel="stylesheet" type="text/css" href="../../../_static/print.css?v=20ff2c19" />
    <link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
<style>
:root {
  --sy-f-text: "Inter", var(--sy-f-sys), var(--sy-f-cjk), sans-serif;
  --sy-f-heading: "Inter", var(--sy-f-sys), var(--sy-f-cjk), sans-serif;
}
</style>
    <meta property="og:type" content="website"/><meta property="og:title" content="gliner.modeling.loss_functions"/>
<meta name="twitter:card" content="summary"/>
  </head>
<body><div class="sy-head">
  <div class="sy-head-blur"></div>
  <div class="sy-head-inner sy-container mx-auto">
    <a class="sy-head-brand" href="../../../index.html">
      
      
      <strong>Home</strong>
    </a>
    <div class="sy-head-nav" id="head-nav">
      <nav class="sy-head-links"></nav>
      <div class="sy-head-extra flex items-center print:hidden"><form class="searchbox flex items-center" action="../../../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <kbd>/</kbd>
</form><div class="sy-head-socials"></div></div>
    </div>
    <div class="sy-head-actions flex items-center shrink-0 print:hidden"><button class="js-theme theme-switch flex items-center"
data-aria-auto="Switch to light color mode"
data-aria-light="Switch to dark color mode"
data-aria-dark="Switch to auto color mode">
<i class="i-lucide theme-icon"></i>
</button><button class="md:hidden flex items-center js-menu" aria-label="Menu" type="button" aria-controls="head-nav" aria-expanded="false">
        <div class="hamburger">
          <span class="hamburger_1"></span>
          <span class="hamburger_2"></span>
          <span class="hamburger_3"></span>
        </div>
      </button>
    </div>
  </div>
</div>
<div class="sy-page sy-container flex mx-auto">
  <aside id="lside" class="sy-lside md:w-72 md:shrink-0 print:hidden">
    <div class="sy-lside-inner md:sticky">
      <div class="sy-scrollbar p-6">
        <div class="globaltoc" data-expand-depth="0"><p class="caption" role="heading" aria-level="3"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../intro.html">Introduction to ðŸ‘‘ GLiNER</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../instalation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage.html">Advanced Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../configs.html">Components &amp; Configs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../training.html">Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../architectures.html">Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../convert_to_onnx.html">ONNX Export &amp; Deployment</a></li>
</ul>
<p class="caption" role="heading" aria-level="3"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.model.html">gliner.model module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.config.html">gliner.config module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.training.html">gliner.training package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.training.trainer.html">gliner.training.trainer module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.modeling.html">gliner.modeling package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.multitask.html">gliner.modeling.multitask package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gliner.modeling.multitask.relations_layers.html">gliner.modeling.multitask.relations_layers module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gliner.modeling.multitask.triples_layers.html">gliner.modeling.multitask.triples_layers module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.base.html">gliner.modeling.base module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.decoder.html">gliner.modeling.decoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.encoder.html">gliner.modeling.encoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.layers.html">gliner.modeling.layers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.loss_functions.html">gliner.modeling.loss_functions module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.outputs.html">gliner.modeling.outputs module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.scorers.html">gliner.modeling.scorers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.span_rep.html">gliner.modeling.span_rep module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.utils.html">gliner.modeling.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.data_processing.html">gliner.data_processing package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.data_processing.collator.html">gliner.data_processing.collator module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.data_processing.processor.html">gliner.data_processing.processor module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.data_processing.tokenizer.html">gliner.data_processing.tokenizer module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.data_processing.utils.html">gliner.data_processing.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.evaluation.html">gliner.evaluation package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.evaluation.evaluate_ner.html">gliner.evaluation.evaluate_ner module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.evaluation.evaluator.html">gliner.evaluation.evaluator module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.evaluation.utils.html">gliner.evaluation.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.onnx.html">gliner.onnx package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.onnx.model.html">gliner.onnx.model module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.decoding.html">gliner.decoding package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.decoding.trie.html">gliner.decoding.trie package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gliner.decoding.trie.labels_trie.html">gliner.decoding.trie.labels_trie module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gliner.decoding.trie.python_labels_trie.html">gliner.decoding.trie.python_labels_trie module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.decoding.decoder.html">gliner.decoding.decoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.decoding.utils.html">gliner.decoding.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.utils.html">gliner.utils module</a></li>
</ul>

        </div>
      </div>
    </div>
  </aside>
  <div class="lside-overlay js-menu" role="button" aria-label="Close left sidebar" aria-controls="lside" aria-expanded="false"></div>
  <aside id="rside" class="sy-rside pb-3 w-64 shrink-0 order-last">
    <button class="rside-close js-menu xl:hidden" aria-label="Close Table of Contents" type="button" aria-controls="rside" aria-expanded="false">
      <i class="i-lucide close"></i>
    </button>
    <div class="sy-scrollbar sy-rside-inner px-6 xl:top-16 xl:sticky xl:pl-0 pt-6 pb-4"><div id="ethical-ad-placement" data-ea-publisher="readthedocs"></div></div>
  </aside>
  <div class="rside-overlay js-menu" role="button" aria-label="Close Table of Contents" aria-controls="rside" aria-expanded="false"></div>
  <main class="sy-main w-full max-sm:max-w-full print:pt-6">
<div class="sy-breadcrumbs" role="navigation">
  <div class="sy-breadcrumbs-inner flex items-center">
    <div class="md:hidden mr-3">
      <button class="js-menu" aria-label="Menu" type="button" aria-controls="lside" aria-expanded="false">
        <i class="i-lucide menu"></i>
      </button>
    </div>
    <ol class="flex-1" itemscope itemtype="https://schema.org/BreadcrumbList"><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <a itemprop="item" href="../../../index.html"><span itemprop="name">Home</span></a>
        <span>/</span>
        <meta itemprop="position" content="1" />
      </li><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <a itemprop="item" href="../../index.html"><span itemprop="name">Module code</span></a>
        <span>/</span>
        <meta itemprop="position" content="2" />
      </li><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <strong itemprop="name">gliner.modeling.loss_functions</strong>
        <meta itemprop="position" content="3" />
      </li></ol>
    <div class="xl:hidden ml-1">
      <button class="js-menu" aria-label="Show table of contents" type="button" aria-controls="rside"
        aria-expanded="false">
        <i class="i-lucide outdent"></i>
      </button>
    </div>
  </div>
</div><div class="flex flex-col break-words justify-between">
      <div class="min-w-0 max-w-6xl px-6 pb-6 pt-8 xl:px-12">
        <article class="yue" role="main">
          <h1>Source code for gliner.modeling.loss_functions</h1><div class="highlight"><pre>
<span></span><span data-line="1"><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span data-line="2"><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
</span><span data-line="3">
</span><span data-line="4">
<div class="viewcode-block" id="focal_loss_with_logits">
<a class="viewcode-back" href="../../../api/gliner.modeling.loss_functions.html#gliner.modeling.loss_functions.focal_loss_with_logits">[docs]</a>
</span><span data-line="5"><span class="k">def</span><span class="w"> </span><span class="nf">focal_loss_with_logits</span><span class="p">(</span>
</span><span data-line="6">    <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="7">    <span class="n">targets</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="8">    <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">,</span>
</span><span data-line="9">    <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
</span><span data-line="10">    <span class="n">prob_margin</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="11">    <span class="n">reduction</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;none&quot;</span><span class="p">,</span>
</span><span data-line="12">    <span class="n">label_smoothing</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="13">    <span class="n">normalize_prob</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span data-line="14">    <span class="n">ignore_index</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span><span class="p">,</span>
</span><span data-line="15">    <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span><span class="p">,</span>
</span><span data-line="16"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span data-line="17"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute focal loss for binary classification with logits.</span>
</span><span data-line="18">
</span><span data-line="19"><span class="sd">    Focal loss is designed to address class imbalance by down-weighting</span>
</span><span data-line="20"><span class="sd">    easy examples and focusing on hard examples. Originally proposed in</span>
</span><span data-line="21"><span class="sd">    RetinaNet (https://arxiv.org/abs/1708.02002) for dense object detection.</span>
</span><span data-line="22">
</span><span data-line="23"><span class="sd">    The focal loss is defined as:</span>
</span><span data-line="24"><span class="sd">        FL(p_t) = -Î±_t * (1 - p_t)^Î³ * log(p_t)</span>
</span><span data-line="25">
</span><span data-line="26"><span class="sd">    where p_t is the model&#39;s estimated probability for the correct class.</span>
</span><span data-line="27">
</span><span data-line="28"><span class="sd">    Args:</span>
</span><span data-line="29"><span class="sd">        inputs (torch.Tensor): Predicted logits of arbitrary shape.</span>
</span><span data-line="30"><span class="sd">            The predictions for each example (not probabilities).</span>
</span><span data-line="31"><span class="sd">        targets (torch.Tensor): Ground truth binary labels with the same</span>
</span><span data-line="32"><span class="sd">            shape as inputs. Should contain 0 for negative class and 1</span>
</span><span data-line="33"><span class="sd">            for positive class.</span>
</span><span data-line="34"><span class="sd">        alpha (float, optional): Weighting factor in range (0, 1) to balance</span>
</span><span data-line="35"><span class="sd">            positive vs negative examples. Set to -1 to disable. The weight</span>
</span><span data-line="36"><span class="sd">            for positive examples is alpha, and for negative examples is</span>
</span><span data-line="37"><span class="sd">            (1 - alpha). Defaults to 0.25.</span>
</span><span data-line="38"><span class="sd">        gamma (float, optional): Exponent of the modulating factor (1 - p_t)</span>
</span><span data-line="39"><span class="sd">            to balance easy vs hard examples. Higher values give more weight</span>
</span><span data-line="40"><span class="sd">            to hard examples. Set to 0 to disable focal modulation.</span>
</span><span data-line="41"><span class="sd">            Defaults to 2.</span>
</span><span data-line="42"><span class="sd">        prob_margin (float, optional): Margin to subtract from predicted</span>
</span><span data-line="43"><span class="sd">            probabilities for negative examples. Can help with hard negative</span>
</span><span data-line="44"><span class="sd">            mining. Defaults to 0.</span>
</span><span data-line="45"><span class="sd">        reduction (str, optional): Specifies the reduction to apply to the</span>
</span><span data-line="46"><span class="sd">            output. Options are:</span>
</span><span data-line="47"><span class="sd">            - &#39;none&#39;: No reduction, return loss for each element</span>
</span><span data-line="48"><span class="sd">            - &#39;mean&#39;: Return the mean loss (normalized by valid elements)</span>
</span><span data-line="49"><span class="sd">            - &#39;sum&#39;: Return the sum of all losses</span>
</span><span data-line="50"><span class="sd">            Defaults to &#39;none&#39;.</span>
</span><span data-line="51"><span class="sd">        label_smoothing (float, optional): Amount of label smoothing to apply.</span>
</span><span data-line="52"><span class="sd">            Targets become: target * (1 - label_smoothing) + 0.5 * label_smoothing.</span>
</span><span data-line="53"><span class="sd">            Value should be in range [0, 1]. Defaults to 0.0 (no smoothing).</span>
</span><span data-line="54"><span class="sd">        normalize_prob (bool, optional): If True, apply sigmoid to inputs to</span>
</span><span data-line="55"><span class="sd">            get probabilities. If False, treat inputs as probabilities directly.</span>
</span><span data-line="56"><span class="sd">            Defaults to True.</span>
</span><span data-line="57"><span class="sd">        ignore_index (int, optional): Specifies a target value that is ignored</span>
</span><span data-line="58"><span class="sd">            and does not contribute to the loss gradient. Defaults to -100.</span>
</span><span data-line="59"><span class="sd">        eps (float, optional): Small epsilon value for numerical stability</span>
</span><span data-line="60"><span class="sd">            when computing logarithms. Defaults to 1e-6.</span>
</span><span data-line="61">
</span><span data-line="62"><span class="sd">    Returns:</span>
</span><span data-line="63"><span class="sd">        torch.Tensor: Loss tensor. Shape depends on reduction parameter:</span>
</span><span data-line="64"><span class="sd">            - If reduction=&#39;none&#39;: same shape as inputs</span>
</span><span data-line="65"><span class="sd">            - If reduction=&#39;mean&#39; or &#39;sum&#39;: scalar tensor</span>
</span><span data-line="66">
</span><span data-line="67"><span class="sd">    Raises:</span>
</span><span data-line="68"><span class="sd">        ValueError: If an invalid reduction mode is specified.</span>
</span><span data-line="69">
</span><span data-line="70"><span class="sd">    Example:</span>
</span><span data-line="71"><span class="sd">        &gt;&gt;&gt; inputs = torch.randn(32, 100)  # logits</span>
</span><span data-line="72"><span class="sd">        &gt;&gt;&gt; targets = torch.randint(0, 2, (32, 100)).float()</span>
</span><span data-line="73"><span class="sd">        &gt;&gt;&gt; loss = focal_loss_with_logits(inputs, targets, reduction=&quot;mean&quot;)</span>
</span><span data-line="74"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="75">    <span class="c1"># Create a mask to ignore specified index</span>
</span><span data-line="76">    <span class="n">valid_mask</span> <span class="o">=</span> <span class="n">targets</span> <span class="o">!=</span> <span class="n">ignore_index</span>
</span><span data-line="77">
</span><span data-line="78">    <span class="c1"># Apply label smoothing if needed</span>
</span><span data-line="79">    <span class="k">if</span> <span class="n">label_smoothing</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
</span><span data-line="80">        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span data-line="81">            <span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">label_smoothing</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">label_smoothing</span>
</span><span data-line="82">
</span><span data-line="83">    <span class="c1"># Apply sigmoid activation to inputs</span>
</span><span data-line="84">    <span class="k">if</span> <span class="n">normalize_prob</span><span class="p">:</span>
</span><span data-line="85">        <span class="n">p</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span data-line="86">    <span class="k">else</span><span class="p">:</span>
</span><span data-line="87">        <span class="n">p</span> <span class="o">=</span> <span class="n">inputs</span>
</span><span data-line="88">
</span><span data-line="89">    <span class="n">pm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">p</span> <span class="o">-</span> <span class="n">prob_margin</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</span><span data-line="90">
</span><span data-line="91">    <span class="c1"># Compute the binary cross-entropy loss without reduction</span>
</span><span data-line="92">    <span class="n">pos_term</span> <span class="o">=</span> <span class="o">-</span><span class="n">targets</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="n">eps</span><span class="p">))</span>
</span><span data-line="93">    <span class="n">neg_term</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">targets</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">pm</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="n">eps</span><span class="p">))</span>
</span><span data-line="94">    <span class="n">loss</span> <span class="o">=</span> <span class="n">pos_term</span> <span class="o">+</span> <span class="n">neg_term</span>
</span><span data-line="95">
</span><span data-line="96">    <span class="c1"># Apply the valid mask to the loss</span>
</span><span data-line="97">    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">*</span> <span class="n">valid_mask</span>
</span><span data-line="98">
</span><span data-line="99">    <span class="c1"># Apply focal loss modulation if gamma is greater than 0</span>
</span><span data-line="100">    <span class="k">if</span> <span class="n">gamma</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span><span data-line="101">        <span class="n">p_t</span> <span class="o">=</span> <span class="n">p</span> <span class="o">*</span> <span class="n">targets</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">pm</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">targets</span><span class="p">)</span>
</span><span data-line="102">        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">*</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p_t</span><span class="p">)</span> <span class="o">**</span> <span class="n">gamma</span><span class="p">)</span>
</span><span data-line="103">
</span><span data-line="104">    <span class="c1"># Apply alpha weighting if alpha is specified</span>
</span><span data-line="105">    <span class="k">if</span> <span class="n">alpha</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
</span><span data-line="106">        <span class="n">alpha_t</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">targets</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">targets</span><span class="p">)</span>
</span><span data-line="107">        <span class="n">loss</span> <span class="o">=</span> <span class="n">alpha_t</span> <span class="o">*</span> <span class="n">loss</span>
</span><span data-line="108">
</span><span data-line="109">    <span class="c1"># Apply reduction method</span>
</span><span data-line="110">    <span class="k">if</span> <span class="n">reduction</span> <span class="o">==</span> <span class="s2">&quot;none&quot;</span><span class="p">:</span>
</span><span data-line="111">        <span class="k">return</span> <span class="n">loss</span>
</span><span data-line="112">    <span class="k">elif</span> <span class="n">reduction</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
</span><span data-line="113">        <span class="c1"># Normalize by the number of valid (non-ignored) elements</span>
</span><span data-line="114">        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">valid_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span data-line="115">    <span class="k">elif</span> <span class="n">reduction</span> <span class="o">==</span> <span class="s2">&quot;sum&quot;</span><span class="p">:</span>
</span><span data-line="116">        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span data-line="117">    <span class="k">else</span><span class="p">:</span>
</span><span data-line="118">        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span data-line="119">            <span class="sa">f</span><span class="s2">&quot;Invalid value for argument &#39;reduction&#39;: &#39;</span><span class="si">{</span><span class="n">reduction</span><span class="si">}</span><span class="s2">&#39;. Supported reduction modes: &#39;none&#39;, &#39;mean&#39;, &#39;sum&#39;&quot;</span>
</span><span data-line="120">        <span class="p">)</span></div>

</span><span data-line="121">
</span><span data-line="122">
<div class="viewcode-block" id="cross_entropy_loss">
<a class="viewcode-back" href="../../../api/gliner.modeling.loss_functions.html#gliner.modeling.loss_functions.cross_entropy_loss">[docs]</a>
</span><span data-line="123"><span class="k">def</span><span class="w"> </span><span class="nf">cross_entropy_loss</span><span class="p">(</span>
</span><span data-line="124">    <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="125">    <span class="n">targets</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="126">    <span class="n">reduction</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sum&quot;</span><span class="p">,</span>
</span><span data-line="127">    <span class="n">label_smoothing</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="128">    <span class="n">ignore_index</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span><span class="p">,</span>
</span><span data-line="129"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span data-line="130"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute cross-entropy loss for multi-class classification.</span>
</span><span data-line="131">
</span><span data-line="132"><span class="sd">    A wrapper around PyTorch&#39;s F.cross_entropy that reshapes inputs and</span>
</span><span data-line="133"><span class="sd">    targets for convenient use in GLiNER models. This function flattens</span>
</span><span data-line="134"><span class="sd">    batch and sequence dimensions before computing the loss.</span>
</span><span data-line="135">
</span><span data-line="136"><span class="sd">    Args:</span>
</span><span data-line="137"><span class="sd">        inputs (torch.Tensor): Predicted logits of shape [..., num_classes].</span>
</span><span data-line="138"><span class="sd">            Typically shape [batch_size, seq_len, num_classes] or similar.</span>
</span><span data-line="139"><span class="sd">            Will be reshaped to [-1, num_classes] internally.</span>
</span><span data-line="140"><span class="sd">        targets (torch.Tensor): Ground truth class indices with shape [...].</span>
</span><span data-line="141"><span class="sd">            Should have one fewer dimension than inputs (no class dimension).</span>
</span><span data-line="142"><span class="sd">            Values should be in range [0, num_classes - 1] or equal to</span>
</span><span data-line="143"><span class="sd">            ignore_index. Will be reshaped to [-1] internally.</span>
</span><span data-line="144"><span class="sd">        reduction (str, optional): Specifies the reduction to apply to the</span>
</span><span data-line="145"><span class="sd">            output. Options are:</span>
</span><span data-line="146"><span class="sd">            - &#39;none&#39;: No reduction, return loss for each element</span>
</span><span data-line="147"><span class="sd">            - &#39;mean&#39;: Return the mean loss</span>
</span><span data-line="148"><span class="sd">            - &#39;sum&#39;: Return the sum of all losses</span>
</span><span data-line="149"><span class="sd">            Defaults to &#39;sum&#39;.</span>
</span><span data-line="150"><span class="sd">        label_smoothing (float, optional): Amount of label smoothing to apply.</span>
</span><span data-line="151"><span class="sd">            Value should be in range [0, 1]. Defaults to 0.0 (no smoothing).</span>
</span><span data-line="152"><span class="sd">        ignore_index (int, optional): Specifies a target value that is ignored</span>
</span><span data-line="153"><span class="sd">            and does not contribute to the loss gradient. Defaults to -100.</span>
</span><span data-line="154">
</span><span data-line="155"><span class="sd">    Returns:</span>
</span><span data-line="156"><span class="sd">        torch.Tensor: Loss tensor. Shape depends on reduction parameter:</span>
</span><span data-line="157"><span class="sd">            - If reduction=&#39;none&#39;: shape [batch_size * seq_len] (flattened)</span>
</span><span data-line="158"><span class="sd">            - If reduction=&#39;mean&#39; or &#39;sum&#39;: scalar tensor</span>
</span><span data-line="159">
</span><span data-line="160"><span class="sd">    Example:</span>
</span><span data-line="161"><span class="sd">        &gt;&gt;&gt; inputs = torch.randn(8, 50, 10)  # batch=8, seq_len=50, classes=10</span>
</span><span data-line="162"><span class="sd">        &gt;&gt;&gt; targets = torch.randint(0, 10, (8, 50))  # class indices</span>
</span><span data-line="163"><span class="sd">        &gt;&gt;&gt; loss = cross_entropy_loss(inputs, targets, reduction=&quot;mean&quot;)</span>
</span><span data-line="164"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="165">    <span class="n">cls_size</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span data-line="166">    <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">cls_size</span><span class="p">)</span>
</span><span data-line="167">    <span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span data-line="168">
</span><span data-line="169">    <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span>
</span><span data-line="170">        <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="n">ignore_index</span><span class="p">,</span> <span class="n">label_smoothing</span><span class="o">=</span><span class="n">label_smoothing</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">reduction</span>
</span><span data-line="171">    <span class="p">)</span>
</span><span data-line="172">
</span><span data-line="173">    <span class="k">return</span> <span class="n">loss</span></div>

</span></pre></div>
        </article><button class="back-to-top" type="button">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
  </svg>
  <span>Back to top</span>
</button><div class="navigation flex print:hidden"></div></div>
    </div>
  </main>
</div>
<footer class="sy-foot">
  <div class="sy-foot-inner sy-container mx-auto">
    <div class="sy-foot-reserved md:flex justify-between items-center">
      <div class="sy-foot-copyright"><p>2025, GLiNER community</p>
  
  <p>
    Made with
    
    <a href="https://www.sphinx-doc.org/">Sphinx</a> and
    
    <a href="https://shibuya.lepture.com">Shibuya theme</a>.
  </p>
</div>
      <div class="sy-foot-socials"></div>
    </div>
  </div>
</footer>
      <script src="../../../_static/documentation_options.js?v=dc91f075"></script>
      <script src="../../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../../_static/shibuya.js?v=9b0e4dde"></script></body>
</html>