<!DOCTYPE html>
<html lang="en" data-accent-color="violet" data-content_root="../../../">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>gliner.training.trainer - Home 0.2.24 documentation</title><link rel="index" title="Index" href="../../../genindex.html" /><link rel="search" title="Search" href="../../../search.html" /><script>
    function setColorMode(t){let e=document.documentElement;e.setAttribute("data-color-mode",t);let a=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,s=t;"auto"===t&&(s=a?"dark":"light"),"light"===s?(e.classList.remove("dark"),e.classList.add("light")):(e.classList.remove("light"),e.classList.add("dark"))}
    setColorMode(localStorage._theme||"auto");
  </script><link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=e1a1ceaf" />
    <link rel="stylesheet" type="text/css" href="../../../_static/shibuya.css?v=d140fbf8" />
    <link media="print" rel="stylesheet" type="text/css" href="../../../_static/print.css?v=20ff2c19" />
    <link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
<style>
:root {
  --sy-f-text: "Inter", var(--sy-f-sys), var(--sy-f-cjk), sans-serif;
  --sy-f-heading: "Inter", var(--sy-f-sys), var(--sy-f-cjk), sans-serif;
}
</style>
    <meta property="og:type" content="website"/><meta property="og:title" content="gliner.training.trainer"/>
<meta name="twitter:card" content="summary"/>
  </head>
<body><div class="sy-head">
  <div class="sy-head-blur"></div>
  <div class="sy-head-inner sy-container mx-auto">
    <a class="sy-head-brand" href="../../../index.html">
      
      
      <strong>Home</strong>
    </a>
    <div class="sy-head-nav" id="head-nav">
      <nav class="sy-head-links"></nav>
      <div class="sy-head-extra flex items-center print:hidden"><form class="searchbox flex items-center" action="../../../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <kbd>/</kbd>
</form><div class="sy-head-socials"></div></div>
    </div>
    <div class="sy-head-actions flex items-center shrink-0 print:hidden"><button class="js-theme theme-switch flex items-center"
data-aria-auto="Switch to light color mode"
data-aria-light="Switch to dark color mode"
data-aria-dark="Switch to auto color mode">
<i class="i-lucide theme-icon"></i>
</button><button class="md:hidden flex items-center js-menu" aria-label="Menu" type="button" aria-controls="head-nav" aria-expanded="false">
        <div class="hamburger">
          <span class="hamburger_1"></span>
          <span class="hamburger_2"></span>
          <span class="hamburger_3"></span>
        </div>
      </button>
    </div>
  </div>
</div>
<div class="sy-page sy-container flex mx-auto">
  <aside id="lside" class="sy-lside md:w-72 md:shrink-0 print:hidden">
    <div class="sy-lside-inner md:sticky">
      <div class="sy-scrollbar p-6">
        <div class="globaltoc" data-expand-depth="0"><p class="caption" role="heading" aria-level="3"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../intro.html">Introduction to ðŸ‘‘ GLiNER</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../instalation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage.html">Advanced Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../configs.html">Components &amp; Configs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../training.html">Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../architectures.html">Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../convert_to_onnx.html">ONNX Export &amp; Deployment</a></li>
</ul>
<p class="caption" role="heading" aria-level="3"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.model.html">gliner.model module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.config.html">gliner.config module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.training.html">gliner.training package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.training.trainer.html">gliner.training.trainer module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.modeling.html">gliner.modeling package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.multitask.html">gliner.modeling.multitask package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gliner.modeling.multitask.relations_layers.html">gliner.modeling.multitask.relations_layers module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gliner.modeling.multitask.triples_layers.html">gliner.modeling.multitask.triples_layers module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.base.html">gliner.modeling.base module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.decoder.html">gliner.modeling.decoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.encoder.html">gliner.modeling.encoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.layers.html">gliner.modeling.layers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.loss_functions.html">gliner.modeling.loss_functions module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.outputs.html">gliner.modeling.outputs module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.scorers.html">gliner.modeling.scorers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.span_rep.html">gliner.modeling.span_rep module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.utils.html">gliner.modeling.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.data_processing.html">gliner.data_processing package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.data_processing.collator.html">gliner.data_processing.collator module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.data_processing.processor.html">gliner.data_processing.processor module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.data_processing.tokenizer.html">gliner.data_processing.tokenizer module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.data_processing.utils.html">gliner.data_processing.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.evaluation.html">gliner.evaluation package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.evaluation.evaluate_ner.html">gliner.evaluation.evaluate_ner module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.evaluation.evaluator.html">gliner.evaluation.evaluator module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.evaluation.utils.html">gliner.evaluation.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.onnx.html">gliner.onnx package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.onnx.model.html">gliner.onnx.model module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.decoding.html">gliner.decoding package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.decoding.trie.html">gliner.decoding.trie package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gliner.decoding.trie.labels_trie.html">gliner.decoding.trie.labels_trie module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gliner.decoding.trie.python_labels_trie.html">gliner.decoding.trie.python_labels_trie module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.decoding.decoder.html">gliner.decoding.decoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.decoding.utils.html">gliner.decoding.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.utils.html">gliner.utils module</a></li>
</ul>

        </div>
      </div>
    </div>
  </aside>
  <div class="lside-overlay js-menu" role="button" aria-label="Close left sidebar" aria-controls="lside" aria-expanded="false"></div>
  <aside id="rside" class="sy-rside pb-3 w-64 shrink-0 order-last">
    <button class="rside-close js-menu xl:hidden" aria-label="Close Table of Contents" type="button" aria-controls="rside" aria-expanded="false">
      <i class="i-lucide close"></i>
    </button>
    <div class="sy-scrollbar sy-rside-inner px-6 xl:top-16 xl:sticky xl:pl-0 pt-6 pb-4"><div id="ethical-ad-placement" data-ea-publisher="readthedocs"></div></div>
  </aside>
  <div class="rside-overlay js-menu" role="button" aria-label="Close Table of Contents" aria-controls="rside" aria-expanded="false"></div>
  <main class="sy-main w-full max-sm:max-w-full print:pt-6">
<div class="sy-breadcrumbs" role="navigation">
  <div class="sy-breadcrumbs-inner flex items-center">
    <div class="md:hidden mr-3">
      <button class="js-menu" aria-label="Menu" type="button" aria-controls="lside" aria-expanded="false">
        <i class="i-lucide menu"></i>
      </button>
    </div>
    <ol class="flex-1" itemscope itemtype="https://schema.org/BreadcrumbList"><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <a itemprop="item" href="../../../index.html"><span itemprop="name">Home</span></a>
        <span>/</span>
        <meta itemprop="position" content="1" />
      </li><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <a itemprop="item" href="../../index.html"><span itemprop="name">Module code</span></a>
        <span>/</span>
        <meta itemprop="position" content="2" />
      </li><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <strong itemprop="name">gliner.training.trainer</strong>
        <meta itemprop="position" content="3" />
      </li></ol>
    <div class="xl:hidden ml-1">
      <button class="js-menu" aria-label="Show table of contents" type="button" aria-controls="rside"
        aria-expanded="false">
        <i class="i-lucide outdent"></i>
      </button>
    </div>
  </div>
</div><div class="flex flex-col break-words justify-between">
      <div class="min-w-0 max-w-6xl px-6 pb-6 pt-8 xl:px-12">
        <article class="yue" role="main">
          <h1>Source code for gliner.training.trainer</h1><div class="highlight"><pre>
<span></span><span data-line="1"><span class="sd">&quot;&quot;&quot;Custom Trainer implementation with enhanced loss functions and optimizer configuration.</span>
</span><span data-line="2">
</span><span data-line="3"><span class="sd">This module extends the Hugging Face Transformers Trainer class to support</span>
</span><span data-line="4"><span class="sd">custom loss functions (focal loss, label smoothing), flexible learning rates</span>
</span><span data-line="5"><span class="sd">for different parameter groups, and robust error handling during training.</span>
</span><span data-line="6"><span class="sd">&quot;&quot;&quot;</span>
</span><span data-line="7">
</span><span data-line="8"><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
</span><span data-line="9"><span class="kn">import</span><span class="w"> </span><span class="nn">inspect</span>
</span><span data-line="10"><span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
</span><span data-line="11"><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Optional</span>
</span><span data-line="12"><span class="kn">from</span><span class="w"> </span><span class="nn">dataclasses</span><span class="w"> </span><span class="kn">import</span> <span class="n">field</span><span class="p">,</span> <span class="n">dataclass</span>
</span><span data-line="13">
</span><span data-line="14"><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span data-line="15"><span class="kn">import</span><span class="w"> </span><span class="nn">transformers</span>
</span><span data-line="16"><span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
</span><span data-line="17"><span class="kn">from</span><span class="w"> </span><span class="nn">transformers.trainer</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span data-line="18">    <span class="n">get_parameter_names</span><span class="p">,</span>
</span><span data-line="19">    <span class="n">is_sagemaker_mp_enabled</span><span class="p">,</span>
</span><span data-line="20"><span class="p">)</span>
</span><span data-line="21"><span class="kn">from</span><span class="w"> </span><span class="nn">transformers.trainer_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">set_seed</span>
</span><span data-line="22">
</span><span data-line="23"><span class="k">if</span> <span class="n">is_sagemaker_mp_enabled</span><span class="p">():</span>
</span><span data-line="24">    <span class="kn">from</span><span class="w"> </span><span class="nn">transformers.trainer_pt_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">smp_forward_backward</span>
</span><span data-line="25"><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
</span><span data-line="26">
</span><span data-line="27"><span class="n">ALL_LAYERNORM_LAYERS</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">]</span>
</span><span data-line="28">
</span><span data-line="29"><span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
</span><span data-line="30">
</span><span data-line="31">
<div class="viewcode-block" id="seed_worker">
<a class="viewcode-back" href="../../../api/gliner.training.trainer.html#gliner.training.trainer.seed_worker">[docs]</a>
</span><span data-line="32"><span class="k">def</span><span class="w"> </span><span class="nf">seed_worker</span><span class="p">(</span><span class="n">_</span><span class="p">):</span>
</span><span data-line="33"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Set worker seed during DataLoader initialization.</span>
</span><span data-line="34">
</span><span data-line="35"><span class="sd">    Helper function to ensure reproducibility by seeding each DataLoader worker</span>
</span><span data-line="36"><span class="sd">    process with a unique but deterministic seed based on PyTorch&#39;s initial seed.</span>
</span><span data-line="37">
</span><span data-line="38"><span class="sd">    Args:</span>
</span><span data-line="39"><span class="sd">        _: Worker ID (unused, but required by DataLoader worker_init_fn signature).</span>
</span><span data-line="40"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="41">    <span class="n">worker_seed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">initial_seed</span><span class="p">()</span> <span class="o">%</span> <span class="mi">2</span><span class="o">**</span><span class="mi">32</span>
</span><span data-line="42">    <span class="n">set_seed</span><span class="p">(</span><span class="n">worker_seed</span><span class="p">)</span></div>

</span><span data-line="43">
</span><span data-line="44">
<div class="viewcode-block" id="TrainingArguments">
<a class="viewcode-back" href="../../../api/gliner.training.trainer.html#gliner.training.trainer.TrainingArguments">[docs]</a>
</span><span data-line="45"><span class="nd">@dataclass</span>
</span><span data-line="46"><span class="k">class</span><span class="w"> </span><span class="nc">TrainingArguments</span><span class="p">(</span><span class="n">transformers</span><span class="o">.</span><span class="n">TrainingArguments</span><span class="p">):</span>
</span><span data-line="47"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Extended training arguments with custom loss and optimization parameters.</span>
</span><span data-line="48">
</span><span data-line="49"><span class="sd">    Extends the standard Hugging Face TrainingArguments with additional parameters</span>
</span><span data-line="50"><span class="sd">    for focal loss, label smoothing, differential learning rates, and custom</span>
</span><span data-line="51"><span class="sd">    negative sampling strategies.</span>
</span><span data-line="52">
</span><span data-line="53"><span class="sd">    Attributes:</span>
</span><span data-line="54"><span class="sd">        cache_dir: Directory to cache downloaded models and datasets.</span>
</span><span data-line="55"><span class="sd">        optim: Optimizer to use. Defaults to &quot;adamw_torch&quot;.</span>
</span><span data-line="56"><span class="sd">        others_lr: Optional separate learning rate for non-encoder parameters</span>
</span><span data-line="57"><span class="sd">            (e.g., classification heads). If None, uses the main learning rate.</span>
</span><span data-line="58"><span class="sd">        others_weight_decay: Weight decay for non-encoder parameters when</span>
</span><span data-line="59"><span class="sd">            using others_lr. Defaults to 0.0.</span>
</span><span data-line="60"><span class="sd">        focal_loss_alpha: Alpha parameter for focal loss. Values &lt; 0 disable</span>
</span><span data-line="61"><span class="sd">            focal loss weighting. Defaults to -1.</span>
</span><span data-line="62"><span class="sd">        focal_loss_gamma: Gamma (focusing parameter) for focal loss. Higher values</span>
</span><span data-line="63"><span class="sd">            increase focus on hard examples. Defaults to 0.</span>
</span><span data-line="64"><span class="sd">        focal_loss_prob_margin: Probability margin for focal loss computation.</span>
</span><span data-line="65"><span class="sd">            Defaults to 0.</span>
</span><span data-line="66"><span class="sd">        label_smoothing: Label smoothing factor. 0.0 means no smoothing.</span>
</span><span data-line="67"><span class="sd">            Defaults to 0.</span>
</span><span data-line="68"><span class="sd">        loss_reduction: Reduction method for loss (&#39;sum&#39;, &#39;mean&#39;, or &#39;none&#39;).</span>
</span><span data-line="69"><span class="sd">            Defaults to &#39;sum&#39;.</span>
</span><span data-line="70"><span class="sd">        negatives: Ratio of negative samples to use. Defaults to 1.0.</span>
</span><span data-line="71"><span class="sd">        masking: Masking strategy for training (&#39;global&#39; or other strategies).</span>
</span><span data-line="72"><span class="sd">            Defaults to &#39;global&#39;.</span>
</span><span data-line="73"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="74">
</span><span data-line="75">    <span class="n">cache_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span><span data-line="76">    <span class="n">optim</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="s2">&quot;adamw_torch&quot;</span><span class="p">)</span>
</span><span data-line="77">    <span class="n">others_lr</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span data-line="78">    <span class="n">others_weight_decay</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
</span><span data-line="79">    <span class="n">focal_loss_alpha</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</span><span data-line="80">    <span class="n">focal_loss_gamma</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span data-line="81">    <span class="n">focal_loss_prob_margin</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span data-line="82">    <span class="n">label_smoothing</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span data-line="83">    <span class="n">loss_reduction</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;sum&quot;</span>
</span><span data-line="84">    <span class="n">negatives</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
</span><span data-line="85">    <span class="n">masking</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;global&quot;</span></div>

</span><span data-line="86">
</span><span data-line="87">
<div class="viewcode-block" id="Trainer">
<a class="viewcode-back" href="../../../api/gliner.training.trainer.html#gliner.training.trainer.Trainer">[docs]</a>
</span><span data-line="88"><span class="k">class</span><span class="w"> </span><span class="nc">Trainer</span><span class="p">(</span><span class="n">transformers</span><span class="o">.</span><span class="n">Trainer</span><span class="p">):</span>
</span><span data-line="89"><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span data-line="90"><span class="sd">    Transformers v4/v5 compatible custom Trainer.</span>
</span><span data-line="91"><span class="sd">    - v5-safe method signatures (num_items_in_batch)</span>
</span><span data-line="92"><span class="sd">    - no hard dependency on self.use_apex</span>
</span><span data-line="93"><span class="sd">    - skips only OOM by default (other exceptions are raised so you don&#39;t silently get 0 loss)</span>
</span><span data-line="94"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="95">
</span><span data-line="96">    <span class="k">def</span><span class="w"> </span><span class="nf">_save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">state_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span data-line="97">        <span class="c1"># called by HF during checkpoint saves</span>
</span><span data-line="98">        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">should_save</span><span class="p">:</span>
</span><span data-line="99">            <span class="k">return</span>
</span><span data-line="100">
</span><span data-line="101">        <span class="n">output_dir</span> <span class="o">=</span> <span class="n">output_dir</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">output_dir</span>
</span><span data-line="102">        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span data-line="103">
</span><span data-line="104">        <span class="n">model_to_save</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">unwrap_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</span><span data-line="105">
</span><span data-line="106">        <span class="c1"># Prefer safetensors if TrainingArguments says so</span>
</span><span data-line="107">        <span class="n">safe</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="p">,</span> <span class="s2">&quot;save_safetensors&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">))</span>
</span><span data-line="108">
</span><span data-line="109">        <span class="n">sp</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model_to_save</span><span class="p">,</span> <span class="s2">&quot;save_pretrained&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span><span data-line="110">        <span class="k">if</span> <span class="n">sp</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="111">            <span class="c1"># last-resort fallback: behave like HF (weights only)</span>
</span><span data-line="112">            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model_to_save</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s2">&quot;pytorch_model.bin&quot;</span><span class="p">))</span>
</span><span data-line="113">            <span class="k">return</span>
</span><span data-line="114">
</span><span data-line="115">        <span class="n">sp_sig</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">sp</span><span class="p">)</span><span class="o">.</span><span class="n">parameters</span>
</span><span data-line="116">        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
</span><span data-line="117">        <span class="k">if</span> <span class="s2">&quot;safe_serialization&quot;</span> <span class="ow">in</span> <span class="n">sp_sig</span><span class="p">:</span>
</span><span data-line="118">            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;safe_serialization&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">safe</span>
</span><span data-line="119">
</span><span data-line="120">        <span class="k">if</span> <span class="n">state_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="s2">&quot;state_dict&quot;</span> <span class="ow">in</span> <span class="n">sp_sig</span><span class="p">:</span>
</span><span data-line="121">            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;state_dict&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">state_dict</span>
</span><span data-line="122">
</span><span data-line="123">        <span class="n">model_to_save</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span data-line="124">
</span><span data-line="125">        <span class="n">proc</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;processing_class&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;tokenizer&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span><span data-line="126">        <span class="k">if</span> <span class="n">proc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">proc</span><span class="p">,</span> <span class="s2">&quot;save_pretrained&quot;</span><span class="p">):</span>
</span><span data-line="127">            <span class="n">proc</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>
</span><span data-line="128">
<div class="viewcode-block" id="Trainer.save_model">
<a class="viewcode-back" href="../../../api/gliner.training.trainer.html#gliner.training.trainer.Trainer.save_model">[docs]</a>
</span><span data-line="129">    <span class="k">def</span><span class="w"> </span><span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">_internal_call</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
</span><span data-line="130">        <span class="c1"># make final save consistent with checkpoint saving</span>
</span><span data-line="131">        <span class="bp">self</span><span class="o">.</span><span class="n">_save</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span></div>

</span><span data-line="132">
</span><span data-line="133">    <span class="nd">@property</span>
</span><span data-line="134">    <span class="k">def</span><span class="w"> </span><span class="nf">use_apex</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
</span><span data-line="135">        <span class="k">return</span> <span class="nb">bool</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_use_apex&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">))</span>
</span><span data-line="136">
</span><span data-line="137">    <span class="nd">@use_apex</span><span class="o">.</span><span class="n">setter</span>
</span><span data-line="138">    <span class="k">def</span><span class="w"> </span><span class="nf">use_apex</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="139">        <span class="bp">self</span><span class="o">.</span><span class="n">_use_apex</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
</span><span data-line="140">
<div class="viewcode-block" id="Trainer.compute_loss">
<a class="viewcode-back" href="../../../api/gliner.training.trainer.html#gliner.training.trainer.Trainer.compute_loss">[docs]</a>
</span><span data-line="141">    <span class="k">def</span><span class="w"> </span><span class="nf">compute_loss</span><span class="p">(</span>
</span><span data-line="142">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="143">        <span class="n">model</span><span class="p">,</span>
</span><span data-line="144">        <span class="n">inputs</span><span class="p">,</span>
</span><span data-line="145">        <span class="n">return_outputs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span data-line="146">        <span class="n">num_items_in_batch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="147">    <span class="p">):</span>
</span><span data-line="148">        <span class="c1"># Prepare inputs are done in training_step / prediction_step</span>
</span><span data-line="149">        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span>
</span><span data-line="150">            <span class="n">alpha</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">focal_loss_alpha</span><span class="p">,</span>
</span><span data-line="151">            <span class="n">gamma</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">focal_loss_gamma</span><span class="p">,</span>
</span><span data-line="152">            <span class="n">prob_margin</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">focal_loss_prob_margin</span><span class="p">,</span>
</span><span data-line="153">            <span class="n">label_smoothing</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">label_smoothing</span><span class="p">,</span>
</span><span data-line="154">            <span class="n">reduction</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">loss_reduction</span><span class="p">,</span>
</span><span data-line="155">            <span class="n">negatives</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">negatives</span><span class="p">,</span>
</span><span data-line="156">            <span class="n">masking</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">masking</span><span class="p">,</span>
</span><span data-line="157">            <span class="o">**</span><span class="n">inputs</span><span class="p">,</span>
</span><span data-line="158">        <span class="p">)</span>
</span><span data-line="159">
</span><span data-line="160">        <span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">loss</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="s2">&quot;loss&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span>
</span><span data-line="161">        <span class="k">return</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span> <span class="k">if</span> <span class="n">return_outputs</span> <span class="k">else</span> <span class="n">loss</span></div>

</span><span data-line="162">
<div class="viewcode-block" id="Trainer.training_step">
<a class="viewcode-back" href="../../../api/gliner.training.trainer.html#gliner.training.trainer.Trainer.training_step">[docs]</a>
</span><span data-line="163">    <span class="k">def</span><span class="w"> </span><span class="nf">training_step</span><span class="p">(</span>
</span><span data-line="164">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="165">        <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
</span><span data-line="166">        <span class="n">inputs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
</span><span data-line="167">        <span class="n">num_items_in_batch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="168">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span data-line="169">        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</span><span data-line="170">        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_inputs</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span data-line="171">
</span><span data-line="172">        <span class="c1"># Guardrail: if labels are missing, fail loudly (otherwise you end up with loss=None -&gt; silent 0)</span>
</span><span data-line="173">        <span class="k">if</span> <span class="s2">&quot;labels&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
</span><span data-line="174">            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Batch has no &#39;labels&#39;. Keys: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span data-line="175">
</span><span data-line="176">        <span class="k">try</span><span class="p">:</span>
</span><span data-line="177">            <span class="k">if</span> <span class="n">is_sagemaker_mp_enabled</span><span class="p">():</span>
</span><span data-line="178">                <span class="n">loss_mb</span> <span class="o">=</span> <span class="n">smp_forward_backward</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span><span class="p">)</span>
</span><span data-line="179">                <span class="k">return</span> <span class="n">loss_mb</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span data-line="180">
</span><span data-line="181">            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_loss_context_manager</span><span class="p">():</span>
</span><span data-line="182">                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">num_items_in_batch</span><span class="o">=</span><span class="n">num_items_in_batch</span><span class="p">)</span>
</span><span data-line="183">
</span><span data-line="184">            <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="185">                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Model returned loss=None (check labels / remove_unused_columns / forward).&quot;</span><span class="p">)</span>
</span><span data-line="186">
</span><span data-line="187">            <span class="c1"># Average on multi-gpu</span>
</span><span data-line="188">            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">n_gpu</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span data-line="189">                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span><span data-line="190">
</span><span data-line="191">            <span class="c1"># Match upstream Trainer behavior: scale loss for grad accumulation before backward</span>
</span><span data-line="192">            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">deepspeed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="193">                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">gradient_accumulation_steps</span>
</span><span data-line="194">
</span><span data-line="195">            <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</span><span data-line="196">
</span><span data-line="197">            <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</span><span data-line="198">
</span><span data-line="199">        <span class="k">except</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">OutOfMemoryError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span data-line="200">            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Skipping batch due to CUDA OOM: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>
</span><span data-line="201">            <span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span data-line="202">            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
</span><span data-line="203">                <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</span><span data-line="204">            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((),</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span data-line="205">
</span><span data-line="206">        <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span data-line="207">            <span class="c1"># Some OOMs come as RuntimeError(&quot;CUDA out of memory...&quot;)</span>
</span><span data-line="208">            <span class="k">if</span> <span class="s2">&quot;out of memory&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
</span><span data-line="209">                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Skipping batch due to OOM RuntimeError: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>
</span><span data-line="210">                <span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span data-line="211">                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
</span><span data-line="212">                    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</span><span data-line="213">                <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((),</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span data-line="214">            <span class="c1"># Anything else: raise, so you don&#39;t silently train with zeros again</span>
</span><span data-line="215">            <span class="k">raise</span></div>

</span><span data-line="216">
<div class="viewcode-block" id="Trainer.create_optimizer">
<a class="viewcode-back" href="../../../api/gliner.training.trainer.html#gliner.training.trainer.Trainer.create_optimizer">[docs]</a>
</span><span data-line="217">    <span class="k">def</span><span class="w"> </span><span class="nf">create_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span data-line="218">        <span class="k">if</span> <span class="n">is_sagemaker_mp_enabled</span><span class="p">():</span>
</span><span data-line="219">            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">create_optimizer</span><span class="p">()</span>
</span><span data-line="220">
</span><span data-line="221">        <span class="n">opt_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span>
</span><span data-line="222">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="223">            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span>
</span><span data-line="224">
</span><span data-line="225">        <span class="n">decay_parameters</span> <span class="o">=</span> <span class="n">get_parameter_names</span><span class="p">(</span><span class="n">opt_model</span><span class="p">,</span> <span class="n">ALL_LAYERNORM_LAYERS</span><span class="p">)</span>
</span><span data-line="226">        <span class="n">decay_parameters</span> <span class="o">=</span> <span class="p">[</span><span class="n">name</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">decay_parameters</span> <span class="k">if</span> <span class="s2">&quot;bias&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">name</span><span class="p">]</span>
</span><span data-line="227">
</span><span data-line="228">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">others_lr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="229">            <span class="n">encoder_parameters</span> <span class="o">=</span> <span class="p">[</span><span class="n">name</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">opt_model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()</span> <span class="k">if</span> <span class="s2">&quot;token_rep_layer&quot;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">]</span>
</span><span data-line="230">            <span class="n">optimizer_grouped_parameters</span> <span class="o">=</span> <span class="p">[</span>
</span><span data-line="231">                <span class="p">{</span>
</span><span data-line="232">                    <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span>
</span><span data-line="233">                        <span class="n">p</span>
</span><span data-line="234">                        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">opt_model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()</span>
</span><span data-line="235">                        <span class="k">if</span> <span class="p">(</span><span class="n">n</span> <span class="ow">in</span> <span class="n">decay_parameters</span> <span class="ow">and</span> <span class="n">n</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">encoder_parameters</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
</span><span data-line="236">                    <span class="p">],</span>
</span><span data-line="237">                    <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">others_weight_decay</span><span class="p">,</span>
</span><span data-line="238">                    <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">others_lr</span><span class="p">,</span>
</span><span data-line="239">                <span class="p">},</span>
</span><span data-line="240">                <span class="p">{</span>
</span><span data-line="241">                    <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span>
</span><span data-line="242">                        <span class="n">p</span>
</span><span data-line="243">                        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">opt_model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()</span>
</span><span data-line="244">                        <span class="k">if</span> <span class="p">(</span><span class="n">n</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">decay_parameters</span> <span class="ow">and</span> <span class="n">n</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">encoder_parameters</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
</span><span data-line="245">                    <span class="p">],</span>
</span><span data-line="246">                    <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="247">                    <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">others_lr</span><span class="p">,</span>
</span><span data-line="248">                <span class="p">},</span>
</span><span data-line="249">                <span class="p">{</span>
</span><span data-line="250">                    <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span>
</span><span data-line="251">                        <span class="n">p</span>
</span><span data-line="252">                        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">opt_model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()</span>
</span><span data-line="253">                        <span class="k">if</span> <span class="p">(</span><span class="n">n</span> <span class="ow">in</span> <span class="n">decay_parameters</span> <span class="ow">and</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">encoder_parameters</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
</span><span data-line="254">                    <span class="p">],</span>
</span><span data-line="255">                    <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">,</span>
</span><span data-line="256">                <span class="p">},</span>
</span><span data-line="257">                <span class="p">{</span>
</span><span data-line="258">                    <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span>
</span><span data-line="259">                        <span class="n">p</span>
</span><span data-line="260">                        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">opt_model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()</span>
</span><span data-line="261">                        <span class="k">if</span> <span class="p">(</span><span class="n">n</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">decay_parameters</span> <span class="ow">and</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">encoder_parameters</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
</span><span data-line="262">                    <span class="p">],</span>
</span><span data-line="263">                    <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="264">                <span class="p">},</span>
</span><span data-line="265">            <span class="p">]</span>
</span><span data-line="266">        <span class="k">else</span><span class="p">:</span>
</span><span data-line="267">            <span class="n">optimizer_grouped_parameters</span> <span class="o">=</span> <span class="p">[</span>
</span><span data-line="268">                <span class="p">{</span>
</span><span data-line="269">                    <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span>
</span><span data-line="270">                        <span class="n">p</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">opt_model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()</span> <span class="k">if</span> <span class="p">(</span><span class="n">n</span> <span class="ow">in</span> <span class="n">decay_parameters</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
</span><span data-line="271">                    <span class="p">],</span>
</span><span data-line="272">                    <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">,</span>
</span><span data-line="273">                <span class="p">},</span>
</span><span data-line="274">                <span class="p">{</span>
</span><span data-line="275">                    <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span>
</span><span data-line="276">                        <span class="n">p</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">opt_model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()</span> <span class="k">if</span> <span class="p">(</span><span class="n">n</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">decay_parameters</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
</span><span data-line="277">                    <span class="p">],</span>
</span><span data-line="278">                    <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span data-line="279">                <span class="p">},</span>
</span><span data-line="280">            <span class="p">]</span>
</span><span data-line="281">
</span><span data-line="282">        <span class="c1"># Works across v4/v5</span>
</span><span data-line="283">        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">transformers</span><span class="o">.</span><span class="n">Trainer</span><span class="p">,</span> <span class="s2">&quot;get_optimizer_cls_and_kwargs&quot;</span><span class="p">):</span>
</span><span data-line="284">            <span class="n">optimizer_cls</span><span class="p">,</span> <span class="n">optimizer_kwargs</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">Trainer</span><span class="o">.</span><span class="n">get_optimizer_cls_and_kwargs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="p">)</span>
</span><span data-line="285">        <span class="k">else</span><span class="p">:</span>
</span><span data-line="286">            <span class="c1"># very old fallback</span>
</span><span data-line="287">            <span class="n">optimizer_cls</span><span class="p">,</span> <span class="n">optimizer_kwargs</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_optimizer_cls_and_kwargs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="p">)</span>
</span><span data-line="288">
</span><span data-line="289">        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer_cls</span><span class="p">(</span><span class="n">optimizer_grouped_parameters</span><span class="p">,</span> <span class="o">**</span><span class="n">optimizer_kwargs</span><span class="p">)</span>
</span><span data-line="290">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span></div>

</span><span data-line="291">
<div class="viewcode-block" id="Trainer.prediction_step">
<a class="viewcode-back" href="../../../api/gliner.training.trainer.html#gliner.training.trainer.Trainer.prediction_step">[docs]</a>
</span><span data-line="292">    <span class="k">def</span><span class="w"> </span><span class="nf">prediction_step</span><span class="p">(</span>
</span><span data-line="293">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="294">        <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
</span><span data-line="295">        <span class="n">inputs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
</span><span data-line="296">        <span class="n">prediction_loss_only</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span data-line="297">        <span class="n">ignore_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="298">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
</span><span data-line="299">        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span><span data-line="300">        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_inputs</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span data-line="301">
</span><span data-line="302">        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span data-line="303">            <span class="n">loss</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">return_outputs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span data-line="304">            <span class="n">logits</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="s2">&quot;logits&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span><span data-line="305">            <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;labels&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span><span data-line="306">
</span><span data-line="307">        <span class="k">if</span> <span class="n">prediction_loss_only</span><span class="p">:</span>
</span><span data-line="308">            <span class="k">return</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span><span data-line="309">        <span class="k">return</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span></div>

</span><span data-line="310">
<div class="viewcode-block" id="Trainer.get_train_dataloader">
<a class="viewcode-back" href="../../../api/gliner.training.trainer.html#gliner.training.trainer.Trainer.get_train_dataloader">[docs]</a>
</span><span data-line="311">    <span class="k">def</span><span class="w"> </span><span class="nf">get_train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataLoader</span><span class="p">:</span>
</span><span data-line="312">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="313">            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Trainer: training requires a train_dataset.&quot;</span><span class="p">)</span>
</span><span data-line="314">
</span><span data-line="315">        <span class="n">train_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span>
</span><span data-line="316">        <span class="n">data_collator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_collator</span>
</span><span data-line="317">
</span><span data-line="318">        <span class="n">dataloader_params</span> <span class="o">=</span> <span class="p">{</span>
</span><span data-line="319">            <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_batch_size</span><span class="p">,</span>
</span><span data-line="320">            <span class="s2">&quot;collate_fn&quot;</span><span class="p">:</span> <span class="n">data_collator</span><span class="p">,</span>
</span><span data-line="321">            <span class="s2">&quot;num_workers&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">dataloader_num_workers</span><span class="p">,</span>
</span><span data-line="322">            <span class="s2">&quot;pin_memory&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">dataloader_pin_memory</span><span class="p">,</span>
</span><span data-line="323">            <span class="s2">&quot;persistent_workers&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">dataloader_persistent_workers</span><span class="p">,</span>
</span><span data-line="324">        <span class="p">}</span>
</span><span data-line="325">
</span><span data-line="326">        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">IterableDataset</span><span class="p">):</span>
</span><span data-line="327">            <span class="n">dataloader_params</span><span class="p">[</span><span class="s2">&quot;sampler&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_train_sampler</span><span class="p">()</span>
</span><span data-line="328">            <span class="n">dataloader_params</span><span class="p">[</span><span class="s2">&quot;drop_last&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">dataloader_drop_last</span>
</span><span data-line="329">            <span class="n">dataloader_params</span><span class="p">[</span><span class="s2">&quot;worker_init_fn&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">seed_worker</span>
</span><span data-line="330">            <span class="n">dataloader_params</span><span class="p">[</span><span class="s2">&quot;prefetch_factor&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">dataloader_prefetch_factor</span>
</span><span data-line="331">
</span><span data-line="332">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="o">**</span><span class="n">dataloader_params</span><span class="p">))</span></div>

</span><span data-line="333">
<div class="viewcode-block" id="Trainer.get_eval_dataloader">
<a class="viewcode-back" href="../../../api/gliner.training.trainer.html#gliner.training.trainer.Trainer.get_eval_dataloader">[docs]</a>
</span><span data-line="334">    <span class="k">def</span><span class="w"> </span><span class="nf">get_eval_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eval_dataset</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataLoader</span><span class="p">:</span>
</span><span data-line="335">        <span class="k">if</span> <span class="n">eval_dataset</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="336">            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Trainer: evaluation requires an eval_dataset.&quot;</span><span class="p">)</span>
</span><span data-line="337">
</span><span data-line="338">        <span class="n">dataloader_key</span> <span class="o">=</span> <span class="n">eval_dataset</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;eval&quot;</span>
</span><span data-line="339">        <span class="k">if</span> <span class="p">(</span>
</span><span data-line="340">            <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_eval_dataloaders&quot;</span><span class="p">)</span>
</span><span data-line="341">            <span class="ow">and</span> <span class="n">dataloader_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_eval_dataloaders</span>
</span><span data-line="342">            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">dataloader_persistent_workers</span>
</span><span data-line="343">        <span class="p">):</span>
</span><span data-line="344">            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_eval_dataloaders</span><span class="p">[</span><span class="n">dataloader_key</span><span class="p">])</span>
</span><span data-line="345">
</span><span data-line="346">        <span class="n">eval_dataset</span> <span class="o">=</span> <span class="p">(</span>
</span><span data-line="347">            <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span><span class="p">[</span><span class="n">eval_dataset</span><span class="p">]</span>
</span><span data-line="348">            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
</span><span data-line="349">            <span class="k">else</span> <span class="n">eval_dataset</span>
</span><span data-line="350">            <span class="k">if</span> <span class="n">eval_dataset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span><span data-line="351">            <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_dataset</span>
</span><span data-line="352">        <span class="p">)</span>
</span><span data-line="353">
</span><span data-line="354">        <span class="n">dataloader_params</span> <span class="o">=</span> <span class="p">{</span>
</span><span data-line="355">            <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">eval_batch_size</span><span class="p">,</span>
</span><span data-line="356">            <span class="s2">&quot;collate_fn&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_collator</span><span class="p">,</span>
</span><span data-line="357">            <span class="s2">&quot;num_workers&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">dataloader_num_workers</span><span class="p">,</span>
</span><span data-line="358">            <span class="s2">&quot;pin_memory&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">dataloader_pin_memory</span><span class="p">,</span>
</span><span data-line="359">            <span class="s2">&quot;persistent_workers&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">dataloader_persistent_workers</span><span class="p">,</span>
</span><span data-line="360">        <span class="p">}</span>
</span><span data-line="361">
</span><span data-line="362">        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">IterableDataset</span><span class="p">):</span>
</span><span data-line="363">            <span class="n">dataloader_params</span><span class="p">[</span><span class="s2">&quot;sampler&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_eval_sampler</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">)</span>
</span><span data-line="364">            <span class="n">dataloader_params</span><span class="p">[</span><span class="s2">&quot;drop_last&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">dataloader_drop_last</span>
</span><span data-line="365">            <span class="n">dataloader_params</span><span class="p">[</span><span class="s2">&quot;prefetch_factor&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">dataloader_prefetch_factor</span>
</span><span data-line="366">
</span><span data-line="367">        <span class="n">eval_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">,</span> <span class="o">**</span><span class="n">dataloader_params</span><span class="p">)</span>
</span><span data-line="368">
</span><span data-line="369">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">dataloader_persistent_workers</span><span class="p">:</span>
</span><span data-line="370">            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_eval_dataloaders&quot;</span><span class="p">):</span>
</span><span data-line="371">                <span class="bp">self</span><span class="o">.</span><span class="n">_eval_dataloaders</span><span class="p">[</span><span class="n">dataloader_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">eval_dataloader</span>
</span><span data-line="372">            <span class="k">else</span><span class="p">:</span>
</span><span data-line="373">                <span class="bp">self</span><span class="o">.</span><span class="n">_eval_dataloaders</span> <span class="o">=</span> <span class="p">{</span><span class="n">dataloader_key</span><span class="p">:</span> <span class="n">eval_dataloader</span><span class="p">}</span>
</span><span data-line="374">
</span><span data-line="375">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">eval_dataloader</span><span class="p">)</span></div>
</div>

</span></pre></div>
        </article><button class="back-to-top" type="button">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
  </svg>
  <span>Back to top</span>
</button><div class="navigation flex print:hidden"></div></div>
    </div>
  </main>
</div>
<footer class="sy-foot">
  <div class="sy-foot-inner sy-container mx-auto">
    <div class="sy-foot-reserved md:flex justify-between items-center">
      <div class="sy-foot-copyright"><p>2025, GLiNER community</p>
  
  <p>
    Made with
    
    <a href="https://www.sphinx-doc.org/">Sphinx</a> and
    
    <a href="https://shibuya.lepture.com">Shibuya theme</a>.
  </p>
</div>
      <div class="sy-foot-socials"></div>
    </div>
  </div>
</footer>
      <script src="../../../_static/documentation_options.js?v=dc91f075"></script>
      <script src="../../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../../_static/shibuya.js?v=9b0e4dde"></script></body>
</html>