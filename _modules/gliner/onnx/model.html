<!DOCTYPE html>
<html lang="en" data-accent-color="violet" data-content_root="../../../">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0"><title>gliner.onnx.model - Home 0.2.24 documentation</title><link rel="index" title="Index" href="../../../genindex.html" /><link rel="search" title="Search" href="../../../search.html" /><script>
    function setColorMode(t){let e=document.documentElement;e.setAttribute("data-color-mode",t);let a=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,s=t;"auto"===t&&(s=a?"dark":"light"),"light"===s?(e.classList.remove("dark"),e.classList.add("light")):(e.classList.remove("light"),e.classList.add("dark"))}
    setColorMode(localStorage._theme||"auto");
  </script><link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=e1a1ceaf" />
    <link rel="stylesheet" type="text/css" href="../../../_static/shibuya.css?v=d140fbf8" />
    <link media="print" rel="stylesheet" type="text/css" href="../../../_static/print.css?v=20ff2c19" />
    <link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
<style>
:root {
  --sy-f-text: "Inter", var(--sy-f-sys), var(--sy-f-cjk), sans-serif;
  --sy-f-heading: "Inter", var(--sy-f-sys), var(--sy-f-cjk), sans-serif;
}
</style>
    <meta property="og:type" content="website"/><meta property="og:title" content="gliner.onnx.model"/>
<meta name="twitter:card" content="summary"/>
  </head>
<body><div class="sy-head">
  <div class="sy-head-blur"></div>
  <div class="sy-head-inner sy-container mx-auto">
    <a class="sy-head-brand" href="../../../index.html">
      
      
      <strong>Home</strong>
    </a>
    <div class="sy-head-nav" id="head-nav">
      <nav class="sy-head-links"></nav>
      <div class="sy-head-extra flex items-center print:hidden"><form class="searchbox flex items-center" action="../../../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <kbd>/</kbd>
</form><div class="sy-head-socials"></div></div>
    </div>
    <div class="sy-head-actions flex items-center shrink-0 print:hidden"><button class="js-theme theme-switch flex items-center"
data-aria-auto="Switch to light color mode"
data-aria-light="Switch to dark color mode"
data-aria-dark="Switch to auto color mode">
<i class="i-lucide theme-icon"></i>
</button><button class="md:hidden flex items-center js-menu" aria-label="Menu" type="button" aria-controls="head-nav" aria-expanded="false">
        <div class="hamburger">
          <span class="hamburger_1"></span>
          <span class="hamburger_2"></span>
          <span class="hamburger_3"></span>
        </div>
      </button>
    </div>
  </div>
</div>
<div class="sy-page sy-container flex mx-auto">
  <aside id="lside" class="sy-lside md:w-72 md:shrink-0 print:hidden">
    <div class="sy-lside-inner md:sticky">
      <div class="sy-scrollbar p-6">
        <div class="globaltoc" data-expand-depth="0"><p class="caption" role="heading" aria-level="3"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../intro.html">Introduction to ðŸ‘‘ GLiNER</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../instalation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage.html">Advanced Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../configs.html">Components &amp; Configs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../training.html">Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../architectures.html">Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../convert_to_onnx.html">ONNX Export &amp; Deployment</a></li>
</ul>
<p class="caption" role="heading" aria-level="3"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.model.html">gliner.model module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.config.html">gliner.config module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.training.html">gliner.training package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.training.trainer.html">gliner.training.trainer module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.modeling.html">gliner.modeling package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.multitask.html">gliner.modeling.multitask package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gliner.modeling.multitask.relations_layers.html">gliner.modeling.multitask.relations_layers module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gliner.modeling.multitask.triples_layers.html">gliner.modeling.multitask.triples_layers module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.base.html">gliner.modeling.base module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.decoder.html">gliner.modeling.decoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.encoder.html">gliner.modeling.encoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.layers.html">gliner.modeling.layers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.loss_functions.html">gliner.modeling.loss_functions module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.outputs.html">gliner.modeling.outputs module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.scorers.html">gliner.modeling.scorers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.span_rep.html">gliner.modeling.span_rep module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.modeling.utils.html">gliner.modeling.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.data_processing.html">gliner.data_processing package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.data_processing.collator.html">gliner.data_processing.collator module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.data_processing.processor.html">gliner.data_processing.processor module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.data_processing.tokenizer.html">gliner.data_processing.tokenizer module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.data_processing.utils.html">gliner.data_processing.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.evaluation.html">gliner.evaluation package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.evaluation.evaluate_ner.html">gliner.evaluation.evaluate_ner module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.evaluation.evaluator.html">gliner.evaluation.evaluator module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.evaluation.utils.html">gliner.evaluation.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.onnx.html">gliner.onnx package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.onnx.model.html">gliner.onnx.model module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.decoding.html">gliner.decoding package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.decoding.trie.html">gliner.decoding.trie package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gliner.decoding.trie.labels_trie.html">gliner.decoding.trie.labels_trie module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gliner.decoding.trie.python_labels_trie.html">gliner.decoding.trie.python_labels_trie module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.decoding.decoder.html">gliner.decoding.decoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gliner.decoding.utils.html">gliner.decoding.utils module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/gliner.utils.html">gliner.utils module</a></li>
</ul>

        </div>
      </div>
    </div>
  </aside>
  <div class="lside-overlay js-menu" role="button" aria-label="Close left sidebar" aria-controls="lside" aria-expanded="false"></div>
  <aside id="rside" class="sy-rside pb-3 w-64 shrink-0 order-last">
    <button class="rside-close js-menu xl:hidden" aria-label="Close Table of Contents" type="button" aria-controls="rside" aria-expanded="false">
      <i class="i-lucide close"></i>
    </button>
    <div class="sy-scrollbar sy-rside-inner px-6 xl:top-16 xl:sticky xl:pl-0 pt-6 pb-4"><div id="ethical-ad-placement" data-ea-publisher="readthedocs"></div></div>
  </aside>
  <div class="rside-overlay js-menu" role="button" aria-label="Close Table of Contents" aria-controls="rside" aria-expanded="false"></div>
  <main class="sy-main w-full max-sm:max-w-full print:pt-6">
<div class="sy-breadcrumbs" role="navigation">
  <div class="sy-breadcrumbs-inner flex items-center">
    <div class="md:hidden mr-3">
      <button class="js-menu" aria-label="Menu" type="button" aria-controls="lside" aria-expanded="false">
        <i class="i-lucide menu"></i>
      </button>
    </div>
    <ol class="flex-1" itemscope itemtype="https://schema.org/BreadcrumbList"><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <a itemprop="item" href="../../../index.html"><span itemprop="name">Home</span></a>
        <span>/</span>
        <meta itemprop="position" content="1" />
      </li><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <a itemprop="item" href="../../index.html"><span itemprop="name">Module code</span></a>
        <span>/</span>
        <meta itemprop="position" content="2" />
      </li><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <strong itemprop="name">gliner.onnx.model</strong>
        <meta itemprop="position" content="3" />
      </li></ol>
    <div class="xl:hidden ml-1">
      <button class="js-menu" aria-label="Show table of contents" type="button" aria-controls="rside"
        aria-expanded="false">
        <i class="i-lucide outdent"></i>
      </button>
    </div>
  </div>
</div><div class="flex flex-col break-words justify-between">
      <div class="min-w-0 max-w-6xl px-6 pb-6 pt-8 xl:px-12">
        <article class="yue" role="main">
          <h1>Source code for gliner.onnx.model</h1><div class="highlight"><pre>
<span></span><span data-line="1"><span class="sd">&quot;&quot;&quot;ONNX Runtime inference models for GLiNER.</span>
</span><span data-line="2">
</span><span data-line="3"><span class="sd">This module provides ONNX Runtime implementations of various GLiNER model</span>
</span><span data-line="4"><span class="sd">architectures, including uni-encoder and bi-encoder variants for both</span>
</span><span data-line="5"><span class="sd">span-level and token-level named entity recognition, as well as relation</span>
</span><span data-line="6"><span class="sd">extraction models.</span>
</span><span data-line="7"><span class="sd">&quot;&quot;&quot;</span>
</span><span data-line="8">
</span><span data-line="9"><span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
</span><span data-line="10"><span class="kn">from</span><span class="w"> </span><span class="nn">abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
</span><span data-line="11"><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Optional</span>
</span><span data-line="12">
</span><span data-line="13"><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
</span><span data-line="14"><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span data-line="15"><span class="kn">import</span><span class="w"> </span><span class="nn">onnxruntime</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ort</span>
</span><span data-line="16">
</span><span data-line="17"><span class="kn">from</span><span class="w"> </span><span class="nn">..modeling.outputs</span><span class="w"> </span><span class="kn">import</span> <span class="n">GLiNERBaseOutput</span><span class="p">,</span> <span class="n">GLiNERRelexOutput</span>
</span><span data-line="18">
</span><span data-line="19">
<div class="viewcode-block" id="BaseORTModel">
<a class="viewcode-back" href="../../../api/gliner.onnx.model.html#gliner.onnx.model.BaseORTModel">[docs]</a>
</span><span data-line="20"><span class="k">class</span><span class="w"> </span><span class="nc">BaseORTModel</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
</span><span data-line="21"><span class="w">    </span><span class="sd">&quot;&quot;&quot;Base class for ONNX Runtime inference models.</span>
</span><span data-line="22">
</span><span data-line="23"><span class="sd">    Provides common functionality for preparing inputs, running inference,</span>
</span><span data-line="24"><span class="sd">    and managing ONNX session I/O. All concrete ORT model implementations</span>
</span><span data-line="25"><span class="sd">    should inherit from this class.</span>
</span><span data-line="26">
</span><span data-line="27"><span class="sd">    Attributes:</span>
</span><span data-line="28"><span class="sd">        session: ONNX Runtime inference session.</span>
</span><span data-line="29"><span class="sd">        input_names: Dictionary mapping input names to their indices.</span>
</span><span data-line="30"><span class="sd">        output_names: Dictionary mapping output names to their indices.</span>
</span><span data-line="31"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="32">
<div class="viewcode-block" id="BaseORTModel.__init__">
<a class="viewcode-back" href="../../../api/gliner.onnx.model.html#gliner.onnx.model.BaseORTModel.__init__">[docs]</a>
</span><span data-line="33">    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">session</span><span class="p">:</span> <span class="n">ort</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">):</span>
</span><span data-line="34"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the ONNX Runtime model.</span>
</span><span data-line="35">
</span><span data-line="36"><span class="sd">        Args:</span>
</span><span data-line="37"><span class="sd">            session: ONNX Runtime inference session.</span>
</span><span data-line="38"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="39">        <span class="bp">self</span><span class="o">.</span><span class="n">session</span> <span class="o">=</span> <span class="n">session</span>
</span><span data-line="40">        <span class="bp">self</span><span class="o">.</span><span class="n">input_names</span> <span class="o">=</span> <span class="p">{</span><span class="n">input_key</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">input_key</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">())}</span>
</span><span data-line="41">        <span class="bp">self</span><span class="o">.</span><span class="n">output_names</span> <span class="o">=</span> <span class="p">{</span><span class="n">output_key</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">output_key</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">get_outputs</span><span class="p">())}</span></div>

</span><span data-line="42">
<div class="viewcode-block" id="BaseORTModel.prepare_inputs">
<a class="viewcode-back" href="../../../api/gliner.onnx.model.html#gliner.onnx.model.BaseORTModel.prepare_inputs">[docs]</a>
</span><span data-line="43">    <span class="k">def</span><span class="w"> </span><span class="nf">prepare_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
</span><span data-line="44"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Prepare inputs for ONNX model inference.</span>
</span><span data-line="45">
</span><span data-line="46"><span class="sd">        Converts PyTorch tensors to numpy arrays and filters out inputs</span>
</span><span data-line="47"><span class="sd">        that are not expected by the ONNX model.</span>
</span><span data-line="48">
</span><span data-line="49"><span class="sd">        Args:</span>
</span><span data-line="50"><span class="sd">            inputs: Dictionary of input names and PyTorch tensors.</span>
</span><span data-line="51">
</span><span data-line="52"><span class="sd">        Returns:</span>
</span><span data-line="53"><span class="sd">            Dictionary of input names and numpy arrays ready for ONNX inference.</span>
</span><span data-line="54">
</span><span data-line="55"><span class="sd">        Raises:</span>
</span><span data-line="56"><span class="sd">            ValueError: If inputs is not a dictionary.</span>
</span><span data-line="57"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="58">        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
</span><span data-line="59">            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Inputs must be a dictionary of input names and tensors.&quot;</span><span class="p">)</span>
</span><span data-line="60">
</span><span data-line="61">        <span class="n">prepared_inputs</span> <span class="o">=</span> <span class="p">{}</span>
</span><span data-line="62">        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span data-line="63">            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_names</span><span class="p">:</span>
</span><span data-line="64">                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Input key &#39;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">&#39; not found in ONNX model&#39;s input names. Ignored.&quot;</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span><span data-line="65">                <span class="k">continue</span>
</span><span data-line="66">            <span class="n">prepared_inputs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span data-line="67">        <span class="k">return</span> <span class="n">prepared_inputs</span></div>

</span><span data-line="68">
<div class="viewcode-block" id="BaseORTModel.run_inference">
<a class="viewcode-back" href="../../../api/gliner.onnx.model.html#gliner.onnx.model.BaseORTModel.run_inference">[docs]</a>
</span><span data-line="69">    <span class="k">def</span><span class="w"> </span><span class="nf">run_inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
</span><span data-line="70"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Run the ONNX model inference.</span>
</span><span data-line="71">
</span><span data-line="72"><span class="sd">        Args:</span>
</span><span data-line="73"><span class="sd">            inputs: Prepared inputs for the model as numpy arrays.</span>
</span><span data-line="74">
</span><span data-line="75"><span class="sd">        Returns:</span>
</span><span data-line="76"><span class="sd">            Dictionary mapping output names to their corresponding numpy arrays.</span>
</span><span data-line="77"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="78">        <span class="n">onnx_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
</span><span data-line="79">        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">onnx_outputs</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_names</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</span><span data-line="80">        <span class="k">return</span> <span class="n">outputs</span></div>

</span><span data-line="81">
<div class="viewcode-block" id="BaseORTModel.forward">
<a class="viewcode-back" href="../../../api/gliner.onnx.model.html#gliner.onnx.model.BaseORTModel.forward">[docs]</a>
</span><span data-line="82">    <span class="nd">@abstractmethod</span>
</span><span data-line="83">    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
</span><span data-line="84"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform forward pass through the model.</span>
</span><span data-line="85">
</span><span data-line="86"><span class="sd">        Abstract method that must be implemented by subclasses to define</span>
</span><span data-line="87"><span class="sd">        model-specific forward pass logic.</span>
</span><span data-line="88">
</span><span data-line="89"><span class="sd">        Args:</span>
</span><span data-line="90"><span class="sd">            input_ids: Input token IDs.</span>
</span><span data-line="91"><span class="sd">            attention_mask: Attention mask for input tokens.</span>
</span><span data-line="92"><span class="sd">            **kwargs: Additional model-specific arguments.</span>
</span><span data-line="93">
</span><span data-line="94"><span class="sd">        Returns:</span>
</span><span data-line="95"><span class="sd">            Dictionary containing model outputs.</span>
</span><span data-line="96"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="97">        <span class="k">pass</span></div>

</span><span data-line="98">
</span><span data-line="99">    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span data-line="100"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Make the model callable.</span>
</span><span data-line="101">
</span><span data-line="102"><span class="sd">        Delegates to the forward method.</span>
</span><span data-line="103">
</span><span data-line="104"><span class="sd">        Args:</span>
</span><span data-line="105"><span class="sd">            *args: Positional arguments to pass to forward.</span>
</span><span data-line="106"><span class="sd">            **kwargs: Keyword arguments to pass to forward.</span>
</span><span data-line="107">
</span><span data-line="108"><span class="sd">        Returns:</span>
</span><span data-line="109"><span class="sd">            Output from the forward method.</span>
</span><span data-line="110"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="111">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

</span><span data-line="112">
</span><span data-line="113">
<div class="viewcode-block" id="UniEncoderSpanORTModel">
<a class="viewcode-back" href="../../../api/gliner.onnx.model.html#gliner.onnx.model.UniEncoderSpanORTModel">[docs]</a>
</span><span data-line="114"><span class="k">class</span><span class="w"> </span><span class="nc">UniEncoderSpanORTModel</span><span class="p">(</span><span class="n">BaseORTModel</span><span class="p">):</span>
</span><span data-line="115"><span class="w">    </span><span class="sd">&quot;&quot;&quot;ONNX Runtime model for uni-encoder span-level NER.</span>
</span><span data-line="116">
</span><span data-line="117"><span class="sd">    Uses a single encoder to process both text and entity labels,</span>
</span><span data-line="118"><span class="sd">    performing span-level entity recognition.</span>
</span><span data-line="119"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="120">
<div class="viewcode-block" id="UniEncoderSpanORTModel.forward">
<a class="viewcode-back" href="../../../api/gliner.onnx.model.html#gliner.onnx.model.UniEncoderSpanORTModel.forward">[docs]</a>
</span><span data-line="121">    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span data-line="122">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="123">        <span class="n">input_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="124">        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="125">        <span class="n">words_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="126">        <span class="n">text_lengths</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="127">        <span class="n">span_idx</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="128">        <span class="n">span_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="129">        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span data-line="130">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
</span><span data-line="131"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward pass for span model using ONNX inference.</span>
</span><span data-line="132">
</span><span data-line="133"><span class="sd">        Args:</span>
</span><span data-line="134"><span class="sd">            input_ids: Tensor of shape (batch_size, seq_len) containing input token IDs.</span>
</span><span data-line="135"><span class="sd">            attention_mask: Tensor of shape (batch_size, seq_len) with 1s for real</span>
</span><span data-line="136"><span class="sd">                tokens and 0s for padding.</span>
</span><span data-line="137"><span class="sd">            words_mask: Tensor of shape (batch_size, seq_len) indicating word boundaries.</span>
</span><span data-line="138"><span class="sd">            text_lengths: Tensor of shape (batch_size,) containing the actual length</span>
</span><span data-line="139"><span class="sd">                of each text sequence.</span>
</span><span data-line="140"><span class="sd">            span_idx: Tensor containing indices of spans to classify.</span>
</span><span data-line="141"><span class="sd">            span_mask: Tensor indicating which spans are valid (not padding).</span>
</span><span data-line="142"><span class="sd">            **kwargs: Additional arguments (ignored).</span>
</span><span data-line="143">
</span><span data-line="144"><span class="sd">        Returns:</span>
</span><span data-line="145"><span class="sd">            GLiNERBaseOutput containing logits for span classification.</span>
</span><span data-line="146"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="147">        <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span>
</span><span data-line="148">            <span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">input_ids</span><span class="p">,</span>
</span><span data-line="149">            <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">attention_mask</span><span class="p">,</span>
</span><span data-line="150">            <span class="s2">&quot;words_mask&quot;</span><span class="p">:</span> <span class="n">words_mask</span><span class="p">,</span>
</span><span data-line="151">            <span class="s2">&quot;text_lengths&quot;</span><span class="p">:</span> <span class="n">text_lengths</span><span class="p">,</span>
</span><span data-line="152">            <span class="s2">&quot;span_idx&quot;</span><span class="p">:</span> <span class="n">span_idx</span><span class="p">,</span>
</span><span data-line="153">            <span class="s2">&quot;span_mask&quot;</span><span class="p">:</span> <span class="n">span_mask</span><span class="p">,</span>
</span><span data-line="154">        <span class="p">}</span>
</span><span data-line="155">        <span class="n">prepared_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_inputs</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span data-line="156">        <span class="n">inference_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_inference</span><span class="p">(</span><span class="n">prepared_inputs</span><span class="p">)</span>
</span><span data-line="157">        <span class="n">outputs</span> <span class="o">=</span> <span class="n">GLiNERBaseOutput</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">inference_output</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">])</span>
</span><span data-line="158">        <span class="k">return</span> <span class="n">outputs</span></div>
</div>

</span><span data-line="159">
</span><span data-line="160">
<div class="viewcode-block" id="BiEncoderSpanORTModel">
<a class="viewcode-back" href="../../../api/gliner.onnx.model.html#gliner.onnx.model.BiEncoderSpanORTModel">[docs]</a>
</span><span data-line="161"><span class="k">class</span><span class="w"> </span><span class="nc">BiEncoderSpanORTModel</span><span class="p">(</span><span class="n">BaseORTModel</span><span class="p">):</span>
</span><span data-line="162"><span class="w">    </span><span class="sd">&quot;&quot;&quot;ONNX Runtime model for bi-encoder span-level NER.</span>
</span><span data-line="163">
</span><span data-line="164"><span class="sd">    Uses separate encoders for text and entity labels, performing</span>
</span><span data-line="165"><span class="sd">    span-level entity recognition with bi-encoder architecture.</span>
</span><span data-line="166"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="167">
<div class="viewcode-block" id="BiEncoderSpanORTModel.forward">
<a class="viewcode-back" href="../../../api/gliner.onnx.model.html#gliner.onnx.model.BiEncoderSpanORTModel.forward">[docs]</a>
</span><span data-line="168">    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span data-line="169">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="170">        <span class="n">input_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="171">        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="172">        <span class="n">words_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="173">        <span class="n">text_lengths</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="174">        <span class="n">span_idx</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="175">        <span class="n">span_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="176">        <span class="n">labels_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="177">        <span class="n">labels_input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="178">        <span class="n">labels_attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="179">        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span data-line="180">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
</span><span data-line="181"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward pass for bi-encoder span model using ONNX inference.</span>
</span><span data-line="182">
</span><span data-line="183"><span class="sd">        Args:</span>
</span><span data-line="184"><span class="sd">            input_ids: Tensor of shape (batch_size, seq_len) containing input token IDs.</span>
</span><span data-line="185"><span class="sd">            attention_mask: Tensor of shape (batch_size, seq_len) with 1s for real</span>
</span><span data-line="186"><span class="sd">                tokens and 0s for padding.</span>
</span><span data-line="187"><span class="sd">            words_mask: Tensor of shape (batch_size, seq_len) indicating word boundaries.</span>
</span><span data-line="188"><span class="sd">            text_lengths: Tensor of shape (batch_size,) containing the actual length</span>
</span><span data-line="189"><span class="sd">                of each text sequence.</span>
</span><span data-line="190"><span class="sd">            span_idx: Tensor containing indices of spans to classify.</span>
</span><span data-line="191"><span class="sd">            span_mask: Tensor indicating which spans are valid (not padding).</span>
</span><span data-line="192"><span class="sd">            labels_embeds: Optional pre-computed embeddings for entity labels.</span>
</span><span data-line="193"><span class="sd">                If provided, labels_input_ids and labels_attention_mask are ignored.</span>
</span><span data-line="194"><span class="sd">            labels_input_ids: Optional tensor containing token IDs for entity labels.</span>
</span><span data-line="195"><span class="sd">                Used when labels_embeds is not provided.</span>
</span><span data-line="196"><span class="sd">            labels_attention_mask: Optional attention mask for entity label tokens.</span>
</span><span data-line="197"><span class="sd">                Used when labels_embeds is not provided.</span>
</span><span data-line="198"><span class="sd">            **kwargs: Additional arguments (ignored).</span>
</span><span data-line="199">
</span><span data-line="200"><span class="sd">        Returns:</span>
</span><span data-line="201"><span class="sd">            GLiNERBaseOutput containing logits for span classification.</span>
</span><span data-line="202"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="203">        <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span>
</span><span data-line="204">            <span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">input_ids</span><span class="p">,</span>
</span><span data-line="205">            <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">attention_mask</span><span class="p">,</span>
</span><span data-line="206">            <span class="s2">&quot;words_mask&quot;</span><span class="p">:</span> <span class="n">words_mask</span><span class="p">,</span>
</span><span data-line="207">            <span class="s2">&quot;text_lengths&quot;</span><span class="p">:</span> <span class="n">text_lengths</span><span class="p">,</span>
</span><span data-line="208">            <span class="s2">&quot;span_idx&quot;</span><span class="p">:</span> <span class="n">span_idx</span><span class="p">,</span>
</span><span data-line="209">            <span class="s2">&quot;span_mask&quot;</span><span class="p">:</span> <span class="n">span_mask</span><span class="p">,</span>
</span><span data-line="210">        <span class="p">}</span>
</span><span data-line="211">        <span class="k">if</span> <span class="n">labels_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="212">            <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;labels_embeds&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels_embeds</span>
</span><span data-line="213">        <span class="k">else</span><span class="p">:</span>
</span><span data-line="214">            <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;labels_input_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels_input_ids</span>
</span><span data-line="215">            <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;labels_attention_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels_attention_mask</span>
</span><span data-line="216">
</span><span data-line="217">        <span class="n">prepared_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_inputs</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span data-line="218">        <span class="n">inference_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_inference</span><span class="p">(</span><span class="n">prepared_inputs</span><span class="p">)</span>
</span><span data-line="219">        <span class="n">outputs</span> <span class="o">=</span> <span class="n">GLiNERBaseOutput</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">inference_output</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">])</span>
</span><span data-line="220">        <span class="k">return</span> <span class="n">outputs</span></div>
</div>

</span><span data-line="221">
</span><span data-line="222">
<div class="viewcode-block" id="UniEncoderTokenORTModel">
<a class="viewcode-back" href="../../../api/gliner.onnx.model.html#gliner.onnx.model.UniEncoderTokenORTModel">[docs]</a>
</span><span data-line="223"><span class="k">class</span><span class="w"> </span><span class="nc">UniEncoderTokenORTModel</span><span class="p">(</span><span class="n">BaseORTModel</span><span class="p">):</span>
</span><span data-line="224"><span class="w">    </span><span class="sd">&quot;&quot;&quot;ONNX Runtime model for uni-encoder token-level NER.</span>
</span><span data-line="225">
</span><span data-line="226"><span class="sd">    Uses a single encoder to process both text and entity labels,</span>
</span><span data-line="227"><span class="sd">    performing token-level entity recognition.</span>
</span><span data-line="228"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="229">
<div class="viewcode-block" id="UniEncoderTokenORTModel.forward">
<a class="viewcode-back" href="../../../api/gliner.onnx.model.html#gliner.onnx.model.UniEncoderTokenORTModel.forward">[docs]</a>
</span><span data-line="230">    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span data-line="231">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="232">        <span class="n">input_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="233">        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="234">        <span class="n">words_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="235">        <span class="n">text_lengths</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="236">        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span data-line="237">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
</span><span data-line="238"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward pass for token model using ONNX inference.</span>
</span><span data-line="239">
</span><span data-line="240"><span class="sd">        Args:</span>
</span><span data-line="241"><span class="sd">            input_ids: Tensor of shape (batch_size, seq_len) containing input token IDs.</span>
</span><span data-line="242"><span class="sd">            attention_mask: Tensor of shape (batch_size, seq_len) with 1s for real</span>
</span><span data-line="243"><span class="sd">                tokens and 0s for padding.</span>
</span><span data-line="244"><span class="sd">            words_mask: Tensor of shape (batch_size, seq_len) indicating word boundaries.</span>
</span><span data-line="245"><span class="sd">            text_lengths: Tensor of shape (batch_size,) containing the actual length</span>
</span><span data-line="246"><span class="sd">                of each text sequence.</span>
</span><span data-line="247"><span class="sd">            **kwargs: Additional arguments (ignored).</span>
</span><span data-line="248">
</span><span data-line="249"><span class="sd">        Returns:</span>
</span><span data-line="250"><span class="sd">            GLiNERBaseOutput containing logits for token classification.</span>
</span><span data-line="251"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="252">        <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span>
</span><span data-line="253">            <span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">input_ids</span><span class="p">,</span>
</span><span data-line="254">            <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">attention_mask</span><span class="p">,</span>
</span><span data-line="255">            <span class="s2">&quot;words_mask&quot;</span><span class="p">:</span> <span class="n">words_mask</span><span class="p">,</span>
</span><span data-line="256">            <span class="s2">&quot;text_lengths&quot;</span><span class="p">:</span> <span class="n">text_lengths</span><span class="p">,</span>
</span><span data-line="257">        <span class="p">}</span>
</span><span data-line="258">        <span class="n">prepared_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_inputs</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span data-line="259">        <span class="n">inference_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_inference</span><span class="p">(</span><span class="n">prepared_inputs</span><span class="p">)</span>
</span><span data-line="260">        <span class="n">outputs</span> <span class="o">=</span> <span class="n">GLiNERBaseOutput</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">inference_output</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">])</span>
</span><span data-line="261">        <span class="k">return</span> <span class="n">outputs</span></div>
</div>

</span><span data-line="262">
</span><span data-line="263">
<div class="viewcode-block" id="BiEncoderTokenORTModel">
<a class="viewcode-back" href="../../../api/gliner.onnx.model.html#gliner.onnx.model.BiEncoderTokenORTModel">[docs]</a>
</span><span data-line="264"><span class="k">class</span><span class="w"> </span><span class="nc">BiEncoderTokenORTModel</span><span class="p">(</span><span class="n">BaseORTModel</span><span class="p">):</span>
</span><span data-line="265"><span class="w">    </span><span class="sd">&quot;&quot;&quot;ONNX Runtime model for bi-encoder token-level NER.</span>
</span><span data-line="266">
</span><span data-line="267"><span class="sd">    Uses separate encoders for text and entity labels, performing</span>
</span><span data-line="268"><span class="sd">    token-level entity recognition with bi-encoder architecture.</span>
</span><span data-line="269"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="270">
<div class="viewcode-block" id="BiEncoderTokenORTModel.forward">
<a class="viewcode-back" href="../../../api/gliner.onnx.model.html#gliner.onnx.model.BiEncoderTokenORTModel.forward">[docs]</a>
</span><span data-line="271">    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span data-line="272">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="273">        <span class="n">input_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="274">        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="275">        <span class="n">words_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="276">        <span class="n">text_lengths</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="277">        <span class="n">labels_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="278">        <span class="n">labels_input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="279">        <span class="n">labels_attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span data-line="280">        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span data-line="281">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
</span><span data-line="282"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward pass for bi-encoder token model using ONNX inference.</span>
</span><span data-line="283">
</span><span data-line="284"><span class="sd">        Args:</span>
</span><span data-line="285"><span class="sd">            input_ids: Tensor of shape (batch_size, seq_len) containing input token IDs.</span>
</span><span data-line="286"><span class="sd">            attention_mask: Tensor of shape (batch_size, seq_len) with 1s for real</span>
</span><span data-line="287"><span class="sd">                tokens and 0s for padding.</span>
</span><span data-line="288"><span class="sd">            words_mask: Tensor of shape (batch_size, seq_len) indicating word boundaries.</span>
</span><span data-line="289"><span class="sd">            text_lengths: Tensor of shape (batch_size,) containing the actual length</span>
</span><span data-line="290"><span class="sd">                of each text sequence.</span>
</span><span data-line="291"><span class="sd">            labels_embeds: Optional pre-computed embeddings for entity labels.</span>
</span><span data-line="292"><span class="sd">                If provided, labels_input_ids and labels_attention_mask are ignored.</span>
</span><span data-line="293"><span class="sd">            labels_input_ids: Optional tensor containing token IDs for entity labels.</span>
</span><span data-line="294"><span class="sd">                Used when labels_embeds is not provided.</span>
</span><span data-line="295"><span class="sd">            labels_attention_mask: Optional attention mask for entity label tokens.</span>
</span><span data-line="296"><span class="sd">                Used when labels_embeds is not provided.</span>
</span><span data-line="297"><span class="sd">            **kwargs: Additional arguments (ignored).</span>
</span><span data-line="298">
</span><span data-line="299"><span class="sd">        Returns:</span>
</span><span data-line="300"><span class="sd">            GLiNERBaseOutput containing logits for token classification.</span>
</span><span data-line="301"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="302">        <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span>
</span><span data-line="303">            <span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">input_ids</span><span class="p">,</span>
</span><span data-line="304">            <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">attention_mask</span><span class="p">,</span>
</span><span data-line="305">            <span class="s2">&quot;words_mask&quot;</span><span class="p">:</span> <span class="n">words_mask</span><span class="p">,</span>
</span><span data-line="306">            <span class="s2">&quot;text_lengths&quot;</span><span class="p">:</span> <span class="n">text_lengths</span><span class="p">,</span>
</span><span data-line="307">        <span class="p">}</span>
</span><span data-line="308">
</span><span data-line="309">        <span class="k">if</span> <span class="n">labels_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span data-line="310">            <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;labels_embeds&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels_embeds</span>
</span><span data-line="311">        <span class="k">else</span><span class="p">:</span>
</span><span data-line="312">            <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;labels_input_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels_input_ids</span>
</span><span data-line="313">            <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;labels_attention_mask&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels_attention_mask</span>
</span><span data-line="314">
</span><span data-line="315">        <span class="n">prepared_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_inputs</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span data-line="316">        <span class="n">inference_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_inference</span><span class="p">(</span><span class="n">prepared_inputs</span><span class="p">)</span>
</span><span data-line="317">        <span class="n">outputs</span> <span class="o">=</span> <span class="n">GLiNERBaseOutput</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">inference_output</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">])</span>
</span><span data-line="318">        <span class="k">return</span> <span class="n">outputs</span></div>
</div>

</span><span data-line="319">
</span><span data-line="320">
<div class="viewcode-block" id="UniEncoderSpanRelexORTModel">
<a class="viewcode-back" href="../../../api/gliner.onnx.model.html#gliner.onnx.model.UniEncoderSpanRelexORTModel">[docs]</a>
</span><span data-line="321"><span class="k">class</span><span class="w"> </span><span class="nc">UniEncoderSpanRelexORTModel</span><span class="p">(</span><span class="n">BaseORTModel</span><span class="p">):</span>
</span><span data-line="322"><span class="w">    </span><span class="sd">&quot;&quot;&quot;ONNX Runtime model for uni-encoder span-level relation extraction.</span>
</span><span data-line="323">
</span><span data-line="324"><span class="sd">    Uses a single encoder to process text and perform both entity recognition</span>
</span><span data-line="325"><span class="sd">    and relation extraction at the span level.</span>
</span><span data-line="326"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="327">
<div class="viewcode-block" id="UniEncoderSpanRelexORTModel.forward">
<a class="viewcode-back" href="../../../api/gliner.onnx.model.html#gliner.onnx.model.UniEncoderSpanRelexORTModel.forward">[docs]</a>
</span><span data-line="328">    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span data-line="329">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="330">        <span class="n">input_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="331">        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="332">        <span class="n">words_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="333">        <span class="n">text_lengths</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="334">        <span class="n">span_idx</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="335">        <span class="n">span_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="336">        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span data-line="337">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
</span><span data-line="338"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward pass for span relation extraction model using ONNX inference.</span>
</span><span data-line="339">
</span><span data-line="340"><span class="sd">        Args:</span>
</span><span data-line="341"><span class="sd">            input_ids: Tensor of shape (batch_size, seq_len) containing input token IDs.</span>
</span><span data-line="342"><span class="sd">            attention_mask: Tensor of shape (batch_size, seq_len) with 1s for real</span>
</span><span data-line="343"><span class="sd">                tokens and 0s for padding.</span>
</span><span data-line="344"><span class="sd">            words_mask: Tensor of shape (batch_size, seq_len) indicating word boundaries.</span>
</span><span data-line="345"><span class="sd">            text_lengths: Tensor of shape (batch_size,) containing the actual length</span>
</span><span data-line="346"><span class="sd">                of each text sequence.</span>
</span><span data-line="347"><span class="sd">            span_idx: Tensor containing indices of spans to classify.</span>
</span><span data-line="348"><span class="sd">            span_mask: Tensor indicating which spans are valid (not padding).</span>
</span><span data-line="349"><span class="sd">            **kwargs: Additional arguments (ignored).</span>
</span><span data-line="350">
</span><span data-line="351"><span class="sd">        Returns:</span>
</span><span data-line="352"><span class="sd">            GLiNERRelexOutput containing logits for span classification, relation</span>
</span><span data-line="353"><span class="sd">            indices, relation logits, and relation mask.</span>
</span><span data-line="354"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="355">        <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span>
</span><span data-line="356">            <span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">input_ids</span><span class="p">,</span>
</span><span data-line="357">            <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">attention_mask</span><span class="p">,</span>
</span><span data-line="358">            <span class="s2">&quot;words_mask&quot;</span><span class="p">:</span> <span class="n">words_mask</span><span class="p">,</span>
</span><span data-line="359">            <span class="s2">&quot;text_lengths&quot;</span><span class="p">:</span> <span class="n">text_lengths</span><span class="p">,</span>
</span><span data-line="360">            <span class="s2">&quot;span_idx&quot;</span><span class="p">:</span> <span class="n">span_idx</span><span class="p">,</span>
</span><span data-line="361">            <span class="s2">&quot;span_mask&quot;</span><span class="p">:</span> <span class="n">span_mask</span><span class="p">,</span>
</span><span data-line="362">        <span class="p">}</span>
</span><span data-line="363">        <span class="n">prepared_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_inputs</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span data-line="364">        <span class="n">inference_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_inference</span><span class="p">(</span><span class="n">prepared_inputs</span><span class="p">)</span>
</span><span data-line="365">        <span class="n">outputs</span> <span class="o">=</span> <span class="n">GLiNERRelexOutput</span><span class="p">(</span>
</span><span data-line="366">            <span class="n">logits</span><span class="o">=</span><span class="n">inference_output</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">],</span>
</span><span data-line="367">            <span class="n">rel_idx</span><span class="o">=</span><span class="n">inference_output</span><span class="p">[</span><span class="s2">&quot;rel_idx&quot;</span><span class="p">],</span>
</span><span data-line="368">            <span class="n">rel_logits</span><span class="o">=</span><span class="n">inference_output</span><span class="p">[</span><span class="s2">&quot;rel_logits&quot;</span><span class="p">],</span>
</span><span data-line="369">            <span class="n">rel_mask</span><span class="o">=</span><span class="n">inference_output</span><span class="p">[</span><span class="s2">&quot;rel_mask&quot;</span><span class="p">],</span>
</span><span data-line="370">        <span class="p">)</span>
</span><span data-line="371">        <span class="k">return</span> <span class="n">outputs</span></div>
</div>

</span><span data-line="372">
</span><span data-line="373">
<div class="viewcode-block" id="UniEncoderTokenRelexORTModel">
<a class="viewcode-back" href="../../../api/gliner.onnx.model.html#gliner.onnx.model.UniEncoderTokenRelexORTModel">[docs]</a>
</span><span data-line="374"><span class="k">class</span><span class="w"> </span><span class="nc">UniEncoderTokenRelexORTModel</span><span class="p">(</span><span class="n">BaseORTModel</span><span class="p">):</span>
</span><span data-line="375"><span class="w">    </span><span class="sd">&quot;&quot;&quot;ONNX Runtime model for uni-encoder token-level relation extraction.</span>
</span><span data-line="376">
</span><span data-line="377"><span class="sd">    Uses a single encoder to process text and perform both entity recognition</span>
</span><span data-line="378"><span class="sd">    and relation extraction at the token level.</span>
</span><span data-line="379"><span class="sd">    &quot;&quot;&quot;</span>
</span><span data-line="380">
<div class="viewcode-block" id="UniEncoderTokenRelexORTModel.forward">
<a class="viewcode-back" href="../../../api/gliner.onnx.model.html#gliner.onnx.model.UniEncoderTokenRelexORTModel.forward">[docs]</a>
</span><span data-line="381">    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
</span><span data-line="382">        <span class="bp">self</span><span class="p">,</span>
</span><span data-line="383">        <span class="n">input_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="384">        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="385">        <span class="n">words_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="386">        <span class="n">text_lengths</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span data-line="387">        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span data-line="388">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
</span><span data-line="389"><span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward pass for span relation extraction model using ONNX inference.</span>
</span><span data-line="390">
</span><span data-line="391"><span class="sd">        Args:</span>
</span><span data-line="392"><span class="sd">            input_ids: Tensor of shape (batch_size, seq_len) containing input token IDs.</span>
</span><span data-line="393"><span class="sd">            attention_mask: Tensor of shape (batch_size, seq_len) with 1s for real</span>
</span><span data-line="394"><span class="sd">                tokens and 0s for padding.</span>
</span><span data-line="395"><span class="sd">            words_mask: Tensor of shape (batch_size, seq_len) indicating word boundaries.</span>
</span><span data-line="396"><span class="sd">            text_lengths: Tensor of shape (batch_size,) containing the actual length</span>
</span><span data-line="397"><span class="sd">                of each text sequence.</span>
</span><span data-line="398"><span class="sd">            span_idx: Tensor containing indices of spans to classify.</span>
</span><span data-line="399"><span class="sd">            span_mask: Tensor indicating which spans are valid (not padding).</span>
</span><span data-line="400"><span class="sd">            **kwargs: Additional arguments (ignored).</span>
</span><span data-line="401">
</span><span data-line="402"><span class="sd">        Returns:</span>
</span><span data-line="403"><span class="sd">            GLiNERRelexOutput containing logits for span classification, relation</span>
</span><span data-line="404"><span class="sd">            indices, relation logits, and relation mask.</span>
</span><span data-line="405"><span class="sd">        &quot;&quot;&quot;</span>
</span><span data-line="406">        <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span>
</span><span data-line="407">            <span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">input_ids</span><span class="p">,</span>
</span><span data-line="408">            <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">attention_mask</span><span class="p">,</span>
</span><span data-line="409">            <span class="s2">&quot;words_mask&quot;</span><span class="p">:</span> <span class="n">words_mask</span><span class="p">,</span>
</span><span data-line="410">            <span class="s2">&quot;text_lengths&quot;</span><span class="p">:</span> <span class="n">text_lengths</span><span class="p">,</span>
</span><span data-line="411">        <span class="p">}</span>
</span><span data-line="412">        <span class="n">prepared_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_inputs</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span data-line="413">        <span class="n">inference_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_inference</span><span class="p">(</span><span class="n">prepared_inputs</span><span class="p">)</span>
</span><span data-line="414">        <span class="n">outputs</span> <span class="o">=</span> <span class="n">GLiNERRelexOutput</span><span class="p">(</span>
</span><span data-line="415">            <span class="n">logits</span><span class="o">=</span><span class="n">inference_output</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">],</span>
</span><span data-line="416">            <span class="n">rel_idx</span><span class="o">=</span><span class="n">inference_output</span><span class="p">[</span><span class="s2">&quot;rel_idx&quot;</span><span class="p">],</span>
</span><span data-line="417">            <span class="n">rel_logits</span><span class="o">=</span><span class="n">inference_output</span><span class="p">[</span><span class="s2">&quot;rel_logits&quot;</span><span class="p">],</span>
</span><span data-line="418">            <span class="n">rel_mask</span><span class="o">=</span><span class="n">inference_output</span><span class="p">[</span><span class="s2">&quot;rel_mask&quot;</span><span class="p">],</span>
</span><span data-line="419">        <span class="p">)</span>
</span><span data-line="420">        <span class="k">return</span> <span class="n">outputs</span></div>
</div>

</span></pre></div>
        </article><button class="back-to-top" type="button">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
  </svg>
  <span>Back to top</span>
</button><div class="navigation flex print:hidden"></div></div>
    </div>
  </main>
</div>
<footer class="sy-foot">
  <div class="sy-foot-inner sy-container mx-auto">
    <div class="sy-foot-reserved md:flex justify-between items-center">
      <div class="sy-foot-copyright"><p>2025, GLiNER community</p>
  
  <p>
    Made with
    
    <a href="https://www.sphinx-doc.org/">Sphinx</a> and
    
    <a href="https://shibuya.lepture.com">Shibuya theme</a>.
  </p>
</div>
      <div class="sy-foot-socials"></div>
    </div>
  </div>
</footer>
      <script src="../../../_static/documentation_options.js?v=dc91f075"></script>
      <script src="../../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../../_static/shibuya.js?v=9b0e4dde"></script></body>
</html>